---
layout: post
title: '#96 AWS re:Invent 2023'
date: 2023-12-15 08:00:00 +0200
description: 
episode: "96"
tags: ["aws","azure","nvidia","github","graviton","aurora","opentelemetry","grafana"]
spreaker: 58004652
apple: 
newsletter:  |
  

  ## Posłuchaj odcinka na ⬇️

  ➡️ [WWW](https://patoarchitekci.io/96/)

  ➡️ [Spotify](https://open.spotify.com/episode/)

  ➡️ [Apple Podcasts](https://podcasts.apple.com/pl/podcast/)

  ➡️ [YouTube]()
---
To się podziało! Dzisiaj w podcaście kilka ogłoszeń patoparafialnych, w tym MEETUP! Tak, z okazji setnego odcinak zapraszamy Cię na specjalny meetup. Szczegóły w podcaście i linkach. A to dopiero początek, bo mamy też w zanadrzu otwarte patoszkolenia. Co, jak, gdzie i kiedy? Tego też dowiesz się bezpośrednio z podcastu. Stay tuned i czekaj na kolejne informacje!

A poza tym - Łukasz i Szymon grillują ostatnią konfę AWS-a. Nie zostawiają suchej nitki na utopijnych, hypowych pomysłach. Ale jest też coś, co przypadło im do gustu. Szymon opowiada o tym, jak 5 godzin spędził na słuchaniu podcastu. Chyba było warto? Hm. 

Chcesz więcej? Posłuchaj nowego odcinka!


Linki i ciekawe znaleziska:

- [Top announcements of AWS re:Invent 2023  ](https://aws.amazon.com/blogs/aws/top-announcements-of-aws-reinvent-2023/)
- [Getting started with new Amazon RDS for Db2  ](https://aws.amazon.com/blogs/aws/getting-started-with-new-amazon-rds-for-db2/)
- [Vector engine for Amazon OpenSearch Serverless is now available  ](https://aws.amazon.com/blogs/aws/vector-engine-for-amazon-opensearch-serverless-is-now-generally-available/)
- [Amazon CloudWatch Application Signals for automatic instrumentation of your applications nullpreview)  ](https://aws.amazon.com/blogs/aws/amazon-cloudwatch-application-signals-for-automatic-instrumentation-of-your-applications-preview/)
- [Agents for Amazon Bedrock is now available with improved control of orchestration and visibility into reasoning  ](https://aws.amazon.com/blogs/aws/agents-for-amazon-bedrock-is-now-available-with-improved-control-of-orchestration-and-visibility-into-reasoning/)
- [Amazon Q (Preview)](https://aws.amazon.com/q/)
- [Agents for Amazon Bedrock is now available with improved control of orchestration and visibility into reasoning  ](https://aws.amazon.com/blogs/aws/agents-for-amazon-bedrock-is-now-available-with-improved-control-of-orchestration-and-visibility-into-reasoning/)

### Transkrypcja

**Łukasz Kałużny**: Cześć, słuchacie Patoarchitektów. Prowadzą Łukasz Kałużny...

**Szymon Warda**: I Szymon Warda. Wszystkie linki do tego odcinka oczywiście na Patoarchitekci.io. Numerek sobie ogarniecie, będzie w opisie. I co Łukaszu mamy? Numerki się zbliżają, bo o nich trochę nie mówimy, ale zbliża się taki dość pierwszy trzynumerkowy numerek, że tak powiem, więc będzie meet up.

**Łukasz Kałużny**: Tak, z okazji, tak jak było i pięćdziesiątego odcinka, to teraz będziemy świętować, celebrować, czy jak to określicie, setny odcinek. I słuchajcie, zapraszamy Was 10 stycznia, godzina 18:00 do Warszawy. Link już znajdziecie pewnie gdzieś w opisie, jak i na stronie, Face'ach, LinkedInach, mailingu, jeżeli jesteście zapisani. I co? Zrobimy, trzy sesje. Są pewne pomysły. Szymon, chyba wstępnie o IDP będziesz mówił prawdopodobnie?

**Szymon Warda**: Tak, procesy, technologia, dokładnie.

**Łukasz Kałużny**: Tak. Ja mam za to takie szczere patoarchitektoniczne spojrzenie na LLM-y. W jaki sposób to będzie wyglądać? I wspólnie z Wami, być może w formule AMA, być może tak jak odcinek 50, trochę short i AMA. Nagramy wspólnie setny odcinek tam na żywo, który potem już pójdzie i będziecie mogli poznać go wcześniej, jeżeli będziecie na miejscu.

**Szymon Warda**: Tak, ale to nie wszystko, bo stwierdziliśmy, że trochę się wymądrzamy w tych podcastach i też w życiu odnośnie kilku tematów, więc stwierdziliśmy, że skoro się wymądrzamy i dostaliśmy sygnały, że fajnie byłoby nie tylko się wymądrzać, ale też ułożyć tą wiedzę, trochę ustrukturyzować, więc odpalamy szkolenia krótkie. Ja poprowadzę szkolenie odnośnie modelowania danych nie tylko w SQL-u. Generalnie szkolenie będzie o modelowaniu danych. Też jak ktoś umie modelować dane, to się przekłada generalnie na różne bazy, czy NoSQL-owe, czy SQL-owe, obojętne.

**Łukasz Kałużny**: Na razie pokazanie jak zamodelować to w stor'ze do trzymania ich.

**Szymon Warda**: Tak, dokładnie, różne podejścia i to, że odkrycie, piąta postać normalna nie jest czymś wybitnym i praktycznie jak podejść, żeby te dane się skalowały przede wszystkim i żeby były też jakieś rozumne. 21 lutego, zapraszam.

**Łukasz Kałużny**: Tak, a dzień potem, 22 lutego przyszłego roku, bo to już będzie 2024 Kubernetes The Hard Way. Się śmieję, że jest to troszeczkę kultowe szkolenie, żeby pokazać, dlaczego nie warto używać Kubernetesa. Czyli pokazanie jak postawić i jak działa Kubernetes od bebechów strony, binarek i całej infry, żeby go naprawdę zrozumieć, co tam siedzi i zrozumieć dlaczego tak często wypowiadam się, że jest to cep.

**Szymon Warda**: Trochę jest.

**Łukasz Kałużny**: I co ważne mocno praktyczne. U Ciebie, z tego co kojarzę, jest Szymonie dużo ćwiczeń praktycznych i grupowych.

**Szymon Warda**: Slajdów nie będzie, to ogólnie rzecz biorąc.

**Łukasz Kałużny**: Tak, a u mnie dostajecie takie ciekawe repozytorium GitHubowe, które przechodzimy wspólnie i sami stawiacie na środowisku, w którym dostaniecie cały klaster. Więc zapraszamy, linki też w opisie. I jest to na żywo szkolenie, bo tego nie dodaliśmy, mogło wynikać, że coś nagrywamy. Nie, to szkolenie takie całodniowe, na żywo, zdalnie.

**Szymon Warda**: Tak, z pełną interakcją. Dobrze, to o czym dzisiaj?

**Łukasz Kałużny**: Dzisiaj ostatnia konferencja w tym roku, czyli AWS re:Invent. I dobra, to Szymon, jakie pierwsze przemyślenie, jeżeli popatrzysz na całość? I zestawmy Gen AI-a.

**Szymon Warda**: Tak, dla mnie ciekawy właściwie miks, bo wydawało mi się przed konferencją, że AWS pójdzie w opcję - wcale nie jesteśmy tak w plecy jak pozostali konkurenci jeżeli chodzi o AI-a de facto. A nie było aż tyle o AI-u, może dlatego, że to co było o AI-u nie było jakieś takie zbyt rewolucyjne i trochę tak średnio to wyglądało. Było dużo rzeczy aplikacyjnych, było dużo rzeczy przygotowujących pod AI-a de facto. Ale samego AI-a nie było aż tak dużo. Było dużo o skalowaniu, było o tych aplikacjach. Całkiem powiedziałbym, że to ciekawie wygląda tak naprawdę.

**Łukasz Kałużny**: Dobra, to wiesz co, tak, z mojej perspektywy pierwsze przemyślenie, 2 keynote'y, które warto byłoby obejrzeć, to są prawie dwie godziny. Jeżeli główny keynote i Wernera Vogelsa obejrzymy, to są prawie 4 godziny keynote'ów. I to taka moja w tym i styl jest podobnie beznadziejny jak Microsoftu, podobnie beznadziejny jak GitHuba, podobnie beznadziejny jak Google'a.

**Szymon Warda**: Tak, to są te korporacje, które są zorientowane na biznes, a chcą robić keynote'y jak Steve Jobs. To nie klei się trochę za bardzo.

**Łukasz Kałużny**: Aczkolwiek z tegorocznych prawdopodobnie jakościowo najlepsza, jeżeli chodzi o przegląd sceniczny. Więc to jest jedna rzecz. Tak jak mówiłeś, tego Gen AI-a jest sporo i nie sporo, bo jak popatrzymy na newsy to go nie ma sporo. Jeżeli popatrzymy na to, o czym... Bo Ja zawsze tak mówię, patrzę na ten główny przekaz, to tam jest sporo, że pokazanie, że jesteśmy na tym samym wózku co reszta.

**Szymon Warda**: Generalnie nie są.

**Łukasz Kałużny**: Nie są. I dla mnie taka jedna duża myśl z całości tej układanki, że wygranym całości jest Nvidia. Całej tegorocznej układanki największym wygranym aktualnie na kasie jest Nvidia.

**Szymon Warda**: Nvidia jest wygranym od mniej więcej już kilku lat, bo wcześniej były kryptowaluty, też była wygranym defacto Nvidia.

**Łukasz Kałużny**: Tak, ale teraz zobacz, to jest na potęgę już pchane, jak sobie popatrzysz sprzęt.

**Szymon Warda**: Ostatnio Nvidia ogłosiła, że nie są firmą od chipów, tylko są firmą od AI-a defacto.

**Łukasz Kałużny**: Która robi chipy. I wiesz co? I teraz patrząc się na całość układanki, pewnie to też masz dokładnie wybrane, patrząc już się na rzeczy technologiczne, które są, takich głównych rzeczy, kasa jest w hardwarze i dostępie do tego capacity computingowego pod AI-a aktualnie.

**Szymon Warda**: Tak, to jest konferencja gdzie AWS pokazuje bardziej, że my możemy przyjąć na twarz duże ilości danych i to widać w compute i widać to w bazach danych, widać to w storage'u, widać w bardzo wielu rzeczach, że oni są gotowi te dane przyjąć, ale nie do końca jest co z tymi danymi robić tak naprawdę.

**Łukasz Kałużny**: Tak i teraz zabawa pokazuje, że oni również ogłosili nowe chipy. Pewnie masz to wybrane i chipy pod AI-a i pod serwowanie.

**Szymon Warda**: Ale ja im się nie dziwię, bo to, że mówimy, że Nvidia wygrała, to w ogóle bez dwóch zdań, ale to jest tak silne uzależnienie się wszystkich dostawców chmurowych i nawet nie tylko od Nvidii, że każdy z nich zauważy ogromne ryzyko. Po pierwsze ryzyko biznesowe. Po drugie te chipy żrą prądu ile tylko mogą de facto, więc to będzie na granicy opłacalności. Dlatego też.

**Łukasz Kałużny**: Szanuję też nazwę, Trainium, tego chipa.

**Szymon Warda**: I tam jeszcze jest drugi, Graviton.

**Łukasz Kałużny**: Tak, ale to jest już ich seria, która była wcześniej, więc to jest po prostu kolejna generacja. I tak jak każdy dostawca idzie i oni z tym ARM-em w sumie, tam patrząc się na rynek, to troszkę zwojowali u siebie, bo ludzie poważnie traktują te instancje, tam gdzie piszą nowy software.

**Szymon Warda**: One też w ogóle są faktycznie, ciekawie wypchnęli, bo AWS wypchnął te instancje jako takie masywne instancje do naprawdę dużych obliczeń, niejako taką tam popelinkę, gdzie możesz sobie aplikacje zahostować. Tylko faktycznie jako instancje dla liczb. Graviton ma 96 neoverse vicorów de facto, 2 Mb cache'u per core, czyli tego jest sporawo, 12 kanałów DDR 5. To są konkretne maszyny.

**Łukasz Kałużny**: Konkretne i to co tam było, taki fajny slajd, że szykują się, że mają świetny chip do trenowania deep learningowego, w szczególności LLM-ów. To była pierwsza taka rzecz, która była rzucana na grafice. I druga, że mają świetne miejsce do serwowania modeli. I ten Graviton przy dużej skali, tak, wygląda nieźle.

**Szymon Warda**: Wygląda nieźle. Żeby dla kontekstu, ogłosili też nowe instancje U7I, które mają 896 vcore'ów i od 16 do 32 TB pamięci.

**Łukasz Kałużny**: Jeżeli umiesz pisać rozproszenie, ładnie możesz zapakować na tą maszynę. Nic więcej nie potrzebujesz.

**Szymon Warda**: Tak. Jedna rzecz pokazuje tutaj dla mnie dość mocno, patrząc na inne konferencje dostawców chmurowych. Jeżeli chodzi o infrastrukturę taką, faktyczne instancje, wirtuale i tego typu rzeczy, to faktycznie AWS jest super dojrzały, to w ogóle przebija innych.

**Łukasz Kałużny**: Wiesz co, ale to jest tak, jak ja sobie patrzę na te ogłoszenia i to jest taki mój zarzut, dlaczego ja osobiście nie preferuję AWS-a. Jakbym miał wybierać projekt, wolę Azure albo Googla. To jest taka bardzo osobista rzecz. Mimo, że wywodzę się z infry, to AWS jest za bardzo przywiązany do myślenia invro, jak sobie teraz popatrzymy.

**Szymon Warda**: Oni powoli to tego dochodzą, ale ja się z tym zgodzę. Młotkiem w AWS-ie jest wirtualka. Potrzebujesz czegokolwiek, robisz wirtualkę.

**Łukasz Kałużny**: Są Lambdy i Fargate'y, ale kończysz gdzieś wokół EC2 w jakiejś formie, albo jak te RDS-y są zorientowane na tą EC2.

**Szymon Warda**: Widać, że oni od paru lat próbują od tego odejść po prostu. Ale moja teoria jest taka, że ludzie po prostu nie są w stanie znaleźć tych nowych usług, bo nazewnictwo w AWS-ie dalej jest tak do dupy jak było do dupy.

**Łukasz Kałużny**: I wiesz co? Ja chciałbym przeskoczyć do keynota Vogelsa z dwóch powodów. 1 jest właśnie na temat tych VM-ek. Drugi, że jest on wartościowy też dla ludzi, którzy nie siedzą w AWS-ie. I Vogels o czym mówił? Jedna rzecz, która mnie przeraża, bo z jednej strony w RDS-ie, czyli usłudze do relacyjnych baz danych, został ogłoszony support dla DB2 IBM-owskiej, czyli typowy lift and shift.

**Szymon Warda**: To znaczy, że idą po taki stary enterprise typu banki.

**Łukasz Kałużny**: Ale słuchaj, to tak jak teraz próbują reanimować WCF-a, żeby to przenosić.

**Szymon Warda**: Ale mi się wydaje, że będzie rynek na open WCF-a. Są firmy, które nigdy z niego nie zejdą de facto.

**Łukasz Kałużny**: Tak, więc przy okazji DB2 tam pada też trochę inne stwierdzenie i całej tej migracji. Jest określenie, że w angielskim jednym z najgorszych zwrotów jest, bo ciągle robiliśmy w ten sam sposób - 'we have always done it this way'. I teraz z jednej strony jest takie narzucenie, że powinniśmy się rozwijać, robić to coraz lepiej. Z drugiej strony robimy po prostu shift to cloud, żeby być w cloudzie, bo nadal są takie podejścia. I na tym AWS zarabia promując, że przenieśmy gówno.

**Szymon Warda**: Pamiętaj o tym, lift and shift to jest najłatwiejszy sposób, żeby zyskać klienta, bo to wygrana właściwie dla managera, który prowadzi projekt. No bo co? No bo udało się. W ciągu dwóch miesięcy może ogłosić, że są w chmurze AWS-owej, itd.

**Łukasz Kałużny**: I RDS pokazuje, że jak mamy RDS-a i EC2, to jesteśmy natywni dla cloudu.

**Szymon Warda**: Ja ich w pełni rozumiem. To jest sposób jak zaatakować takie stare, stare korporacje typu właśnie banki, bo tam jest dużo DB2.

**Łukasz Kałużny**: I Werner jeszcze jedną rzecz promował, czyli podejście żeby być oszczędnym. I tam też to za linkuję sobie, The Fragile Architect, jest takich 7 praw. Ale co jest fajne w przypadku AWS-a, że jest ktoś, czyli CTO AWS-a, który mówi o oszczędności i ją promuje.

**Szymon Warda**: Patrząc na wyniki ekonomiczne, itd., nawet spójrzmy na start tego roku, co było bardzo mocno na świeczniku? Były całe FinOpsy, czyli jak oszczędzać, jak patrzeć, jak monitorować. Pojawiło się masę usług od tego, po ogólnie rzecz biorąc usługi bardzo niepewne, co w ogóle będzie się działo. Więc oficjalnie tak. A wszyscy teraz rzucają się na LLM-y, władują w to masę kasy, ale za pół roku, 3 miesiąc ktoś powie: ej, ale skąd te wydatki? Czemu to się dzieje?

**Łukasz Kałużny**: Wiesz co, Szymon, tylko jedna rzecz, pozwolę Ci się wtrącić, to jest dla mnie plus AWS-a, jako vendora. Jest to jedyny vendor z tych dużych, któremu realnie pracownicy pomagają oszczędzać, bo podchodzili zawsze do tego, że jeżeli pomogą oszczędzić, to klient wrzuci następny projekt i następny, będzie pączkował. Jeżeli pomożemy mu ściąć rachunek, to będzie pączkował dalej.

**Szymon Warda**: Dla mnie jest jedna rzecz oczywista, nie robią tego z dobroci własnego serca.

**Łukasz Kałużny**: Nie, nie robią.

**Szymon Warda**: To też właśnie. Więc to jest zawsze... Ale jedna rzecz, którą poruszyłeś, dane. Jeżeli chodzi o przechowanie danych, mnie co innego zaciekawiło bardzo mocno. Nowa usługa, która dla mnie jest trochę taka, takie niejasne uczucia de facto Aurora Limitless Database. O co tam chodzi? Chodzi o to, że w tym momencie usługa na bazie Aurora, która co umie? Umie się automatycznie skalować, automatycznie tworzyć shardy horyzontalnie. Shardy też zapisowe, nie tylko odczytowe. Jak oni to ciekawie zrobili? Mianowicie na poziomie bazy danych określamy, które tabele mają być shardowane, a które tabele są replikowane dla każdej instancji bazy danych. Ja mam do tego bardzo mieszane uczucia, bo pomysł jako taki jest super, ale pomysł jako taki jest przerażający, bo de facto doprowadzi do tego, że teraz wyobraź sobie, że tworząc bazę tak naprawdę albo tworząc kolumny, tworząc tabele określasz generalnie czy są shardowane, czy są replikowane wszędzie. I teraz z punktu widzenia tego developera, który pisze kod aplikacyjny, on z reguły nie ma pojęcia jak co działa tak naprawdę. Więc jestem bardzo ciekawy wrażeń, bo to jest duży system, nie oszukujmy się, jak to będzie wykorzystywany i jak to będzie się realnie sprawdzało. Bo nazwa jest fenomenalna i jak w jednym zdaniu to jest fenomenalne. W szczegółach to pali się dużo żółtych lampeczek, że to nie jest takie automatyczne, automagiczne, jak nazwa mogłaby wskazywać. Ale usługa nie mniej ciekawa.

**Łukasz Kałużny**: Brzmi ciekawie, ale strasznie. Tak jak mówię, mam swoje wrażenia kiedy w 2017 chyba, 2016, 2017, coś takiego, musiałem się przy okazji nauczyć właśnie całość różnicy pod hurtownie danych, replikacji, asharidngów i innych tych zabaw, gdzie hurtownia jest prostszym scenariuszem.

**Szymon Warda**: Jest dużo prostszym.

**Łukasz Kałużny**: Ludzie od date'y wybaczcie, ale hurtownia po zaprojektowaniu modelu jest dużo prostszym scenariuszem.

**Szymon Warda**: Mamy głównie odczyty.

**Łukasz Kałużny**: Tak, bo mamy odczyty. Na czas ETL-a można zwiększyć moc w cloudzie. To jest to, tak to można określić. Więc nie wierzę w takiego AI-a. Jak jesteśmy przy danych, to co? Dokument DB Open Search dostały wektory, a jakże inaczej. Z nazwy to są te inwestycje, o których trzeba było zrobić.

**Szymon Warda**: To się musiało pojawić, łatwy sposób na dodanie, zwiększenie ophype'owanie usługi, która... DynamoDB jest taką jedną z podstawowych usług AWS-a tak naprawdę. To było zawsze, jest i to jest...

**Łukasz Kałużny**: Tylko przez długi czas była taka fajna patola, jak zrobić wszystko w DynamoDB na jednej tabeli.

**Szymon Warda**: O czym w ogóle mówiliśmy parę odcinków temu, dokładnie tak.

**Łukasz Kałużny**: Chyba tak, było. I słuchaj, z rzeczy, które są ciekawe też, jak jesteśmy w tematyce danych, to również zero-ETL-e do Redshifta i OpenSearcha.

**Szymon Warda**: Tak, właśnie też zauważyłem, że się pojawiły.

**Łukasz Kałużny**: Też się to rzuciło. I słuchajcie, z takich ciekawych rzeczy, czyli Postgresy, Dynamo, RDS-y, Aurorę możemy zapakować do Amazon RedShift-a za pomocą zero-ETL-a. To jest jedna rzecz. Druga, też ciekawa, to DynamoDB ma też integrację zero-ETL-ową pod wektory głównie w OpenSearch. Co też jest ciekawym scenariuszem z perspektywy takiej typowo aplikacyjnej, bo to trochę pokazuje, Szymon, scenariusz, gdzie Cosmos DB można automatycznie zindeksować teraz Azure AI Searchem, jak się teraz ta usługa nazywa, czyli wcześniej Cognitive Searchem.

**Szymon Warda**: I jeszcze kolejny element to jest to, że jeszcze zwiększona została wydajność kolejek, bo jak mówimy dane, to kolejki też za chwilę będą wchodziły i 70 tys. transakcji na sekundę. I [niesłyszalne 00:16:26] ładne wsparcie. Ale powiem Ci, że mnie co innego w ogóle ucieszyło. Takie dwie rzeczy, które mnie naprawdę ucieszyły. To jest jedna rzecz, jeżeli chodzi o monitoring i bezpieczeństwo, to jest wprowadzenie, wsparcie dla zapytań do logów, metryk, itd., wykorzystując język naturalny. To mnie bardzo ucieszyło. Wydaje mi się, to jest genialny absolutnie pomysł, bo o ile lubię kwerendy i zapytania odnośnie różnych narzędzi, to nauczenie się ich jest tak dziwną krzywą nauki, jest to upierdliwe. Cokolwiek ułatwimy w tym obszarze to będzie totalny, ogromny zysk de facto dla aplikacji i dla [niesłyszalne 00:17:06]. I to jest super pomysł dla mnie.

**Łukasz Kałużny**: Wiesz co, ja tutaj, jak wrzuciłeś logi i inne rzeczy, to dwa takie announcementy, które mi się rzuciły. Po pierwsze, nie sprawdzałem tutaj całości, ale Cloud Watch Application Signals, czyli właśnie AWS dorabia się APM-a, Application Performance Monitoringu, patrząc się na możliwości, natywnego. Czyli będzie odpowiedź u innych dostawców, bo tego brakowało. Nie było APM-a wcześniej.

**Szymon Warda**: I będzie. Zaczynają z grubej rury, z dużą obiecanką, że automatycznie mogą korelować telemetrię, logi, trace'y, metryki i w ogóle wszystko.

**Łukasz Kałużny**: Syntetyczny monitoring, więc jest tego sporo. Tylko wiesz, z drugiej strony uczestniczą w Open Telemetry, to już nie będzie takie straszne.

**Szymon Warda**: Tak, tylko czy zmiany na Open Telemetry jest proste? Pytanie, czy pójdą... Bo dla mnie to jest osobista przewaga Application Insights z Azure'a. To jest to, że ten stary model pod Open Telemtry jest dużo potężniejszy. Włączasz i działa wszystko automagicznie i faktycznie działa automagicznie.

**Łukasz Kałużny**: Jestem ciekaw tej autoinstrumentacji. Zrobią pewnie Javę na początku, zobaczymy co dalej, bo nie zaglądałem. I przy tej rzeczy oni jeszcze dodali coś takiego jak My Applications, czyli de facto, że można sobie wyspecyfikować taki wspólny cały dashboard, który będzie zbierał nam informacje o kosztach, statusie zasobów, informacjach z Cloud Watcha, z Security Huba, będzie zbierał w jednym miejscu. I to powiem, wiesz co, taki dashboard dla aplikacji, zastanawiam się po co to? Ale patrząc się to jest w ogóle ciekawa rzecz, że możesz zespołowi wystawić, jeżeli ktoś jest mocno AWS-owy, w jednym miejscu dosłownie wszystkie najważniejsze rzeczy, zamiast bawić się w dashboardzie w Grafanie i zrobić to tak z pudełka.

**Szymon Warda**: Dla mnie, powiem tak, cały rynek zdecydował, że używamy Grafany. Nie do końca widzę sens, żeby iść w coś swojego. Podoba mi się podejście MS-u, że stwierdzili, że okay, to my robimy Manage Grafanę. I to jest fajne podejście po prostu, bo odchodzi nam koszt utrzymania tego, w sensie taki mentalny. Współpracują z firmą, która jest liderem rynkowym, robią to dobrze i jeszcze wspomagają rozwój opensource'owego, mnóstwo produktów, które możemy też zahostować. Jakoś nie kupuję tego podejścia, takiego customowych teraz ekranów, dashboard-ów. Grafana istnieje tyle lat na rynku i jest ewidentnym liderem pod każdym względem.

**Łukasz Kałużny**: Jestem ciekaw jakie są data source'y, bo tego nigdy nie sprawdzałem, jakie są.

**Szymon Warda**: Właśnie tego będzie mniej.

**Łukasz Kałużny**: Wiesz co, właśnie się zastanawiam, ale wiesz co, data source'ów AWS-owych mają trochę do Grafany, więc jest...

**Szymon Warda**: Ok, czyli to jest ich przewaga rynkowa, ta usługa.

**Łukasz Kałużny**: Nie.

**Szymon Warda**: Nie, więc po cholerę to robią?

**Łukasz Kałużny**: Wiesz co, sądzę, że to jest pokazanie, że mamy wszystko. Na zasadzie, pamiętaj, że są głupie pytania Enterprise'ów. Nawet tam w referencji jest głupie pytanie, że chcemy mieć wszystko w jednej szklance.

**Szymon Warda**: Oczywiście tak, masz rację. Dlatego osobiście wolę podejście Azure'a, że wzięli Manage Grafanę.

**Łukasz Kałużny**: Przy czym tak, w AWS-ie też dla obrony jest Manage Grafana.

**Szymon Warda**: A mnie inna rzecz zaciekawiła też odnośnie co mówimy, odnośnie danych. Control Tower dorobił się 65 nowych controls, tak to możemy przetłumaczyć generalnie, które mają wspomagać limity, ograniczenia jeżeli chodzi o suwerenność danych. Czyli limity gdzie te dane mogą być. Czyli znowu AWS pochyla się w kierunku: dajcie nam wasze dane i to samo co też Azure zrobił, będzie to bezpieczne. Czyli ewidentnie mają chrapkę na dane takie bardziej wrażliwe, dane bardziej rządowe, które po prostu nie mogą odpowiednich regionów opuszczać. Taka mała rzecz a pokazuje bardzo mocno w którym kierunku chcą iść.

**Łukasz Kałużny**: Ja jestem ciekaw dokładnie czym są te kontrolki, bo to też się w to nie zagłębiałem. Czy to po prostu wyliczyli sobie per usługa, w którym może być datacenter, bo tak to brzmi troszeczkę.

**Szymon Warda**: To może być ciekawe. Ale druga rzecz, to mnie ucieszyła i też wydaje mi się strzał w dziesiątkę, jeżeli to będzie działało dobrze, bo widziałem, że Ty też to masz - Q Code Transformation, czyli automatyczne upgrade'y aplikacji do nowszych wersji. Np. z Javy z ósemki do jedenastki, z ósemki do jedenastki do siedemnastki. Więc ogromny skok jeżeli chodzi o wersjonowanie. Teraz będą zsadzali się też na rzeczy .NET-owe, itd. Fenomenalny ruch. I teraz czemu...

**Łukasz Kałużny**: Pomysł automatycznego reviewowania jest super?

**Szymon Warda**: I teraz czemu oni to robią? Bo w sensie po co AWS-owi zależy? Ano dlatego, że jak oni mają utrzymać te wszystkie runtime'y stare, to ich to kosztuje. Oni wolą optymalizować te nowsze runtime'y, więc im zależy, żeby aplikacje były w jak nowszej wersji tak naprawdę, bo po prostu mniejszy koszt utrzymaniowy de facto. Więc wydaje mi się, że to jest jedna z takich usług, gdzie zyskuje AWS i zyskuje klient wykorzystujący.

**Szymon Warda**: Tak, więc tutaj się zgodzę i tutaj dorzucę, jak jesteśmy w tematach developerskich, rozwijają bardzo mocno swojego CodeWhisperer, czyli odpowiednik GitHub Copilota. O, to jest chyba najlepsze. I patrząc się, co mnie zaskoczyła, piękna integracja z Visual Studio Code to wiadomo, że będzie, ale również z pełnym Visualem, jako plugin do pełnego Visual Studio. Inaczej, ten .NET, co by nie patrzeć, bardzo mocno tam się przebija.

**Szymon Warda**: Wiesz co, ja jestem po przeglądaniu ponad pięciogodzinnego podcastu z  Carmackiem od Dooma generalnie. Więc to, że tam istnieje ten Visual Studio zwykły, wcale mnie absolutnie nie dziwi.

**Łukasz Kałużny**: Więc tak, lecimy sobie, więc ta integracja, fajną rzecz, mocne wprowadzenie do Infrastructure as Code. I ja sobie rzuciłem i to jest pierdoła, bo w AWS-ie mamy ten natywny język deklaratywny template'owania, który nazywamy Cloud Formation do Infrastructure as Code. I co jest ciekawego, to poszli bardzo fajnie w GitOpsa. Czyli, że możesz synchronizować sobie tak, jak... To jest ciekawa układanka, bo możesz tak, jak synchronizujesz sobie Fluxa czy Argo, żeby zdeployować zasoby z repozytorium, tak teraz możesz podłączyć swój account, żeby ściągał deployment z repozytorium i syncował.

**Szymon Warda**: O ile nie jestem fanem Fluxa ani Argo, to to mi się podoba. Na tym poziomie synchronizacja naprawdę według mnie...

**Łukasz Kałużny**: Jest ciekawą rzeczą. Fakt, że będzie wymagał od Ciebie pewnie kombinowania, bo znając tą układankę i logikę, ale jest ciekawym konceptem.

**Szymon Warda**: Najwyższa wartość jest to, że to robi sam AWS, a nie używamy kolejnego narzędzia, które by za tą synchronizację odpowiadało. Czyli mniej utrzymywania. Mi to gra, zdecydowanie. Co dalej? A rzeczy aplikacyjne, bo też widzę, że masz ogłoszenie odnośnie Lambdy, że nagle będzie 12 razy szybsza, co jest dużym bardzo ogłoszeniem i będzie skalowała się.

**Łukasz Kałużny**: I będzie skalowała się 12 razy, tak. Czyli poszli w jeszcze lepszą skalowalność tego.

**Szymon Warda**: I tak żeby dodać trochę liczb, co rozumiałem przez to, że będzie skalowała się 12 razy szybciej, próbkowanie jest, zwiększanie ilości 1000 instancji co 10 sekund, jakoś tak, co 10 sekund de facto, aż dobijemy do limitu konta albo limitu subskrypcji.

**Łukasz Kałużny**: Konta i regionu, konta i regionu.

**Szymon Warda**: Tak, 1000 równoległych wykonań, co 10 sekund próbkowanie. Całkiem fajne skalowanie bym powiedział.

**Łukasz Kałużny**: Tak, jest to druga ciekawa rzecz. To są całe zabawki z endpointami do Lambda, też się tam rozwija. Z takich ciekawych rzeczy, to endpointy do step functions, to chyba też masz Szymonie?

**Szymon Warda**: Tak, taki odpowiednik integracji z Logic Appsów tak naprawdę, żeby porównać z Azurem.

**Łukasz Kałużny**: I teraz patrząc się na to, jak kleimy rozwiązania albo chcemy dostarczyć na szybko, to naprawdę spoko funkcjonalność, że możemy do tego flowu się odwołać, wreszcie w różne miejsca flowu po prostu przez HTTPS-a.

**Szymon Warda**: Ale nie wiem czy zwróciłeś uwagę na to, jakie są te integracje? To są integracje do providerów płatności i tego typu rzeczy. Co fajnie pokazuje gdzie jest korpbiznes AWS-a. To są różne, przeróżne startupy. To są różne instytucje, które są B2C tak naprawdę, bo oni potrzebują. Czy Enterprise potrzebuje integracji z providrami płatności kart kredytowych? Nie za bardzo. Ale to fajnie pokazuje ten rozrzut, że Azure jest taki dużo bardziej korporacyjny, a AWS tam sobie te startupiki, itd., których jest od groma i na tym też ma dużo Enterprise'u. Ale mimo wszystko, kto jest jego głównym graczem?

**Łukasz Kałużny**: Dobra, to kolejna rzecz i to jest kurde ciekawe i z jednej strony przerażające, bo nie wiem jak jest to możliwe, bo idzie się zabić. Założenie jest takie, żeby zrobić coś takiego jak consol to code. Czyli co sobie wyklikasz na swoim account'cie, w uproszczeniu, zostanie zautomatyzowane za pomocą Gen AI-a i wyplute jako IaC.

**Szymon Warda**: To ma jakiś tam sens. Pytanie, czy to będzie template'ing czy coś więcej?

**Łukasz Kałużny**: Ludzie, którzy się znają na AWS-ie, potrafią się gubić w tej konsoli, chyba nawet bardziej niż w Azure'owej, jeżeli popatrzymy, więc to jest ciekawa rzecz. Dobra. Z pierdół jeszcze, zanim przejdziemy do core'u, którego jeszcze nie poruszyliśmy, AI-owego, to AWS wypuścił swój kawałek grata Tiny Clienta, czyli malutkiego komputera z ARM-em, żeby łączyć się do swojej usługi Amazon Workspace i Upstream, czyli wirtualnych desktopów.

**Szymon Warda**: Czyli ten sam ruch, o którym mówiliśmy w poprzednim odcinku odnośnie tego, czy będziemy pracowali na terminalach de facto.

**Łukasz Kałużny**: Tak, w świecie Microsoftowym tego sprzętu dużo istnieje, więc Microsoft pewnie nie zrobi Surface Tiny Clienta. No a w Googlu mamy te Chromebooki, które ciągle mają się dobrze w edukacji.

**Szymon Warda**: Tak, Azure ma swoje terminale, które Dell klepie takie, które są de facto terminalami i się integrują po prostu dobrze.

**Łukasz Kałużny**: Fajna rzecz jest z provisioningiem, bo przy zamawianiu masz od razu klucz i przypięte do swojego accounta. Więc provisioning tego jest pięknie tutaj przemyślany.

**Szymon Warda**: Dla pewnych organizacji na pewno będzie to super. Ponownie, to jest dla korporacji.

**Łukasz Kałużny**: Tak. Dobra, co Ci jeszcze zostało?

**Szymon Warda**: Wiesz co, zostały tak naprawdę te wszystkie rzeczy AI-owe do omówienia. Ale tego już dużo nie ma tak naprawdę bym powiedział. Nic już mną tak nie ruszyło za zabrdzo. Sorry, jeszcze na rzecz - storage. Zwiększyli prędkość storage'u. I to, co mi się podoba, to jest właśnie S3 Express One, czyli storage, który jest, po pierwsze, w pojedynczych milisekundach dostępu. Jest 50% tańszy, jeżeli chodzi o requesty, ale 7 razy bardziej kosztowny, jeżeli chodzi o storage. I co mnie zdziwiło,? Bo zakładałem, że cennik będzie dokładnie odwrotny.

**Łukasz Kałużny**: tak.

**Szymon Warda**: Ale jest.

**Łukasz Kałużny**: I największa wada, nie róbcie tego na produkcji, jak nie macie powodu, Single-AZ.

**Szymon Warda**: Tak, czyli Availability Zone, trochę w jednym miejscu, ale dlatego, że te dane po prosu muszą być w innym miejscu, więc zapisywanie, itd., to wszystko musi dziać się szybciej, jeżeli nie zrobimy georeplikacji w pojedynczych milisekundach. Fizyka na to na razie nie pozwala. Dobrze.

**Łukasz Kałużny**: To z AI-a były takie dwie ważne rzeczy, które powiedzieliśmy. Wcześniej jedną powiedzieliśmy, trzeba powiedzieć wprost. Czyli z jednej strony Amazon nastawia się na hostowanie różnych opensource'owych i komercyjnych modeli i wystawianie tego as a service w ramach swojej usługi AWS Bedrock. I druga rzecz, Amazon Q...

**Szymon Warda**: Który tak trochę się nie pokazał na tej prezentacji do końca. Bardzo mieszane uczucia. Chyba nie wypaliło tak bardzo jak AWS na to liczył, że będzie ładnie i pięknie.

**Łukasz Kałużny**: Teraz o co chodzi? Żeby Wam pokazać, ja też poczytałem sobie newsy i ludzie są w niektórych miejscach przestraszeni. Czyli dostajemy z jednej strony asystenta do budowy Copilota, nazwijmy to asystenta, czyli narzędzie do budowy Copilota dla Ciebie. Z drugiej strony Copilot dla AWS-a, żebyś nie klikał tylko wpisał, że chcesz coś zrobić. I ludzie już się zastanawiają jak tam prompt injection, to już jest teraz, była duża dyskusja czy będzie można obejść IAMA czy nie, w zależności jak to będzie zrobione. I potem, co jest de facto, Microsoft ma swojego Power BI, czyli dashboardy do Business Intelligence. I tutaj, tak jak zresztą MS to robi, czyli nakładka na Quicksighta właśnie, czyli prosty Business Intelligence od AWS-a. Czyli wygeneruj mi z takiej takie dane i na podstawie tego co mamy podłączone powinien zbudować nam insight i inne rzeczy.

**Szymon Warda**: To jest genialne, używanie AI-a, żeby pozwolić na wykorzystywanie naturalnego języka do zapytań odnośnie logów, telemetrii, danych, itd.

**Łukasz Kałużny**: Czy danych biznesowych. Jeżeli masz dobrze zrobione metryki i to jest bardzo ważne, jeżeli masz dobrze zrobione metryki biznesowe to wpuszczenie zwykłego użytkownika jest super, ale pod warunkiem, że te miary tam w środku są realnie zdefiniowane na naszych hurtowniach.

**Szymon Warda**: Ale z reguły te dane biznesowe to jest jeden wielki pierdolnik [niesłyszalne 00:30:07] wielu lat, wielu systemów, itd. Więc tam taki AI to jest fajna rzecz. To co mnie martwi to jest to, na ile te kwerendy będą dobre, na ile faktycznie będziemy widzieli, że dostaliśmy to, o co się pytaliśmy.

**Łukasz Kałużny**: Dlatego na dobrze zadbaną hurtownię można z czymś takim wpuścić człowieka.

**Szymon Warda**: Według mnie to jest taka opcja, że za chwilę dojdziemy do tego, że one nie będą zwracały danych, tylko będziemy mogli zaznaczyć po prostu opcję "pokaż mi kwerendę" i będziemy tak to weryfikowali do danych krytycznych.

**Łukasz Kałużny**: Ty będziesz weryfikował. Ale zobacz, że chcesz posadzić od tego... Te narzędzia są nie dla IT, tylko dla biznesu.

**Szymon Warda**: Który potem, doskonale wiemy, jak biznesowi daje się narzędzia, to potem zaczynają ukłądać raporty, nie pytajmy się IT i nagle mamy system, który jest na produkcji, który jest niezabezpieczony. Takie przypadki też już były nie raz.

**Łukasz Kałużny**: Lećmy sobie, jeszcze dwie rzeczy i dwie ostatnie rzeczy, które spina. Jest tam centralka telefoniczna Amazon Connect, więc wpina się w budowę sobie Call Center Service Desku, na wsparcie. I druga usługa, która jest ciekawa, to mamy AWS Supply Chain. Nie mylić z atakami, tylko z faktycznym zarządzaniem dostawą, bo jest to robione jako taki know-how, udostępniają produkt w ramach AWS-u. I tam również zostanie władowane do m.in. właśnie eksploracji jakichś przypadków, what-if i innych takich rzeczy.

**Szymon Warda**: Mi się to podoba, bo to nie jest pierwszy raz, kiedy oni adresują problemy w ogóle całego tego łańcucha zależności dostaw jakie mamy. I to jest cholernie trudny problem, jak się na to spojrzymy.

**Łukasz Kałużny**: Dlatego ten Q nie jest wow, ale w kontekście tej usługi Connect i Supply Chain dla klientów, którzy z tego korzystają, to może być wow.

**Szymon Warda**: Tak, to nie zmieni życia, ale to jest ok. Spora odpowiedzialność, spore ryzyko korporacyjne, które mamy nagle odpada po prostu. I to może być ten element, którego normalnie nie patrzymy tworząc aplikacje, itd. Ale jak patrzymy na zakupy, decydowanie się na chmurę, to może być ten element, który mówi, że okej, bierzemy to, bo to ma ten feature de facto, no nie? I to jest bardzo fajna opcja.

**Łukasz Kałużny**: Dobra, masz jeszcze coś z niusów?

**Szymon Warda**: Tyle.

**Łukasz Kałużny**: Dobra, to taka myśl kończąca jeszcze Wernerem na temat LLM-ów i Gen AI-a. To, że LLM-y nie są srebrną kulą AI-a.

**Szymon Warda**: Co miał powiedzieć jeżeli nie mają swojego dużego LLM-a? Sorry, to jest to samo co powiedział Ballmer, który wyśmiał pierwszego iPhone'a. Nie może powiedzieć nic innego.

**Łukasz Kałużny**: Wiesz co? Dokładnie. Aczkolwiek jedno takie po całości przemyślenie, właśnie LLM w niektórych przypadkach może, jak dobrze go użyjesz, może być tą srebrną kulą jeżeli chodzi o początek wejścia. Bo i w przypadku NLP, teraz budowanie customowych modeli, no sorry, prawdopodobnie traci rację bytu cały Natural Language Processing, ale pracy na liczbach nam nie zastąpi.

**Szymon Warda**: To jest trochę tak samo jak jest z iPhonem. Ten pierwszy iPhone był fajny, był mocno okrojony. Wydaje mi się, że czekają nas ciekawe iteracje i ciekawe kilka lat rozwoju tego całego rynku. Czy są srebrnym pociskiem? Nie, nie są, ale są bardzo bliskie, na pewno się błyszczy ten pocisk z LLM-u na chwilę obecną.

**Łukasz Kałużny**: No dobra i tym kończymy.

**Szymon Warda**: Dobra, na razie.

**Łukasz Kałużny**: Na razie.

