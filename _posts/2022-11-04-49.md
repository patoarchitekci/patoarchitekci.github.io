---
layout: post
title: '#49 Patoarchitekci Short #10'
date: 2022-11-04 08:00:00 +0200
description: 
img: "49"
tags: 
spreaker: 51778363
---




Ciekawe linki i inne znaleziska z tego odcinka:
* [Apache Kafka 3.3 Replaces ZooKeeper with the New KRaft Consensus Protocol]( https://www.infoq.com/news/2022/10/apache-kafka-kraft/)
* [Redpanda](https://redpanda.com/)
* [State of AWS security - raport](https://www.datadoghq.com/state-of-aws-security/)
* [Sustainability workload documentation]( https://learn.microsoft.com/en-us/azure/architecture/framework/sustainability/)
* [SEC Proposes Rules to Enhance and Standardize Climate-Related Disclosures for Investors](https://www.sec.gov/news/press-release/2022-46)
* [ Mandatory Carbon Reporting — 6 Ways Companies Can Prepare](https://nbs.net/the-shift-to-mandatory-carbon-reporting-6-ways-companies-can-prepare/)
* [Streamlined Energy & Carbon Reporting](https://www.pwc.co.uk/services/audit/non-financial-assurance/streamlined-energy-and-carbon-reporting.html)




### Transkrypcja

**Szymon Warda [SW]**: Cześć! Słuchacie Patoarchitektów short. Prowadzą Szymon Warda

**Łukasz Kałużny [ŁK]**: i Łukasz Kałużny. Wszystkie linki do tego odcinka znajdziecie na: patoarchitekci.io/49. Wczoraj zakończyła się rejestracja na nasz urodzinowy meetup, więc jeśli się rejestrowaliście, to pamiętajcie, że jest 9 listopada. Dodatkowo z okazji 50. odcinka (który jest już za tydzień) zbieramy pytania do sesji AMA (Ask Me Anything). Link znajdziecie też w opisie.

**SW**:Dobrze, Łukaszu, lecimy z linkami. Co wygrzebałeś?

**ŁK**: Zastanawiam się, od czego zacząć. Zacznijmy od rzeczy od słuchacza. Michał nam wspomniał, że biadolimy na Kafkę i ZooKeepera.

**SW**: Słuszna uwaga.

**ŁK**: I… Tak, słuszna. Mamy swoje preferencje. Może trzeba się będzie któregoś razu na Google Cloudzie powyżywać i też na niego pobiadolić… Dostaniemy pewnie ciekawe rzeczy. Ale wracając – Michał podesłał rozwiązanie, które się nazywa Redpanda. I to jest dla Was do zerknięcia jako ciekawostka. Jest to platforma do streamingu, która jest kompatybilna z Kafką. Została przetestowana przez Jepsena, więc ma zapewnioną spójność. I co najlepsze – jest reklamowana jako JVM-free, Zookeeper-free i jest ponoć 10 razy szybsza i 6 razy wydajniejsza. Ciekawe liczby. Patrząc na użytkowników, jest wśród nich Akamai. Więc jestem ciekaw, co to jest, jak to wygląda i z czym to się je. Będę na to z ciekawości zerkał.

**SW**: A ja jestem ciekawy, kosztem czego to jest. Bo to nie jest tak, że wydajność jest za darmo za każdym razem, tylko coś musiało być depnięte. Nie mówię, że to jest zła decyzja, ale też się przyjrzę.

**ŁK**: No i jestem ciekaw. Może nie ma query, a może niektóre wzorce, które są wykorzystane, nie funkcjonują… Więc, tak – do sprawdzenia. I przy okazji naszego biadolenia na ZooKeepera – to jest bardziej istotny news, który był pierwszym, o którym chciałem powiedzieć – to… oficjalnie, z ostatnim wydaniem Kafki, którą mamy (3.3.1) najważniejszy ficzer, KRaft, czyli Kafka Kraft, zastępuje już oficjalnie ZooKeepera.

**SW**: O! Krok w dobrym kierunku. Późno…

**ŁK**: Tak.

**SW**: No późno, ale… Mimo wszystko.

**ŁK**: Mimo wszystko. Szymon, koniec, nie możemy już biadolić. Bo to była chyba nasza główna rzecz, oprócz ociężałości Ops-owej, która i tak w dużych brokerach zawsze występuje w dump czy smartach, nie ważne. Ale ten ZooKeeper wyleciał, a więc koniec biadolenia.

**SW**: Tak, dobra. To też się pochwalę dwoma linkami. Jeden będzie trochę rozbudowany. I trochę przerażający. Datadog – platforma, która swego czasu służyła głównie do monitorowania infrastruktury, teraz właściwie służy do monitorowania już wszystkiego - wydali swój raport: State of AWS Security. Niektóre rzeczy są lekko niepokojące, nazwijmy to delikatnie. Mianowicie, kilka liczb. 40% organizacji ma użytkowników z dostępem do konsoli bez żadnego MFA.

**ŁK**: (śmiech)

**SW**: To jest straszne, ale lecimy dalej. 23%, czyli prawie 1/4 organizacji, ma usera, który użył credentiali roota. A root w AWS-ie to może być wszystko.

**ŁK**: To główne konto, główne konto organizacyjne.

**SW**: Tak. Użył credentiali roota w ciągu ostatnich 30 dni.

**ŁK**: 23%, bo chyba nie padło.

**SW**: Tak, 23.

**ŁK**: 23

**SW**: Czyli 1/4, praktycznie.

**ŁK**: Dla mnie te dwie statystyki… Bo trochę spoilerując resztę. Spoilerujac jeszcze ostatni, będzie ciekawe, co powiesz, ale te 2 pierwsze staty są przerażające. Na zasadzie: „Nie kontrolujemy tego, co robimy”.

**SW**: Organizacje nie kontrolują tego w ogóle. To jest tak.

**ŁK**: Tak, tak. Ale w sensie takim…

**SW**: To jest takie podejście do security na poziomie: „A, możemy wszystko…”.

**ŁK**: Możemy wszystko, tak. To jest… przerażające, a zarazem arcyciekawe.

**SW**: Tak. Idziemy dalej. Uwierzytelnianie, jeżeli chodzi o AWS-a, opiera się najczęściej na access keys - to są po prostu klucze tak naprawdę. No i jak GitGuardian w 2022 robił badania, to na 10 000 commitów mniej więcej 84 wyciekały credentiale AWS-owe. To jest… duża liczba. Ja powtórzę: to jest commity, nie push. Commity pojedyncze.

**ŁK**: Właśnie ja tak… Ja patrzę na commity, bo to nie są… Tak.

**SW**: To nie są pushe, to są questy.

**ŁK**: Reguesty. Tak. Commity. Pojedyncze. Kurde…

**SW**: Więc wliczamy w to refactory, wliczamy w to drobnicę, wliczamy w to naprawdę małe rzeczy i na 10 000 commitów 84 wycieka cedentiale AWS-owe. I teraz…

**ŁK**: To jest dużo.

**SW**: To jest dużo. I teraz idziemy dalej. 75% użytkowników, którzy się uwierzytelniają kluczem, ma klucz starszy niż 90 dni. To jest straszne w kontekście tego, jak to łatwo wycieka. I 10% organizacji ma aktywne konto roota z access keys. Nie z credentialami, a z access keys.

**ŁK**: Dobra, akurat z tym rootem, gdzieś tam jestem jeszcze parę rzeczy sobie w stanie wyobrazić. Aktywne konto roota z access key - dobra, jestem w stanie sobie gdzieś to wyobrazić. O tak, scenariusze były. Pewnie ktoś technicznie nas poprawi, gdzie są potrzebne, gdzie nie przy pewnych automatyzacjach. Ale te klucze, w szczególności developerów, starsze niż 90 dni, przerażają. Bo rozumiem automatyzację, bo mówi się, że 180 przy automatyzacjach. Teraz mówimy 180 dni. Jak popatrzymy best practice rynkowych, że co 6 miesięcy powinniśmy zmieniać klucz, jeżeli… Przy CI/CD czy innych takich rzeczach.

**SW**: Tak, ale na automatyzacjach z reguły lecisz kontami technicznymi, które mają bardzo wąskie uprawnienia, nic nie mogą zrobić.

**ŁK**: Tak. A to sobie leży na Twoim laptopie, na Twojej stacji developerskiej.

**SW**: I to często leży też w… Musi być albo jest często w katalogu projektu, tylko po prostu jest ignorowane albo odcheckowane, że tego nie pushujemy tym razem. Więc to jest na prawdę straszne. I jeszcze ostatnie, mianowicie: Instance Metadata Service w wersji 2. On miał nieco podbić jeżeli chodzi o bezpieczeństwo i trudność wyciekania kluczy z dostępem do EC2. To nie jest włączone domyślnie i jest bardzo małe jego użycie. Tak że… powiem tak… Zacząłem czytać i myślałem: „E! Będzie taki słaby raport, nic tam się ciekawego nie dowiemy. Ale, muszę powiedzieć, że przeraziło mnie to trochę”.

**ŁK**: Dobra.

**SW**: Drugi link. Drugi jest ciekawy, bo trochę nawiązuje do tego, co mówiliśmy chyba parę odcinków temu, parę miesięcy temu.

**ŁK**: Coś było, tak. CO carbone footprint, bo trochę z tego… Z jednej strony, że niby potrzeba, z drugiej naśmiewajki…

**SW**: Tak. I przewidywałem, że to zacznie się pojawiać i zaczniemy być z tego rozliczani, ponieważ instytucje kontroli giełdy amerykańskiej będą tego wymagały. I co się stało? Microsoft ma tak naprawdę 2 duże frameworki. Takie organizacyjne, nie chodzi o kod. CAF i WAF. I do WAF-a właśnie został dodany sustainability obszar. Czyli ten 6 wymiar WAF-a. Więc jakby nie patrzeć, powoli ten temat się toczy i wydaje mi się, że będzie się toczył i od niego nie uciekniemy. I czeka nas branie w budżety finansowe też budżety carbonowe. Jakiekolwiek by zdanie o tym nie mieć, jak to wygląda, cały rynek wokół tego obszaru i tego rynku, to wydaje mi się, że mimo wszystko tylko czeka na to, aby zobaczyć, jaki będzie nasz carbon footprint.

**ŁK**: No tak. Przepraszam. Dla mnie to wszystko… Nadal o tym będę mówił jako o green washingu, bo to jest… Z vendorów technologicznych szanuję ich, niech zajmą się - to jest teraz bardzo moja taka, zanim wejdę w technologię, moja opinia - bardzo fajnie, niech zajmą się wykorzystywaniem w Data Center zwiększaniem wskaźnika PUE, czyli tej efektywności energetycznej, wyrzucaniem chłodzenia na rzecz tak naprawdę wytrzymywania wysokich temperatur. To podejście też się dzieje. I władowywaniem tam ekologicznej energii.

**SW**: Tak, dokładnie. Żeby…

**ŁK**: Albo jądrowej, bo dla mnie akurat jest to bardzo kontrowersyjne. Ale atom jest ekologiczny w perspektywie skutków i potencjalnych skutków.

**SW**: Bym się z tym zgodził. Znaczy: atom jest nieunikniony, powiedzmy sobie szczerze.

**ŁK**: Tak.

**SW**: Ale dla mnie to też kolejny wymiar, czemu organizacje będą parły bardziej w kierunku chmury? Bo zrobienie takiego prawdziwego zero, właśnie jak mówiłeś. W sensie nie przez offsetting ani nie przez kupowanie. Na on-premisie będzie bardzo ciężkie.

**ŁK**: Tak, będzie. Tylko… Patrząc się, przypatrując sobie, co tam jest zrobione, mówienie teraz o tym właśnie… energy conclusion, carbon emition w kontekście architektury aplikacji. Bo to zakłada, że zaczynamy robić porządek z architekturą aplikacji. Szymon…

**SW**: Tak.

**ŁK**: Mamy zacząć porządnie kodować kod biznesowy.

**SW**: Łukasz…

**ŁK**: Tak jakby był high performensowy. Dlatego… (śmiech)

**SW**: Łukasz, powiem tak, dziwi mnie, że ty jeszcze żyjesz nadzieją, że będziemy porządnie kodowali kod biznesowy. Ja to, porzuciłem bardziej, po prostu trzeba to bardziej jakoś ogarnąć.

**ŁK**: Ja… nie… nie, nie, nie… Ja wiem, że jakoś ogarnąć. Tylko porównuję to, bo jeżeli sobie teraz popatrzymy, tak realnie. Wpływ, który ma aplikacja na carbon footprint, oznacza, że pobiera mniej energii.

**SW**: Tak, dokładnie tak.

**ŁK**: Weźmy sobie teraz Javę, C# i kochanego Reacta czy Angulara na froncie. Tam nie ma miejsca na energooszczędność.

**SW**: Znaczy nie. Dla mnie to się wiąże z tym samym, jaka jest idea chmury. Czyli… większe parcie w kierunku rozdziału konsumpcyjnego, serverlessa i tego, aby aplikacje nie chodziły cały czas.

**ŁK**: Tak.

**SW**: Bo nie oszukujmy się - kod to jest kod. Ale jeżeli będziemy skalowali w dół albo wyłączali usługi na pozostałe 12 godzin (lekką ręką, już mówię korporacyjne pozostałe 12 godzin), to nie ma większej oszczędności jaką możemy zrobić. Nie ma.

**ŁK**: Tak, dokładnie. To optymalizacja. Bo sobie zaznaczyłem… Patrząc, najbardziej dowcipną rzeczą, która jest tutaj pod spodem, na temat wykorzystania tych zasobów: zrób ewaluacje przeniesienia się z monolitów na mikroserwisy.

**SW**: Tak.

**ŁK**: Więc, dlatego trochę patrzę na to, jak na… Będę patrzył w niektórych miejscach… Niektóre są dobre, np. żeby przejść na Async. Faktycznie, to działa. Czy server-side versus client-side rendering –kiedy to wykorzystywać, czy jak ma wyglądać ten UI. To są fajne rady, ale część jest pokryta tak naprawdę green washingiem.

**SW**: Zgadza się. Dla mnie to jest po prostu znak, że temat się będzie toczył. Czy to jest ostateczny wymiar, jak to będzie wyglądało? Nie, nie jest. To będzie się zmieniało. Ale to znaczy, że… będzie to… będziemy pewnie musieli brać to pod uwagę. Mniej lub bardziej. Pewnie wiadomo, jak wiele tematów w IT zostanie przerobione i pogwałcone w sposób, że nie poznamy tego za 2-3 lata, ale no… będzie się działo.

**ŁK**: Jestem jednego ciekawy, bo jak powiedziałeś o tym, gdzieś tam idącym sobie raportowaniu, które prędzej czy później to dopadnie… Jak bardzo potem dostawcy usług, czyli jak szeroko to jedno miejsce rozleje się na… Takie regulacje z giełdy rozleją się dalej, jeżeli zacznie się takie raportowanie.

**SW**: Rozleją się, bo to ma być wymagane od dostawców. Więc rozleje się nawet na prywatne firmy. Dobrze. Bo się przedłużamy. Kończymy.

**ŁK**: Kończymy.

**SW**: Trzymajcie się.

**ŁK**: No to co, na razie, hej!