---
layout: post
title: '#69 Wprowadzenie do Event Sourcing z Oskarem Dudyczem'
date: 2023-04-07 08:00:00 +0200
description: 
episode: "69"
tags: []
spreaker: 53460484
---


Linki i ciekawe znaleziska:

- [Beginner's Guide to Event Sourcing  ](https://www.eventstore.com/event-sourcing)
- [Event-driven startup - Alexey&#39;s place](https://zimarev.com/blog/event-sourcing/startup-story-1/)
- [](https://event-driven.io/en/optimistic_concurrency_for_pessimistic_times/)
- [[KAFKA-2260] Allow specifying expected offset on produce - ASF JIRA](https://issues.apache.org/jira/browse/KAFKA-2260)
- [Marten  ](https://martendb.io/)
- [EventStoreDB - the state-transition database for data-driven businesses](https://www.eventstore.com/)
- [](https://event-driven.io/en/lets_build_event_store_in_one_hour/)
- [](https://event-driven.io/en/)
- [](https://www.architecture-weekly.com/)
- [Event Store Blog](https://www.eventstore.com/blog)
- [Beginner's Guide to Event Sourcing  ](https://www.eventstore.com/event-sourcing)
- [](https://event-driven.io/en/never_lose_data_with_event_sourcing/)
- [](https://event-driven.io/en/when_not_to_use_event_sourcing/)
- [](https://event-driven.io/en/event_streaming_is_not_event_sourcing)
- [](https://www.youtube.com/watch?v=Lu-skMQ-vAw)
- [](https://leanpub.com/esversioning)
- [](https://event-driven.io/en/simple_events_versioning_patterns/)
- [](https://event-driven.io/en/event_versioning_with_marten/)
- [Keep your streams short! Temporal modeling for fast reads and optimal data retention](https://www.eventstore.com/blog/keep-your-streams-short-temporal-modelling-for-fast-reads-and-optimal-data-retention)
- [](https://www.youtube.com/watch?v=gG6DGmYKk4I)
- [GitHub - oskardudycz/EventSourcing.NetCore: Examples and Tutorials of Event Sourcing in .NET](https://github.com/oskardudycz/EventSourcing.NetCore)

### Transkrypcja

Osoba mówiąca 1
Cześć Słuchacie Patoarchitektów prowadzą Łukasz Kałużny.

Osoba mówiąca 2
I Szymon Warda. Wszystkie linki do odcinka oczywiście trochę ćwierkają. Slash 69.

Osoba mówiąca 1
No dobra Szymonie, to dzisiaj o czym dziś będzie?

Osoba mówiąca 2
I chyba ulubiony temat do nabijania kiedyś, ale dzisiaj będzie wiecej poważnych.

Osoba mówiąca 1
I robimy wprowadzenie. Wzięliśmy osobę, która pomoże nam dzisiaj i odpowie nam na nasze pytania, wątpliwości i rzeczy, z których też się nabijamy. Zaprosiliśmy osobę, którą u mnie w telefonie jest taką właśnie jeżeli chodzi o event casting albo trudne projekty, gdzie ktoś coś rozważyć? Event source i to jest taki numer jeden w moim telefonie, żeby zadzwonić albo napisać i jest z nami dzisiaj Oskar Dudek. Oskar udziela się bardzo sporo na temat event, co zasięgu był listą event. To, że jest darem Martina, czyli event castingu dla dotnet z wykorzystaniem SQL a + stworzy dużo opensource'owego rzeczy, przykładów i hejtuje trochę technologie pokazując, że powinniśmy robić to prościej i logiczne. I co jest z naszym podejściem bardzo zgodne z tego jak my widzimy technologię.

Osoba mówiąca 3
Cześć siatkarze! Cześć! Dzięki. Aż się zarumieniłam. Bardzo ładne wprowadzenie. Dziękuję bardzo. Delikatnie ująłeś to, że gdzieś tam się pojawiają w event Source. Ja już mam wrażenie, że niektórzy chyba tylko w lodówce mnie widzą jak otwierają.

Osoba mówiąca 2
Raczej jesteś synonimem castingu jak się wpisuje casting, ponieważ Ty to się zgadza.

Osoba mówiąca 1
Dokładnie jak i powoli. Dear jest trochę pokodujesz.

Osoba mówiąca 3
Ja się śmieję, że jestem wierzącym praktykującym.

Osoba mówiąca 2
Dobre to jak mamy mówić o castingu? Przejdźmy do konkretów. To w takim razie wytłumacz event Cold Ink. Czy można tłumaczyć casting jak dla pięciolatka albo dla biznesu? Jedna? W sumie to same można powiedzieć, że ok.

Osoba mówiąca 3
Więcej. To najpierw pierwszym pytaniem, które mogłoby paść jest Czy wiesz jak działa księgowość? Jeśli odpowiedź brzmiała tak, to musisz od razu powiedzieć to wiesz jak działa event scoring. Ale żeby nie iść na łatwiznę, to event surfing. Jest to wzorzec wytwarzania oprogramowania, w którym wynik każdej operacji biznesowej powinniśmy zapisać I co więcej, przy podejmowaniu kolejnej decyzji powinniśmy pobrać wszystkie te nasze poprzednie decyzje dla danego obiektu biznesowego, czyli po prostu użytkownika, koszyka zakupowego itd. I dopiero na tej podstawie uzyskać nasz stan wiedzy i podjąć kolejną decyzję i zapisać kolejny fakt. I tymi faktami są właśnie zdarzenia. I nazwa event something pochodzi z tego, że właśnie zdarzenia są naszym źródłem prawdy. To tak wysoko poziomowy tak bym to mógł powiedzieć. Nie wiem czy to by biznes zrozumiał, ale no właśnie.

Osoba mówiąca 1
To jest zawsze ciekawe. Z księgowością jest to chyba genialne porównanie, ale event jest jak właśnie księga przychodów i rozchodów pełna.

Osoba mówiąca 2
Ale to jest księgowe gdzieś tam stwierdzą, że aby edycja przodka przydała się, ale ogólnie rzecz biorąc tak.

Osoba mówiąca 3
Ja jak pracowałem w module księgowym to nasz biznes nam mówił, że możemy robić co chcemy dopóki na koniec dnia się wszystko zgadza.

Osoba mówiąca 1
Tak dobre. Słuchaj Oskar, a gdybyśmy zeszli bardziej technicznie do event surfingu, czyli powiedzieliśmy sobie to jest ta prosta definicja. A dla osób, które jednak są techniczne, jakbyś zdefiniował event source.

Osoba mówiąca 3
To może też spróbuję najpierw od takiej prostej, prostackiej definicji, czyli tej najprostszej definicji technicznej. Event scoring jest to wzorzec taki przechowywania danych, czyli mamy tam dwie struktury danych zdarzenie, które jest tak jak mówiłem, jakimś faktem biznesowym zapisanym po każdej operacji biznesowej, czyli po każdej logice i mamy strumień zdarzeń, gdzie strumień to jest taka uporządkowana sekwencja. Kluczowym aspektem event scoringu jest takie coś jak event store i event store. To jest właśnie baza danych, to podkreśla baza danych właśnie do przechowywania zdarzeń. No i event story z założenia to są takie bazy klucz wartość, gdzie kluczem jest identyfikator strumienia. Czyli to można porównać do zwykłego klucza w bazie relacyjnej, a naszymi danymi jest po prostu sekwencja zdarzeń. Czyli zamiast trzymać jeden spłaszczony stan to trzymamy całą historię tego, co się wydarzyło dla naszego obiektu. No i to tak wydaje mi się. To jest tak najprościej, jakby to można było. Grywalizacja nieco event surfingu, ale w praktyce tak to wygląda.

Osoba mówiąca 1
Jeszcze pytamy się o szczegóły.

Osoba mówiąca 2
Mówiłeś dużo o zdarzeniach. Odchodzili więc pricingu to teraz naturalnym elementem, który jest de facto pytaniem chodzi. A jak się to ma i czy jest jest możliwe bez drugiego? I w którą stronę jest zależność?

Osoba mówiąca 3
To różnie ludzie mówią. Według mnie to event surfing jest jednym z wzorców architektury opartej na zdarzeniach. Ale gdzieś tam na granicach, powiedzmy event architecture, bo event surfing jest o tym jak najlepiej i jak najwydajniejsze rejestrować i potem utrwalać te wszystkie właśnie fakty, te zdarzenia, które się wydarzyły w naszym systemie. Z kolei event driven architecture to jest jak łączyć ze sobą poszczególne elementy, jakiś workflow procesów biznesowych, czyli event something, to jest trwałość danych, a z kolei Event Driven Architecture skupia się na tym, jak orkiestrą łączyć ze sobą poszczególne fragmenty systemu przy pomocy zdarzeń, czyli bardziej dane w ruchu niż dane utrwalone.

Osoba mówiąca 1
Czyli jak na to popatrzymy, to event source jest bardziej wzorcem składowania danych niż samym tym frontem, do którego wszyscy się przyzwyczaili? Wypada i tak.

Osoba mówiąca 3
Zdecydowanie event source. W każdym razie w moim rozumieniu głównie skupia się na modelu zapisu, czyli jak najlepiej przeprowadzić naszą logikę biznesową i zapisać fakty i event source. Event Story daje nam możliwość publikowania informacji o tym, że nowe zdarzenie się pojawiło. I to jest ten element, który jest punktem styku z event driven architecture. Ale wszystko co potem się dzieje to już tak naprawdę nie ma znaczenia, czy my mamy event, surfing, czy bazy relacyjne, czy bazy dokumentów. Wszystkie te same problemy, czy też zalety architektury opartych na zdarzeniach będą takie same, niezależnie od tego, którego wzorca użyjemy.

Osoba mówiąca 2
Czy się zgadzamy? Przez wiele lat robiliśmy dobrze.

Osoba mówiąca 1
Super to jest teraz Oskar takie pytanie, które pewnie już nie raz usłyszałeś, bo ja chyba sam nawet i w projekcie mieliśmy taką kwestię tłumaczącą to wspólnie, czy wyobrażam sobie, bo jak słyszymy właśnie i więc Source i edit a całość jeszcze ludzie wyobrażają sobie, że będą posiadali jeden duży i Więc torus, którego wszyscy będą czytali, pisali. Będzie on uniwersalny i de facto dzięki temu to część asynchroniczne. Po kolei będziemy w stanie jakoś częściowo wyrzucić i zastąpić je po prostu takim event torem.

Osoba mówiąca 2
To też dorzucę, że to jest jedna z takich promowanych często skrzynek na konferencjach, że tak można zrobić de facto.

Osoba mówiąca 3
Wydaje mi się, że większość z tego wywodzi się z Kafki, którą ja nie uważam za event tour, w każdym razie nie w rozumieniu event source rynkowym, ale uwaga niestety też te narzędzia event source, singlowe np. Event Store DB Tak naprawdę można sobie uruchomić kilka klastrów, ale takim domyślnym rozwiązaniem jest jednak użycie tego jednego event stora. Więc musimy odróżnić tutaj dobrą praktykę od praktyki rzeczywistej i raczej dobrą praktyką jest to, żeby jednak traktować event source jako wzorzec wewnątrz modułowy. Ja go w ogóle nie nazywam wzorcem architektonicznym. To jest design pattern. Wzorzec obsługi, przechowywania danych to nie jest coś, co powinniśmy z założenia aplikować globalnie na wszystkie systemy, czyli tak jak wybieramy czy użyjemy w tym module bazę dokumentu ową czy bazę relacyjną oczekiwali Storm, to możemy dodać do tego równania też Event store event source, ale zdecydowanie nie uważam tego, że powinniśmy współdzielić, o ile nasze narzędzia na to nam pozwalają, że nie powinniśmy współdzielić bazy, szczególnie w takim systemie rozproszonym, bo jeżeli mamy monolit albo mniejszą skalę to ok, to możemy tak zrobić, ale.

Osoba mówiąca 2
W ramach modułu de facto.

Osoba mówiąca 1
To podsumujemy, że właśnie taki Mikroserwisach ma swój event store dedykowany swoją przestrzeń. I tak jak przy każdym mikro serwisie przy tym mówimy, że jest właścicielem tych danych i tylko on ma dostęp i odczyt do tej całej warstwy. Technicznie ileś tych event położymy na jednym infrastrukturalnym rozwiązaniu to jest zupełnie oddzielna kwestia.

Osoba mówiąca 3
Tak, zdecydowanie. Ja tutaj bym zalecał ogólnie te same praktyki, które stosujemy. Najlepsze co do tego jak dzielić i układać w pudełka nasze bazy danych w klasycznym podejściu.

Osoba mówiąca 2
To jeszcze jeden temat. Można powiedzieć, że trochę zacząłeś grupować go i jako potwierdzasz naszą szydera. Ale żeby tak zadać pytanie wprost bardzo mocno, bo już wiele lat ponabijamy. Event Fortnite, KFC tak czy nie?

Osoba mówiąca 3
No zdecydowanie nie.

Osoba mówiąca 2
A może wreszcie ktoś to potwierdził?

Osoba mówiąca 3
To znaczy ogólnie ja jestem, podkreślę od razu. Ja w ogóle używałem Kafki. Lubię Kafkę. To jest bardzo fajne narzędzie. Tak, ale nie do węgierskiego. I teraz dlaczego? Bo tak jak wspominałem, event something to jest o tym, jak trwale przechowywać dane i ogólnie trwale. To raczej mamy na myśli bazę danych. I jeżeli patrzymy na kawkę, to ona jest taką bazą danych. I jak moglibyśmy nazwać zapisywanie czegoś w pliku tekstowym bazą danych? Dużym naciągnięciu rzeczywistości? Moglibyśmy tak powiedzieć. Przyjmijmy załóżmy optymistycznie, że ona jest w stanie trwale te dane przechowywać. To niestety, ale Kafka sama w sobie brakuje takich elementów, które byśmy oczekiwali od inwestora. No bo tak jak wspomniałem, zależy nam na tym, żeby trwale przechowywać dane, umieścić event scoring raczej w modelu zapisu. Czyli powinno nam zależeć na tym, żebyśmy byli w stanie podjąć decyzję na bazie aktualnych danych, żebyśmy mieli gwarancję, że nikt w międzyczasie nam tego stanu nie zmienił. No ok, można sobie bez tego radzić, ale zdecydowanie to upraszcza. Jednak większość programistów jest do tego przyzwyczajony.

Osoba mówiąca 3
No i teraz tak Kafka nie ma czegoś takiego jak optymiści konkurencji. Czyli optymistyczna zbieżność. Jest taki ticket w grze, który ma oznaczony bardzo niski priorytet i jest to od iluś tam lat wisi. Więc optymistyczna współczesność Daje nam to gwarancję, że jeżeli dwie osoby zapisały w tym samym czasie, to ta druga dostanie informację, że to nie jest aktualny stan. W KFC nie ma takiej możliwości. No i teraz tak strumienie. I tu i tu mamy strumienie. Z tym, że w kawce nacisk jest na to, żeby ona jak najefektywniej przenosiła dane z jednego miejsca do drugiego. Więc one nie muszą być takie granulaty inne, bo powiedzmy mamy jakiś topik czy też partycję pod kontem modułu pod kątem rodzaju encji. Jak sobie to podzielimy to już jest też dłuższa dyskusja, ale raczej w event surfingu to jeden strumień zdarzeń powinien odpowiadać jednej instancji obiektu. Czyli tak mówiąc w nomenklaturze bazy relacyjnej jednemu wierszom. Tylko że tu mamy całą historię tego, co się dla niego wydarzyło. Nie jesteśmy w stanie tego zrobić w prosty sposób, bo Kafka ma maksymalną liczbę partycji, czyli fizycznie, gdzie możemy zagwarantować kolejność zdarzeń, która w event scoringu jest kluczowa.

Osoba mówiąca 3
To Kawce mamy 160 tysięcy partycji. W każdym razie na tyle, na ile ostatni raz patrzyłem, to 160 tysięcy w bazie danych rekordów. To jest raczej nieakceptowalne. Możemy to kasować, jakoś, umieszczać kilka rekordów na jednej partycji, ale z kolei surfingu. Gdy przywracamy stan, powinniśmy pobrać wszystkie zdarzenia, odbudować nasz domyślny stan i na tej podstawie sobie podjąć kolejną decyzję. To tutaj jeżeli byśmy harowali, to musielibyśmy pobierać wszystkie inne rekordy i tak można by w nieskończoność. Ja takiej dyskusji z jakimiś ewangelista migawki miałem dużo i koniec końców to się sprowadza, że ok, są w stanie wymyślić jakąś taki domek z kart, gdzie można byłoby te definicje event surfingu naciągnąć, ale pytanie po co, skoro są do tego narzędzia, które są dedykowane i robią to dobrze.

Osoba mówiąca 1
Więc dobra, realnie muszę Ci jednej rzeczy pogratulować, bo wpisałem sobie, żeby znaleźć ten numerek. Wpisałem sobie właśnie Kafka optymisty konkurencji i jest w googlu na pierwszym miejscu Twój wpis, w którym to dwa lata temu hejtuje się. Ja sobie wziąłem ten tekst, sprawdziłem. No to długo to wisi, bo już od 2015.

Osoba mówiąca 3
No więc to według mnie to jest ok i że tak wisi, bo dla mnie to pokazuje, że po prostu marketing mówi swoje, a specjaliści techniczni mówią swoje i oni wiedzą, że to dla nich to nie jest scenariusz użycia, który oni chcą promować. To, że marketing sobie promuje ten scenariusz, no to całe szczęście jednak Inżynierów Kafka ma sporo dobrych, choćby ten stop Ford itd. No ale to jest marketing.

Osoba mówiąca 1
A nie wielcy tego, który uprawia marketing. A co do.

Osoba mówiąca 2
Ciekawości jak myślisz skąd wzięło się to? Bo to jest dość dominujące podejście na rynku, że jeżeli mówimy o live castingu, to dużo osób domyślnie mówi okay, to zróbmy to na kawce. Masz story, skąd się wziął?

Osoba mówiąca 3
Mam kilka poszlak. Na pewno konsument ma olbrzymie zasoby, pompuje w marketing. I ja się śmieję, że tak jak niektóre partie prawicowe mówią na prawo od nas już nikt. To konsument mówi w świecie i wędruje na prawo od nas już nikt, więc oni wszystkie wzorce event driven chcą wciągnąć. Ale wydaje mi się, że. Ta oryginalna definicja, bo w sumie nikt nie wie, kto wymyślił event surfing. Greg jak się śmieje, że Sumerowie też tym swoim pierwszym. No ale ta pierwsza definicja i to Greg jak nawet mówi, że Martin Fowler tą definicję, która jest najbardziej popularna event surfingu, to ona jest taka, powiedziałbym nieco nieszczęsna w tym sensie, że ona jest bardzo nieprecyzyjna, więc można podciągnąć bardzo dużo, w tym właśnie to, że po prostu zapisujemy zdarzenia i je potem na sucho dajemy na nie, bo w większości przypadków tak to kiedyś było, choćby jakiś wzorzec obserwator powiadomienia. Wydaje mi się, że wszystko po trochę.

Osoba mówiąca 1
Cały ten Enterprise Integration Pattern, które gdzieś tam powstało na początku lat dwutysięcznych i całe SOA wtedy.

Osoba mówiąca 3
Tak? Wydaje mi się, że tak. Wszystko po trochę nie, ale najbardziej bym winił tutaj w ostatnich latach Marketing con fluent i no wiecie sami zresztą, bo przecież to wasz podcast jest o różnych patologiach i tak niestety nasze działa i wymyślamy sobie bazy Vardy i potem je pchamy dalej.

Osoba mówiąca 1
Raczej chyba jeszcze ktoś kupi ten support od konsumenta, co jest na kogo zwalać. Potem ratowanie tego.

Osoba mówiąca 3
I tak.

Osoba mówiąca 2
Po iluś tam latach to się prędzej czy później potęga się zawali.

Osoba mówiąca 3
Ale na usprawiedliwienie jest, że ja nie byłem, ale znam kogoś, kto był na Kafka Summit i tam nie ma takiego promowania event surfingu. Tam staje się dużo bardziej pragmatyczne.

Osoba mówiąca 1
No nie dziwię się. Słuchaj, to takie pytanie, jakie jesteśmy. Pogadaliśmy trochę technikalia. Wróćmy teraz może bardziej do takich wzorców użycia. I pierwsze takie pytanie, które się nasuwa, bo mówimy, że event jest fajny, ma dużo zawiłości i innych rzeczy, ale jest de facto prostym wzorcem, bo to mamy takie trochę sprzeczne komunikaty i jakbyś powiedział, gdzie on generalnie się sprawdza jako wzorzec właśnie tak jak powiedziałeś strategia w naszych aplikacjach i jak często odradzasz? A jak często mówiłeś, że to jest kierunek, w którym warto żebyście poszli, tylko zrobili to poprawnie?

Osoba mówiąca 3
Ja z założenia nie widzę takiej sytuacji z automatu, gdzie on by się mógł nie sprawdzić, ale widzę sytuacje, kiedy nie dałby jakieś dodatkowej wartości i przede wszystkim największą wartość to widzę tam gdzie mamy bardziej złożony proces biznesowy, czyli taki wielo krokowy, gdzie chcielibyśmy zrozumieć i mieć możliwość diagnostyki. Już nie mówię audytu, bo to możemy bez event marketingu zrobić, ale właśnie takiej diagnostyki i lepszego zrozumienia procesu, ewentualnie jeżeli byśmy chcieli mieć taki większy wkład w sensie takie dosyć granulacji informacje. Ja najczęściej używam takiego dosyć trywialnego, który wygląda nieco krańcowo scenariusza, czyli koszyk zakupowy. No i zobaczcie, że w koszyku zakupowym mamy tych kroków kilka, bo możemy dodać produkt, usunąć, potwierdzić, zdefiniować przesyłkę i tak dalej. I nawet jeżeli ten scenariusz jest dosyć prosty i wydaje się zróbmy Clouda, to zobaczcie, że z tych wszystkich danych choćby właśnie, które produkty były razem wybierane, które koszyki były opuszczone, biznes jest w stanie bardzo dużo ciekawych informacji wyciągnąć. Więc tak długo jak te informacje będziemy mieć trwale zapisane w naszej bazie danych, to potem możemy nawet do tyłu sięgnąć czy to biznes, czy to nawet my, bo możemy sobie wziąć sekwencję zdarzeń dla naszego rekordu jako programiści i po prostu nawet użyć do debugowania lokalnie, żeby zobaczyć, że ok, te pierwsze trzy zdarzenia wszystko szło dobrze, a przy czwartym się coś wywaliło.

Osoba mówiąca 3
Więc po pierwsze właśnie takie wielo krokowe scenariusze, przepływy i potem jako wkład do analityki danych, chociaż też niestety, ale jeszcze event story same w sobie nie mają takich wbudowanych narzędzi do analityki, więc do tego raczej trzeba użyć czegoś co jest dedykowane na kiedy się to nie sprawdzi. Wydaje mi się, że przede wszystkim się nie sprawdzi, kiedy czynnik ludzki jest oporny.

Osoba mówiąca 1
Wiedziałem, wiedziałem, miałem się o to zapytać, więc trafiłeś po prostu w sedno tego problemu, który ja widzę rynkowo.

Osoba mówiąca 2
A to teraz mówimy sobie, gdzie się sprawdzały, czy sprawdzało. Ogólnie event, event story, ale teraz myśmy tak podróżowali, co było wspólne na poziomie technicznym. Zejdźmy już na poziom mięsa. Generalnie jeżeli ma się udać, to co? A jeżeli ma się. To co wybierać to nie segregacja. Byśmy spojrzeli.

Osoba mówiąca 3
To takie składniki, które muszą zajść albo powinny zajść. Po pierwsze to niestety, ale czynnik ludzki i niekoniecznie to muszą być ludzie, którzy zjedli zęby na event surfingu, bo takich nie ma za dużo. Ale ludzie, którzy chcą się uczyć i ludzie, którzy jeżeli chcą się uczyć i nie mają czasu, to lepiej, żeby jednak był ktoś, kto cokolwiek z tym robił, żeby był w stanie wdrożyć innych. Jeśli mają czas, to tych materiałów się pojawia coraz więcej, choćby mój blog. Ależ technicznie ważną rzeczą jest to, żeby się też rozeznać odnośnie tych implementacji i torów, które są w danej technologii, w której pracujemy. Bo tak jak sam event surfing powiedziałem, jest wzorcem dosyć prostym. No ale to już też omówiliśmy, że dużo można to podciągnąć. No i na przykład Martin pod spodem ma post gres, więc dostajemy wszystkie te gwarancje, które daje nam baza relacyjna, czyli transakcyjną ilość, możliwość nawet odbudowy real modeli w tym samej transakcji co dodajemy zdarzenia. Z kolei Event Store DB bardziej celuje na skupienie na właśnie obsłudze samej zdarzeń i to jest baza, która została stworzona.

Osoba mówiąca 3
Nie ma żadnej innej pod spodem, ale też nie ma np. modeli odczytu. Nie ma możliwości jakiegoś hackowania i zapisywania zmian więcej niż jednym strumieniu, czyli więcej niż jednym agregacie w ramach jednej transakcji. Więc The Event Story potrafią się dużo różnić od siebie, więc to trzeba też sprawdzić, bo jeżeli mamy zespół, który się uczy, to może na początku to nie jest może idealna rada, ale jak się uczymy to raczej trochę poszukujemy i potrzebujemy sobie po zhakować. Więc może też użyjmy bazy albo rodzaju Tora, który nas tutaj jakoś nie uderzy w event surfingu. Bardzo ważne jest jednak, żeby zrozumieć te podstawowe aspekty modelowania, bo pamiętajmy, że to jest wzorzec przechowywania danych, czyli tak jak w bazach relacyjnych normalizuje dane w bazach, dokument normalizuje to w event surfingu musimy się nauczyć jak robić, żeby trzymać te strumienie jak najkrótsze, bo jak one będą krótsze, to wszystko będzie lżej, będzie łatwiej jest z nimi pracować, wydajność będzie lepsza. Więc event surfingu Tak naprawdę bardzo dużo jesteśmy w stanie problemów technicznych uniknąć poprzez odpowiednie modelowanie właśnie strumieni, Czyli już tak konkretnie mówiąc, zamiast na przykład trzymać strumień jako historię wszystkich transakcji w kasie w Biedronce, to może trzymajmy strumień jako odpowiednik jednej zmiany kasjera w Biedronce i nagle zamiast kilkudziesięciu czy kilkuset tysięcy zdarzeń będziemy mieć 100 500 w ramach jednej zmiany i to już będzie dużo bardziej zarządzane.

Osoba mówiąca 3
No więc to. No i potem dosyć ważną rzeczą jest jednak, żeby zrozumieć rzeczy związane, opisowe i DevOps owe, które w przypadku narzędzi marketingowych są nieco trudniejsze, bo one pod tym kątem są nieco mniej dojrzałe. Tak jak ogólnie event surfing, event story są już dojrzałymi narzędziami, to w przypadku tematów opisowych i DevOps to mają trochę więcej ostrych krawędzi. Znaczy mają wszystko to, co oczekujemy, ale może to być nieco trudniejsze.

Osoba mówiąca 1
Dobra jest jedna rzecz, która mi się tutaj przy tym jak powiedziałeś, bo bodajże to chyba Greg Young powiedział, że każdy powinien napisać własnego event, bo nie jest trudną rzeczą, że łatwo sobie to zaimplementować. I z Twojej perspektywy jaka jest teraz taka realność w dzisiejszych czasach, Bo event source gdzieś pod spodem musi umieć zrobić. Bardzo dobra biblioteka do event castingu. Musi umieć zrobić dużo rzeczy i powinna też gdzieś w teorii ułatwiać właśnie potem też w integrowanie się w inne takie rozwiązanie, jeżeli podejdziemy to jako na komponent całości, a nie samego użycia. Jak jest Twoim zdaniem z implementacją własnego event story?

Osoba mówiąca 3
Ja bym powiedział, że zachęcam każdego do napisania swojego event story, a potem użycia go w swoim produkcyjnym systemie. Jest super frajda napisać taki event story. Nawet udało mi się w 25 minut to zrobić na prezentacji, ale umówmy się nie zaczynamy naszego projektu od tego typu. O napiszmy sobie bazę relacyjną, bo chcielibyśmy używać bazy relacyjnej. Może to zróbmy. No ok, możemy to zrobić tylko tak jak w przypadku tego stwierdzenia to każdy się puknie w głowę. To jakoś w przypadku event story to jakoś nie wydaje mi się, że to miałoby sens, gdybyśmy nie znaleźli takiego event storage w naszej technologii, który jest. I który ma jakiś ludzi, którzy aktywnie nad tym pracują. Ale jednak w większości technologii takowe już są, więc samo napisanie swojego event stora jest faktycznie dosyć proste. Ale utrzymanie go to jest inna sprawa. To nigdy nie będzie raczej coś, na co my będziemy mieć dedykowany czas od naszego biznesu, więc prędzej czy później każdy takie kolorowe rozwiązanie raczej nie padnie ofiarą zerowego priorytetu. Dodatkowo jeżeli chodzi o sam zapis zdarzeń to jest dosyć proste.

Osoba mówiąca 3
Seriali zużyjemy, zapisujemy i tyle. To są dwie metody w teorii, które musimy mieć. Event store dodaj zdarzenie na koniec strumienia, odczytaj wszystkie zdarzenia ze strumienia, ale jeżeli chcemy a w event surfingu zdecydowanie chcemy i potrzebujemy mieć read modele, no to sytuacja już się dosyć komplikuje. No bo potem jak zrobić, żeby wydajnie te modele były aktualizowane? Jak zapewnić kolejność zdarzeń? Jak zapewnić odbudowę tych modeli? To to są już sytuacje, które są nie trywialne. One może nie są ściśle związane z samym event source ringiem, ale jeżeli się piszemy na event surfing no to to są rzeczy, które i tak będziemy musieli przerobić, więc lepiej żeby robił to ktoś według mnie, kto się na tym zna i komu za to płacą, albo chociaż hobbystycznie siedzi i to robi po godzinach jak ja na przykład.

Osoba mówiąca 2
Ja to pytam, bo w castingu widziałeś jakie są wartości kiedy jest casting. Wszystko fajnie, a tak personalnie to co ja widzę na rynku to jest event. Co? Trening fajnie wygląda jako taki greenfield. Z reguły po x latach on często może dać totalnego braku utrzymania. No bo mówimy sobie, że możemy sobie trzymać wszystkie wiadomości we wszystkich wersjach i tak dalej, i tak dalej, nic nie zmieniać i w ogóle odtworzyć się od startu czasu sprzed 15 30 lat. No ale mi się tak pali lekka lampka, że ja to musimy teraz trzymać te wszystkie kontrakty, utrzymywać taki tam, taki, który tylko rośnie, rośnie, rośnie, rośnie ilość. No więc jak jest z utrzymaniem zasięgu? Co zrobić, żeby ten system był utrzymywany i czy takie popularne mity konferencyjne i to będzie wszystko fajnie, super i nie martw się o nic na ile to jest włożyć CB do szuflady i nie najlepiej, że faktycznie tak jest.

Osoba mówiąca 3
Wydaje mi się, że tak. Trudność wersjonowanie event surfingu istnieje, ale według mnie stopień skomplikowania i to zwykle jak zaczynamy jakieś warsztaty czy spotkanie z ludźmi to jest zawsze jak wersjonowanie zdarzenia i ok, jeżeli się tego nie robiło i się nie myślało o tym od początku, tylko się potem właśnie budzi z ręką w nocniku dwa lata później, no to to będzie trudne, tego się nie da zrobić łatwo, ale to też dotyczy każdej innej migracji, którą gdzieś musimy danych zrobić, jak się obudzimy się z ręką w nocniku po dwóch latach, że nie dbaliśmy o ten nasz model danych. No i faktycznie tych technik modelowania i opisu jak to robić poprawnie niestety materiałów nieco brakuje. Ale jak to można zrobić? Mówi się, że w event surfingu tych danych się nie traci i faktycznie tych danych się nie traci, bo zapisujemy każde zdarzenie osobno i tak dalej. Ale to wcale nie znaczy, że my te dane wszystkie musimy trzymać w jednym miejscu. Bo jeżeli wyodrębnić sobie takie cykle życia, nawet jak mówiłem o tej kasie w Biedronce, to do takiej bieżącej operacyjnej działalności konkretnej kasy interesuje nas tylko to, co się wydarzyło w ramach tej zmiany w tej kasie, prawda?

Osoba mówiąca 3
Czyli wszystkie te pozostałe dane albo już są w ogóle nam nie potrzebne do transakcyjnej takiej operacji ności, czyli do podejmowania decyzji biznesowych? A może są potrzebne tylko gdzieś do modeli odczytu? A może w ogóle jedyne do czego nam są potrzebne, to do jakiegoś audytu itd. Więc w przypadku event surfingu, tak samo jak w przypadku innych rodzajów przechowywania danych, powinniśmy rozróżniać temperaturę naszych danych, czyli te gorące dane, które są na bieżąco. Używamy ich cały czas, je tam zmieniamy, chłodne, czyli których w ogóle nie potrzebujemy, lub takie letnie, które trochę potrzebujemy, trochę nie. No więc nic nie stoi na przeszkodzie, żeby te zdarzenia, których nie potrzebujemy, przenieść gdzieś indziej. Czyli przykładowo jak mamy dane audyt, to przenieść je do jakiegoś bloga. Jeżeli mamy dane, potrzebujemy tylko do analityki, to może przenieśmy je do jakiegoś systemu analitycznego i z tego event stora je usuńmy potem. Czyli powinniśmy stosować techniki archiwizacji. No i w event surfingu kluczowe jest myślenie o cyklu życia obiektów. To jest jedna z charakterystyk, bo im dłużej on żyje, tym strumień jest dłuższy i tym trudniej się pracuje.

Osoba mówiąca 3
Jeszcze co do samego wersjonowanie i jeżeli byśmy zastosowali te techniki archiwizacji to zobacz, że jeżeli mamy nową wersję zdarzenia i wiemy, że w naszym systemie obiekty żyją powiedzmy tydzień dwa, to moglibyśmy wdrożyć wersję, która wspiera i starą i nową. Miną dwa tygodnie czy tam trzy dla bezpieczeństwa i wiemy, że już nie przeżył żaden obiekt w praktyce, który jest w starej wersji, więc możemy zacząć ją po prostu od niej odchodzić, nawet pomimo, że gdzieś może te dane w teorii mogłyby być, ale w praktyce ich nigdy nie będzie, bo już je zarchiwizować mieliśmy, ale.

Osoba mówiąca 2
To trochę lepiej się czuje jak mamy dostęp księgowy czy księgowość. Faktycznie może nasze dane mogą żyć dłuższy czas de facto, czy może tylko sięgnąć do faktury sprzed 2 3 lat? No nie. Czy w tym momencie faktycznie trzymasz tę wersję zdarzeń? De facto wersja jeszcze migruje na nowsze schematy. Jak tutaj to wypośrodkować?

Osoba mówiąca 3
Ja raczej wersją lubię, czyli przez wersjonowanie mogę w ogóle nie wersjonowanie. Jeżeli jedyne do czego się spodziewam to do audytu, to wystarczy, że będę w stanie to odczytać. Potem jeśli mam dane w tej stronie to można w ogóle zignorować te wersje, których nie będziemy używać. Co do innych to są różne taktyki, bo możemy trzymać te wersje i ich nie używać, ale żebyśmy byli w stanie w jakiś to obsłużyć. Jest też technika tak zwany apt casting, czyli trzymamy w kodzie tylko aktualną wersję plus takie funkcje, które biorą stary pilot i w locie go gdy realizujemy to zamieniają na nowy format, dzięki czemu co prawda mamy te zdarzenia w różnych wersjach, ale w kodzie już jesteśmy w stanie używać tylko tej najnowszej. Z kolei Greg, jak twierdzi, że przy każdym wdrożeniu nowej wersji systemu powinniśmy przepisywać wszystkie te zdarzenia na nowy format i archiwizować te, których nie używamy. Z tym, że ja nigdy tak nie zrobiłem. Tzn nie robiłem tego typu przepisywania, ale to raczej przy jakiejś jak robiłem jakąś migrację danych. Raczej nie przy okazji konkretnego deploy Po żeby takie rzeczy robić to trzeba mieć naprawdę opanowane te narzędzia i tak jak mówiłem te narzędzia jeśli chodzi o takie tematy DevOps owe.

Osoba mówiąca 3
Żeby to zrobić płynnie, to trzeba je dobrze znać. One nie dostarczają out of the box tego typu rzeczy, więc tutaj trzeba bardzo uważać.

Osoba mówiąca 2
To zalecenie Grega brzmi jak utrudnianie sobie bardzo mocno każdego typu momentu. To brzmi jak duży proces budowania aplikacji. Mi też się tak trochę pali żółta lampka, że trochę nie za bardzo to brzmi.

Osoba mówiąca 3
Tzn. Znaczy miałoby to sens, jeżeli by to robić konsekwentnie, bo z jednej strony pozbywamy się tych starych danych, których nie używamy i wtedy ten zakres bieżących danych jest względnie mały stosunkowo, no ale wiemy jak to w praktyce jest. No niestety realia są takie, że większość ludzi w ogóle nawet nie myśli w tych kategoriach, które dane potrzebują, które nie, a co dopiero żeby je gdzieś archiwizować itd. Tak to praktyka wygląda.

Osoba mówiąca 2
I calling point jest taki, że nie wiesz, który danych masz potrzebować za ileś tam lat. No tak, dlatego wszystkie zadania, więc okej, ciekawe podejście.

Osoba mówiąca 3
Czy wiesz, te dane ciągle masz, bo równie dobrze możesz się przenieść na jakiś taki.

Osoba mówiąca 2
Archiwum.

Osoba mówiąca 3
Archiwum albo w ogóle do innego klastra, który jeżeli tych danych nie potrzebujesz, czyli np. do odbudowy czy gdzieś, to nie musisz za niego płacić tyle co za normalny produkcyjny. Jak przychodzi Ci sytuacja, gdy tych danych zaczynasz znowu potrzebować, odkręcasz suwaczek i jest to też tańsze, więc jest to dosyć faktycznie rzecz, która jest trochę zaprzeczeniem tego selling point. No ale ja też nie używam w zachwalanie tego czy audyt itd. OK. W ogóle według mnie event surfing sam w sobie on nie ma takiej pojedynczej killer feature, że można powiedzieć to jest to. I tu powinieneś używać event surfingu. Raczej to jest zestaw tych różnych rzeczy, które on daje, po prostu out of the box i tak jakby kumuluje te wszystkie rzeczy. To on daje wtedy tak jakby ten ślub może dać przechylić decyzję na korzyść użycia event scoring. Ale jeżeli byśmy wzięli każdą z tych rzeczy osobno, no to moglibyśmy łatwo to zbić, że ok, w tym innym narzędziu też to ma.

Osoba mówiąca 1
Słuchaj, to kolejne pytanie do tego, które też jest mitem konferencyjnym, blogowym. Od tego się przejawia, że jak robisz i on ing to jest wymagane. Musisz modelować i projektować aplikacje zgodnie. DDD Domain Driven Design. Musisz koniecznie użyć Ursa, inaczej to się rozsypie jak domek z kart. I jest taki mit, że musimy te wszystkie. Określam to mitem, bo się z tym nie zgadzam. Właśnie, że musimy to wszystko zawsze pakować w kupę. Jakie są Twoje doświadczenia?

Osoba mówiąca 3
Prawda leży gdzieś po środku. Tutaj jeżeli ktoś tak twierdzi, to w ogóle powinniśmy się zapytać go co ma na myśli przez DDD. Ja sam nie wiem jakbym określił DDD. Dla mnie Domain Driven Design to jest po prostu jakiś taki przybornik, zestaw różnych narzędzi skupionych na biznesie, które mogę lub nie, ale nie muszę używać w swoim projekcie. No i faktycznie event source. Tak jak wspominałem im lepiej modelujemy dane tym będzie nam łatwiej również technicznie, więc pod tym kątem skupienia na biznesie jest dużo wspólnego z Domain Driven Design. Z tym, że ja osobiście coraz więcej widzę, że Domain Driven Design. Użycie takie książkowe w przypadku event surfingu dodaje więcej ciężkości tego event surfingu niż zalet choćby agregaty, choćby. Ogólnie te wzorce taktyczne są bardziej takie książkowe object oriented, gdzie event source jest dosyć prostym wzorcem, bardziej takim funkcyjnym. Więc te wzorce taktyczne można jak najbardziej używać. Sorry sięgam, ale ja bym od razu najpierw się zastanowił czy faktycznie musimy i to uprościć. Jak najbardziej. Więc to co ma wspólnego event surfing z DDD to na pewno skupienie na biznesie.

Osoba mówiąca 3
No ale wiadomo społeczność DDD wszystkie rzeczy skupione na biznesie zawłaszcza. Ja się czasem śmieję, że coś 16 lat temu nikt nie próbował robić aplikacji skupionych na biznesie. Nagle dopiero od 15 lat ktoś pomyślał, że kurczę fajnie by było, żeby te aplikacje robiły to co biznes chce. No chyba to tak nie do końca jest nawet Eric Evans. On zresztą jest bardzo skromną osobą i on też. Musisz po prostu skatalogować te wzorce, więc.

Osoba mówiąca 2
Nie wzięło się znikąd.

Osoba mówiąca 3
Dokładnie. Co do RS a to cykl RS też zależy jak ludzie to definiują. Jeżeli tak jak na konferencjach to zupełnie nie potrzeba używać cykl Reset event surfing. Jeśli tak jak oryginalna definicja, czyli że segregujemy nasze operacje na zapisy i odczyty i dodatkowo każdą z tych operacji skupiamy się na tym, żeby robiła coś biznesowo konkretnego, czyli zmieniła, powiedzmy wykonała jakąś logikę biznesową albo zrobiła OT, pytała pod jakimś kątem biznesowym. Nasze dane to zdecydowanie event something. Potrzebuje tego. No bo żeby zapisać takie biznesowe, sensowne zdarzenie, to musimy znać biznesową intencję. No bo jeżeli mamy zapytanie z API typu create, update, delete to w najlepszym razie nam wyjdzie cat source sink, a nie event scoring, bo będziemy mieć zdarzenia create update delete. No spoko, tylko technicznie może i można byłoby to nazwać event source linkiem, ale nie da to nam żadnych zalet event scoringu tego typu podejścia. Więc ja też mówię, że cykl rest event source to jest tak jak tequila, limonka i sól dobrze ze sobą grają, ale to nie jest tak, że to musi wszystko być razem.

Osoba mówiąca 3
No event source bez Aresa takiego powiedzmy, no mówię tego prostego wzorca segregacji zachowań. To trudno by było zrobić. A cykl REST bez event scoringu? Jak najbardziej polecam.

Osoba mówiąca 2
Oskar a pytanko tak jak Ty poruszyłeś temat to od cudów z reguły ten projekt to jakieś tam grudy zaczynają się itd. I też mało wiemy o tej domenie, mało wiemy co potrzebujemy teraz. Jakie tu podejście tak naprawdę, czy albo może co uważasz i w jakich sytuacjach? Czy powinniśmy zaczynać od zasięgu jak widzimy, że okej, tu może pasować, czy jednak wejść w prosty model relacyjny albo jakiś inny sposób i dopiero ok, tu by nam pasował event hosting. Jak już znamy lepiej domenę, wiemy co wiemy, czego potrzebujemy i w temacie przy migrować na event core.

Osoba mówiąca 3
Nawet właśnie ostatnio w sobotę miałem takie dyskusje na warsztatach na ten temat. Nie ma dobrej odpowiedzi na ten temat, bo z jednej strony faktycznie gdy uczymy się domeny i zaczynamy. Greenfield no to tak, nie znamy technologii najprawdopodobniej, które używamy, bo skoro zaczynamy greenfield, to się chcemy wyszaleć i wybieramy jakieś nowe technologie, albo chcemy jak to ładnie się mówi po prostu być innowacyjni. No i najgorszą rzeczą. Co możemy zrobić, to uczyć się i technologii i domeny. Więc jeżeli nie mamy kogoś, kto robił coś event surfingu, to faktycznie może to nie być najlepszym pomysłem, żeby powiedzmy rozpoczynać wszystkie możliwe bitwy w jednym czasie. Z tym, że wiemy, że jak czegoś nie zaczniemy robić od razu, to po pierwsze pewnie być już do tego nigdy nie wrócimy. Po drugie jeżeli się uczymy czegoś nowego, to jak na pewno wiecie, to jest proces. Musimy popełnić ileś tam błędów, musimy się tego nauczyć. To nie jest tak, że nagle powiemy o. To jest mój moment, teraz będziemy to robić event surfingu, to tak to nie zadziała.

Osoba mówiąca 3
I tak tą krzywą nauki będziemy musieli przejść. No więc tutaj jest kluczowe, jak bardzo to nam pasuje do naszego projektu, jak bardzo ważnym elementem tego traktujemy. No bo jeżeli wiemy, że tutaj ten event surfing nam da dużą przewagę konkurencyjną i jest to coś, co na czym chcemy się oprzeć z jakichś powodów, to lepiej zacząć to wcześniej robić. Dodatkowo w przypadku greenfield zaletą według mnie event surfingu jest to, że jak pracujemy w surfingu to te zdarzenia są bardzo fajną formą dokumentacji danych. I nawet jeżeli nasze zrozumienie tego będzie powodowało, że będziemy mieć kilka wersji tych zdarzeń, to z drugiej strony w dokumentacji raczej nie uświadczysz. Więc te zdarzenia mogą być taką formą też dokumentacji historycznej jak nasza zrozumienie i nasza domena się zmieniała. Czy to jest warte czy nie? Trudno mi powiedzieć. To zależy od konkretnego projektu, ale niektórzy twierdzą, że w greenfield jak nigdy event surfing. Ja może też podeślę Wam. Jest taki fajny artykuł Alex Zima Rewa. Moglibyśmy dodać do materiałów właśnie po odcinku gdzie on fajnie to właśnie w ten sposób opisuje.

Osoba mówiąca 3
Z tym, że jeszcze tylko jedną rzecz i ja bym raczej zalecał, żebyśmy się nie rzucali. Kluczową domenę z event source ringiem, bo tam stopień skomplikowania jest tak duży, że tak jak powiedziałeś zanim zrozumiemy tą domenę to dużo popełnimy błędów. Więc jeżeli kompletnie nie znamy event core swingu nikt w naszym zespole nie zna. Zacznijmy od czegoś małego. Wdrożymy tą małą rzecz na produkcję. Popełnimy te błędy na takiej sytuacji, gdzie nikt nam głowy za to nie urwie, gdzie sami się nie spalimy ze wstydu. Nawet nam się to nie uda. Coś co moglibyśmy spokojnie wyrzucić do śmietnika i nam tutaj problemu z tego nie robił.

Osoba mówiąca 2
Mi się super podobała 1/100 to powiedziałeś, że używać tam gdzie event hosting byłby naszą przewagą konkurencyjną. I to jest bardzo podsumowanie de facto. Czyli nie, że fajnie byłoby użyć, tylko że jeżeli użyjemy to będą super super zyski z tego na poziomie nawet biznesowym. Tak naprawdę to bardzo, bardzo dobre podsumowania.

Osoba mówiąca 1
Dobra, będziemy powoli kończyć i gdybyś powiedział o trzech takich rzeczach najważniejszych, których chciałbyś, żeby ludzie z tej rozmowy zapamiętali, zapamiętali o event ratingu.

Osoba mówiąca 3
To pierwsza rzecz zmarnuje od razu to event source na kawce. Nie, nie róbcie tego. Użyjcie narzędzi, które są do tego dedykowane. Druga sprawa to bawcie się trochę event something. Niekoniecznie od razu na produkcji, bo event source thing jest wzorcem, który może dać przewagi tam. Jeżeli macie procesy, które są nieco bardziej skomplikowane, gdy potrzebujecie wiedzieć co się wydarzyło i mieć taką lepszą diagnostykę czy wkład pod analitykę. No i uważam, że właśnie to nie jest tak, że musimy go używać wszędzie, ale warto go mieć w swoim przybornika, bo im więcej mamy rzeczy właśnie przybornik programistycznym Leaders Patoarchitektów skin to tym lepiej, tym lepsze będziemy mogli podjąć decyzję, gdy. Nawet jeżeli teraz tego w naszym projekcie nie potrzebujemy, to jeżeli się zdarzy taki moment, to chociaż będziemy w stanie wiedzieć i będziemy w stanie to wykorzystać. Chyba jeszcze mi została jedna rzecz to przede wszystkim event. Surfing też jest czymś, co może jest ciągle niszą, ale mocno się według mnie rozwija. Nawet InfoQ w swoim raporcie to potwierdza. Nieco zbyt optymistycznym, ale jest to też coś, co faktycznie w świecie tym takim rozproszonym, w świecie, gdy storage jest tani, ale informacje są bezcenne, może nam dać pewne zalety i warto chociaż spróbować, bo nie jest taki straszny, jak go malują.

Osoba mówiąca 2
No dobrze, to w takim razie powoli zbieramy się. To powiedz gdzie Cię szukać, gdzie szukać materiałów? Jak? Co robić, żeby wiedzieć więcej?

Osoba mówiąca 3
Zachęcam do lektury mojego bloga Event driven, a ja staram się tam takie pigułki konkretne przekazywać jak właśnie nie tylko event surfingu, ale takie moje przemyślenia. Najwięcej jest o event surfingu, czyli jak rozwiązywać konkretne problemy pragmatycznie. Myślę, że warto sobie też na YouTubie poszukać choćby wiadomo rzeczy Grega Younga. Też Greg pracuje nad nową książką, jest już bliski ukończeniu. Mnie można też znaleźć Architect Weekly. Prowadzę taki newsletter. Są też tam webinary, gdzie czasem coś o event surfingu przekazuję. A jeśli chodzi ogólnie o event surfing, to też na blogu Event Story debili się sporo pojawia. Polecam z narzędzi właśnie Mar Event Story, DB, Saxon. W zależności od tego w jakiej technologii pracujemy, warto się tym pobawić. No i przede wszystkim najlepiej spróbować i się przekonać samemu czy to faktycznie jest takie trudne i straszne.

Osoba mówiąca 2
Dobrze.

Osoba mówiąca 1
To Oskar. Dziękujemy za dzisiaj i podzielenie się wiedzą.

Osoba mówiąca 2
Za bardzo praktyczne rozmowy.

Osoba mówiąca 3
Dziękuję Wam bardzo, Bardzo się cieszę. Dzięki, Mamy odhaczone. Kolejny element Wystąpiłem w moim jednym z moich ulubionych podcastów, także cieszę się bardzo. Słucham każdy odcinek.

Osoba mówiąca 1
Dzięki wzajemnie. Na razie na razie trzymajcie się.

