---
layout: post
title: '#65 Patoarchitekci Short #21'
date: 2023-03-10 08:00:00 +0200
description: 
episode: "65"
tags: ["maersk","heycom","autoskalowanie","serviceweaver"]
spreaker: 11965733
---
Jak zwykle dzieje się dużo:
Maersk, hey.com a AWS i onprem,
Microsoft - czy to Serverless czy autoskalowanie?
a także Google i Service Weaver for Writing Distributed Applications

...i wiele więcej! 


Linki i ciekawe znaleziska:

- [Introducing Service Weaver: A Framework for Writing Distributed Applications | Google Open Source Blog (googleblog.com)](https://opensource.googleblog.com/2023/03/introducing-service-weaver-framework-for-writing-distributed-applications.html)
- [Twitter](https://twitter.com/UdiDahan/status/1631320634843361281?s=20)
- [Introducing MRSK](https://world.hey.com/dhh/introducing-mrsk-9330a267)
- [Dapr - Distributed Application Runtime](https://dapr.io/)
- [How Cloudflare runs Prometheus at scale](https://blog.cloudflare.com/how-cloudflare-runs-prometheus-at-scale/)
- [Serverless compute tier - Azure SQL Database  ](https://learn.microsoft.com/en-us/azure/azure-sql/database/serverless-tier-overview?view=azuresql&tabs=general-purpose)
- [Introducing flexible new cloud services and pricing  ](https://cloud.google.com/blog/topics/cost-management/introducing-flexible-new-cloud-services-and-pricing)

### Transkrypcja

**Szymon Warda**: Cześć Słuchacie Patoarchitektów Prowadzą Szymon Warda...

**Łukasz Kałużny**: ...i Łukasz Kałużny. Wszystkie linki do tego odcinka znajdziecie na Patoarchitekci/io/65 albo gdzieś na dole w Twoim playerze do kliknięcia.

**Szymon Warda**: Dobrze Łukaszu, linki. Co tam masz ciekawego?

**Łukasz Kałużny**: Dobra, zaczynając może od Maerska - takiej nowej technologii...

**Szymon Warda**: Doprecyzujmy. To nie jest Maerzk, ci od kontenerów.

**Łukasz Kałużny**: Tak, ale ten Maersk też zajmuje się kontenerami.

**Szymon Warda**: Tak.

**Łukasz Kałużny**: Więc jakiś czas temu mówiliśmy o Davidzie Heinemeierze Hanssonie i Heicom. Czyli taka duża usługa mailowa, która się ładnie zaczyna rozbudowywać w jakimśtam światku basecampów i innych rzeczy. I oni powiedzieli, że wychodzą z AWS-a do onpremu, bo jest tani.

**Szymon Warda**: Tak, pamiętamy to dokładnie.

**Łukasz Kałużny**: Tak, dokładnie. Przymierzali się tam u siebie, bo opisali tą drogę, przymierzali się do Kubernetesów i innych rzeczy. Enterprisowa sprzedaż ich odstraszyła, mieli tego dość. Sam Kubernetes w onpremie - stwierdzili, że nie chcą budować specjalnie zespołu i kompetencji pod to, co mnie nie dziwi, ale napisali własnego toola do deploymentu kontenerów, który się nazywa Maersk i napisali to na swoją potrzebę. Pozbyli się tak naprawdę całej otoczki Kubernetesowej i to co robią, to w prosty sposób przygotowują serwer tym toolem i deployują sobie na nim po prostu standalone'owo obrazy kontenerów.

**Szymon Warda**: Jestem ciekawy za ile - bo to nie jest pytanie: czy, ale za ile dojdą do opcji żeby te kontenery przynajmniej restartować jak nie działają. Potem monitorować i potem będą powoli, ten taki creep będzie szedł w kierunku orkiestracji tego, bo pójdą w tym kierunku, bo to jest potrzebne. Żeby nie było: rozumiem, czemu nie poszli w Kubernetesa.

**Łukasz Kałużny**: Inaczej - nie, zrobili np. sondy i inne rzeczy, poowijali te template'y, różne rzeczy. Więc ja jestem naprawdę ciekawy. O tak. Jak będzie wyglądało, bo patrząc się jak ja na to patrzę - przez pryzmat Ruby on Rails, czyli gdzieś tam ta wysoka produktywność. No i pytanie właśnie jak to? Czy zostaną przy tym minimalizmie, czy jednak gdzieś skręcą w coś quasi Kubernetesowego?

**Szymon Warda**: Nie zostaną z prostego powodu, będą rekrutowali ludzi, którzy znają Kubernetesa znałem go możliwości. Szli na zasadzie to by mi się przydało i faktycznie się przydało, bo nie od parady Kubernetes ma tak wysoką adopcję, bo ma dużo rzeczy, które po prostu się przydają. Ma ogromny próg wejścia i tak dalej. To jest w pełni słuszne, ale dlatego właśnie masę firm go bierze po maturze, których my potrzebujemy, więc oni dojdą do tego stanu generalnie w utylizacji, a obecnie stworzyli własnego toola do wewnętrznego deploymentu, co jest jeszcze gorsze.

**Łukasz Kałużny**: No właśnie tak jest, to dałoby się to prawdopodobnie obalić kawałkiem terraforma i ansemble'a.

**Szymon Warda**: Raczej - Realnie?

**Łukasz Kałużny**: Realnie, realnie tak.

**Szymon Warda**: W ich sytuacji tak, ale w sytuacji jak chcą mieć małą skalę to to właśnie chmura jest odpowiedzią tak naprawdę.

**Łukasz Kałużny**: Wiesz co, nie będę się... Bo patrząc się na... Jak policzyli sobie, że i tak lecą na opensource, to im się to nie opłaca. Akurat od tej strony tak, jestem w stanie uwierzyć.

**Szymon Warda**: Ja też jestem w stanie uwierzyć. Tylko pytanie jest takie, jak liczyli? Bo wiadomo, że księgowość jest rzeczą płynną i co wliczasz w koszty i jak te koszty liczysz - to różnie Ci może wyjść. No nie? O to mi chodzi.

**Łukasz Kałużny**: Tak? Jeżeli tak, różnie możesz wyjść - tylko zobacz, z ich perspektywy i tego... Może tak - z perspektywy, że czy mi się to opłaca czy nie. Pisanie Toola? Tak szczerze? Wątpię.

**Szymon Warda**: No właśnie, to to jest bez sensu trochę dla mnie.

**Łukasz Kałużny**: Za to, czy ten powrót ich z cloudu do onpremu się mógł opłacać? Jeżeli tak większość robili na modłę infrastrukturalną na EC dwójkach, a usługi plastikowe były menago są diabelnie drogie, to ściągnięcie tego na open source nawet na twoich blachach jest tańsze.

**Szymon Warda**: I jest warte.

**Łukasz Kałużny**: Tego w szczególności. Polacy tak jak pasów nie korzystali, a wiesz utrzymanie nawet dużych baz danych. Nie oszukujmy się, jeżeli posiadasz potrzeba dużo ludzi żeby utrzymać bazy danych w dobrym stanie.

**Szymon Warda**: Zgadza się, jakoś jestem ciekawy to się rozwinie. Wydaje mi się, że będzie powoli, powoli.

**Łukasz Kałużny**: Zobaczysz jak potem albo będą gdzieś wracali.

**Szymon Warda**: Tak to się dowiesz.

**Łukasz Kałużny**: Wiesz, to następna rzecz, która jest ciekawa. To w googlu odkrywają lata 90 te, bo tak bym troszeczkę powiedział patrząc się na podejście. Zostało sobie Service Weaver Framework for writing distributed Applications. Czyli jest sobie taki framework do golenia, jak na razie wydany przez Google jako open source, które ma umożliwić pisanie modularne monolitu. I uwaga ta darmowa deploy owanie go jako mikroserwisach rysuje.

**Szymon Warda**: Nawet ci powiedziałem, że to jest dobry żart, bo jak patrzę co tam jest tak szybko, to też wygląda trochę znajomo do tego co było robione serwisy dla kodu wiele lat temu były takie właśnie opcje, że fabryk zanim było mało coś tam kontenerze dalej tam robić, pisać kod pozycja bitwa pliku. Tak wygląda znajomo bym powiedział raczej od.

**Łukasz Kałużny**: Tylko tam było takie mocne rozgraniczenie do tego. Tutaj jest tak naprawdę w tym przypadku wszystko ma być ukryte tak naprawdę przed deweloperem. Czyli piszmy odpalają u siebie lokalnie monolit i on nagle automagicznie przez całość, która została tam dodana zacznie się pojawiać i auto skalować na różne mikroserwisach serwisy.

**Szymon Warda**: Plany były tam były tylko odpowiedzi typu w używać, że tam listy były automatycznie rozproszone. Dalej ciekawy kawałek.

**Łukasz Kałużny**: Tamten był akurat w tym. Wiesz co, dla mnie to jest troszeczkę właśnie dość fajnie się wypowiedział na ten temat na Twitterze, że trzeba sobie przypomnieć, że właśnie prawidła rozproszonych systemów istnieją.

**Szymon Warda**: Zgadza się, ale uważam mimo wszystko, że to jest dobry kierunek iść, no bo ukrywać te rzeczy, bo to jest taki serwis Mesh 2.0 bym powiedział, że tak ładnie to rozpisze na poziomie kodu. De facto to nie jest proste, ale to jest kierunek, którym zdecydowanie powinniśmy iść.

**Łukasz Kałużny**: Wiesz co, jestem ciekaw, raczej kierunek. Zauważ, że tutaj chowasz synchroniczności asynchroniczne i inne rzeczy. No właśnie jest takie, że może inaczej bardzo mocno, chociaż na początku może to będzie. Wiesz jak ktoś takie coś użyje takiego podejście na początku będzie super. Pytanie jak bardzo się rozjedzie w trakcie.

**Szymon Warda**: Pytanie jak bardzo to będzie light abstrakcję na to jest takie ile będzie automat i na ile Cię kopnie w tyłek.

**Łukasz Kałużny**: No nie no teraz wygląda na sporo automatyki.

**Szymon Warda**: Tak więc możemy mocno kopnąć w tyłek dalej. Pewnie to nie jest finalna wersja.

**Łukasz Kałużny**: Tak? Bo ta rozpęd.

**Szymon Warda**: Nie będzie bardzo dużo generalnie w jeszcze innych rzeczach.

**Łukasz Kałużny**: Tak więc jest to ciekawe. Myślę patrząc się z takich dziwolągów. Bardziej mi odpowiada model, czyli Distributed Application Runtime.

**Szymon Warda**: Tak, zdecydowanie.

**Łukasz Kałużny**: W szczególności, że też dorobili się paru tych. Może trzeba będzie omówić, bo dorobili się paru nowych ficzerów ciekawych. Dobra dla Ciebie.

**Szymon Warda**: Ja znowu będzie. Było dawno żeśmy CloudFlare, ale tym razem tym razem, że było ważne i chwalimy go nie za to co wypuścili, ale wypuścili za bloga post na blogu jest to razem zwie się kalkulator, więc pomysł jest. I żeby nie było, nie jest to wpis. On jest długi. W ogóle nie jest to wpis o tym jak klaster odpala swojego Prometeusza. Tak, to spora ilość, to totalnie. To nie jest opowieść o hiper skali. Nie, to jest super fajny wpis o podstawach Prometeusza. Jak działa, jakie są podstawowe założenia, jakie są dobre wzorce zachowania pojedynczych instancji, nawet i przejście przez zrozumienie wszystkiego Prometeuszu, żeby mieć taki. Dobry punkt startowy do tego, żeby później rozumieć jak on działa, żeby później rozumieć co nas kopnie z tyłu i żeby rozumieć de facto jakie ryzyka nam chodzą, skonfigurować go, rozszerzyć itd. Naprawdę dobry wpis nie jest totalnie odsetkach Prometeuszu pracujących i równolegle jest o tym bardziej jak nawet pojedyncze instancje odpalić dobrze. Jak działa? Raczej wprowadzenie.

**Łukasz Kałużny**: Fajne są właśnie, że w jednym miejscu zgromadzone bebechy, bo pokazują nawet kierunki tych metryk. Fajnie rysunkowo, gdzie zostały zapisane w tym momencie, w czasie, w tym momencie, w czasie. I do tego to służy, więc jest dość fajnie pokazane. Właśnie. Memory mapping Old hands Right Blog study jest, więc to wszystko jest w krokach opisane co cały system robi i fajnie też widać tam na przykładach. Właśnie ten wpis fajnie graficznie oddaje, bo jest pokazanie labeli, czyli od tego jak mamy te metryki oleje celowane do tanków graficznie więc to są w ogóle super, że tak.

**Szymon Warda**: Dużo zrobili dobrze. Tytuł jest totalnie niepasujący do tego co jest w artykule, ale naprawdę jako wprowadzenie do zrozumienia Prometeusza. Super! Nie widziałem niczego tak, żeby w jednym miejscu było tak dobrze zebrane.

**Łukasz Kałużny**: To super.

**Szymon Warda**: A tak tam dwie rzeczy małe rzeczy do dyskusji. Pierwsza Microsoft wprowadza Server Rules do Base SQL owych. To już jest od dawna.

**Łukasz Kałużny**: Wprowadza tak, bo ona ciągle się pojawiają.

**Szymon Warda**: Ale tym razem dodali to tego tera typu bardziej tego wszystkiego, tego. Czyli mówimy sobie tam 80 100 terabajtów danych i tak dalej. Dalej kilka przemyśleń w kontekście tego oczywiście. Tutaj zobaczyliśmy oczywiście pojęcie server. To chyba jest server lepiej wiesz co tylko że. Ale słusznie.

**Łukasz Kałużny**: Tylko pozwól mi jedną rzecz powiedzieć akurat Avis server less pojęcie server lasu i dużo osób zostaje przy klasie z części A ws owej, że bardzo mocno zgwałcił w swoich produktach.

**Szymon Warda**: Tak, chodzi mi o to, że nie mam z tym problemu w tej wersji, bo np. na serwerze płacimy za stałe użycie. Jak są większe pliki to też za nie płacimy. To się auto skaluje, więc mamy auto skalowanie bazy składowych, a jak mamy stop kompilator załapać się na tę bazę są wyłączone, że nie ma tam ruchu. Co jest super dobre jeżeli mówimy o takich ogromnych zbiorach danych, bo to jest często odpalamy jakieś raporty rzeczy, które pracują w plikach, więc tak naprawdę to co nam to daje to jest auto skalowanie. Przy czym uwaga bo to jeszcze nie ma zatrzymywania. To dopiero będzie w kolejnej iteracji. Ale podoba mi się fakt, że to zdejmuje strasznie dużo opisów z prawidłowego ustawienia baz relacyjnych i oszczędzania kasy, bo te bazy są z reguły pierwszym albo drugim większym kosztem w jakiejkolwiek usłudze. Jak patrzymy a nagle wchodzimy tego tira. Serwer lasu też jest trochę droższy niż wszystko, ale zdejmujemy ten cały narzut na zatrzymywanie i skalowanie i tak dalej. Więc to bardzo fajny kierunek, w którym usługi podążają.

**Szymon Warda**: Według mnie.

**Łukasz Kałużny**: Tak dla dużych rzeczy spoko.

**Szymon Warda**: Dla małych to nie ma sensu.

**Łukasz Kałużny**: Już się tak raczej czujesz. To zawsze jest sen, bo mieliśmy przecież przypadki nawet z naszych konsultacji, gdzie opłacało się ze skalować z ośmiu kolorów do dwóch pod grę w nocy i przynosiło to niezłe oszczędności.

**Szymon Warda**: Zgadzam się tylko jak mówimy, że ma zaoszczędzić jak najbardziej. Tylko teraz pytanie ile zaoszczędzisz per godzina pracy? To jak masz 80 zł, a będzie to zauważalna różnica powiedzmy sobie no nie.

**Łukasz Kałużny**: Jest już zauważalna.

**Szymon Warda**: Tak więc to mnie naprawdę cieszy. A druga opcja. Google wprowadziło nowe umowy dla klientów. Nazywa się to Flex. Chodzi głównie o to, że tak naprawdę jest trochę łatwiej klientom wejść w lepsze usługi. Nie musi być. Nie musząc podpisywać takich long term agreement, długich umów na przyszłość, wieloletnich itd. Obniżyli próg wejścia i to sobie sprawdziło, bo jestem mega ciekaw, bo przez ostatnich paru odcinków mówiliśmy o tym, że właściwie ten cały Cloud chmura dorosła i tam już się niewiele dzieje na. Czy jeszcze możliwe jest przetasowania na tym rynku? Zmiana kolejności?

**Łukasz Kałużny**: Wiesz, to.

**Szymon Warda**: Że nie do końca.

**Łukasz Kałużny**: Patrząc się na te rzeczy to jest po prostu model umów w Google u, chyba z dużych dostawców najbardziej do tej pory, tak, to tam, patrząc się na osób z takiej mojej perspektywy i zabawy, jak mówimy o całych przetasowania innych rzeczach, nie wierzę, że one się przy tej skali, że się zadzieje raczej. Jeżeli już, to prędzej dojdzie do zbalansowania. Raczej nie nazwałbym przetasowanie, ale balansem, czyli że może w googlu przychody urosną, fabuła się bardziej zapadną i wszyscy się zatrzymają na podobnym poziomie po prostu posiadania rynku tych dużych.

**Szymon Warda**: Tak, wydaje mi się, że to dużo nie zmieni za bardzo. Jak? To jest bardziej ewidentnie odpowiedź Google'a na wymagania rynkowe i wymagania sprzedaży, na większy próg wejścia, bo to jest głównie do korporacji, bo tam sprawdzenie planu Enterprise, Enterprise Plus itd. To dalej więc o tym mówimy, ale już tam bez dużych ruchów nie będzie wybuchów, zmian i tak dalej.

**Łukasz Kałużny**: Nie słuchaj, wiesz, jak sobie popatrzymy na te Multi Cloud dla aplikacji w większości przypadków jest mitem. Jak sobie popatrzę.

**Szymon Warda**: Nie jest mi tam. Jest zbyt.

**Łukasz Kałużny**: Drogi. Dlaczego? Dlatego mówię, że z tej perspektywy jest mitem. Ja to oceniam, jako że dla większości przypadków jest mitem i niepotrzebne. Tak jak zmiana chmury. To tak jak zmienimy bazę, zmienimy bazę relacyjną, tak będziemy zazwyczaj przepisujemy. Jak zaczynam analizować, to kończy się ze zmianą produktu albo przypisaniem. Każdy ma jakieś preferencje, każdy ma jakieś wady i zalety. Jak potem bierzesz większość przypadków jakichś architektur zabawek i Tak, plusy i minusy z każdej chmury i usług, które tam są, one się balansują. Dochodzą, wyrównują, wyrównują się. Nie ma takiego Super, że pójdź tam, zrób to, pójdź tam, zrób to, pójdź tam, zrób, spojrzyj. Patrzysz się holistycznie na wszystkie usługi, bo w poszczególnych przypadkach tak znajdziesz przypadki, że w danym kraju usług jest bardzo lepsze, ale to już któryś taki szary petent, które lepiej skupić się na jednym klubie i przełknąć, że jakaś pierdoła tam gdzieś jest lepiej zrobiona i zrobić sobie porządnie to w jednym miejscu.

**Szymon Warda**: Tak albo wymagania. Jeżeli chodzi o regulatorów to jest drugi element, gdzie może być tak samo.

**Łukasz Kałużny**: Są chmury prostsze i trudniejsze do zrobienia tego.

**Szymon Warda**: Tak, dokładnie. Może bardziej przygotowane i przygotowane?

**Łukasz Kałużny**: Hahahaha lepsze określenie. Dobrze.

**Szymon Warda**: To ja tyle kont wybiegasz.

**Łukasz Kałużny**: Trzymajcie się na razie.

