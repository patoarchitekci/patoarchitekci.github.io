---
title: '#96 AWS re:Invent 2023 '
date: 2023-12-15T08:00:00+02:00
episode: "96"
tags: ["Konferencja", "AWS", "Cloud Native", "Observability", "AI"]
description: "AWS re:Invent 2023: nowe chipy Trainium i Graviton, Aurora Limitless Database, Lambda 12x szybsza. Prawdziwy zwyciezca? Nvidia. Czy AWS dogania AI?"
seo_keywords: "AWS re:Invent 2023, trainium, graviton, aurora limitless database, amazon q, bedrock, cloud formation, lambda, observability, cloud native, architektura IT"

# Hugo fields
youtube_id: "5TAbY4upXh4"
youtube_url: "https://www.youtube.com/embed/5TAbY4upXh4?enablejsapi=1"

# Spreaker data (technical only - for Schema.org, not user-facing)
duration: "PT33M22S"
audio_url: "https://api.spreaker.com/v2/episodes/58004652/download.mp3"

# Social media images (poprawione nazwy)
og_landscape: "/img/96-landscape.webp"
og_square: "/img/96-square.webp"

# Intro for episode
intro: |
  To si podziao! W dzisiejszym odcinku skupiamy si na AWS re:Invent, analizujemy dominacj Nvidii w technologii i zadajemy pytanie: czy Kubernetes jest faktycznie 'cepem'?  
  
  Mamy te偶 kilka ogosze patoparafialnych. Przygotowujemy si do wielkiego witowania naszego setnego odcinka w Warszawie.
  A to dopiero pocztek, bo mamy te偶 w zanadrzu otwarte patoszkolenia. Co, jak, gdzie i kiedy? Tego te偶 dowiesz si bezporednio z podcastu. Stay tuned i czekaj na kolejne informacje!
  Chcesz wicej? Posuchaj nowego odcinka!
  

# Links for the episode
links:
  - title: "Amazon Q (Preview)"
    url: "https://aws.amazon.com/q/"
  - title: "Getting started with new Amazon RDS for Db2  "
    url: "https://aws.amazon.com/blogs/aws/getting-started-with-new-amazon-rds-for-db2/"
  - title: "Meetup patoarchitekci.io z okazji 100 odcinka podcastu  "
    url: "https://events.teams.microsoft.com/event/e3c509f6-e713-41d9-a1bb-15a14436b030@7d58da1e-863a-433b-881a-eb613237f681"
  - title: "Agents for Amazon Bedrock is now available with improved control of orchestration and visibility into reasoning  "
    url: "https://aws.amazon.com/blogs/aws/agents-for-amazon-bedrock-is-now-available-with-improved-control-of-orchestration-and-visibility-into-reasoning/"
  - title: "Top announcements of AWS re:Invent 2023  "
    url: "https://aws.amazon.com/blogs/aws/top-announcements-of-aws-reinvent-2023/"
  - title: "[22.02.2024] Kubernetes the Hard Way"
    url: "https://easl.ink/W4UpP"
  - title: "Amazon CloudWatch Application Signals for automatic instrumentation of your applications nullpreview)  "
    url: "https://aws.amazon.com/blogs/aws/amazon-cloudwatch-application-signals-for-automatic-instrumentation-of-your-applications-preview/"
  - title: "[21.02.2024] Modelowanie danych nie tylko w NoSQL"
    url: "https://easl.ink/9wfoD"
  - title: "Vector engine for Amazon OpenSearch Serverless is now available  "
    url: "https://aws.amazon.com/blogs/aws/vector-engine-for-amazon-opensearch-serverless-is-now-generally-available/"
---

**ukasz Kau偶ny**: Cze, suchacie Patoarchitekt贸w. Prowadz ukasz Kau偶ny...

**Szymon Warda**: I Szymon Warda. Wszystkie linki do tego odcinka oczywicie na Patoarchitekci.io. Numerek sobie ogarniecie, bdzie w opisie. I co ukaszu mamy? Numerki si zbli偶aj, bo o nich troch nie m贸wimy, ale zbli偶a si taki do pierwszy trzynumerkowy numerek, 偶e tak powiem, wic bdzie meet up.

**ukasz Kau偶ny**: Tak, z okazji, tak jak byo i pidziesitego odcinka, to teraz bdziemy witowa, celebrowa, czy jak to okrelicie, setny odcinek. I suchajcie, zapraszamy Was 10 stycznia, godzina 18:00 do Warszawy. Link ju偶 znajdziecie pewnie gdzie w opisie, jak i na stronie, Face'ach, LinkedInach, mailingu, je偶eli jestecie zapisani. I co? Zrobimy, trzy sesje. S pewne pomysy. Szymon, chyba wstpnie o IDP bdziesz m贸wi prawdopodobnie?

**Szymon Warda**: Tak, procesy, technologia, dokadnie.

**ukasz Kau偶ny**: Tak. Ja mam za to takie szczere patoarchitektoniczne spojrzenie na LLM-y. W jaki spos贸b to bdzie wyglda? I wsp贸lnie z Wami, by mo偶e w formule AMA, by mo偶e tak jak odcinek 50, troch short i AMA. Nagramy wsp贸lnie setny odcinek tam na 偶ywo, kt贸ry potem ju偶 p贸jdzie i bdziecie mogli pozna go wczeniej, je偶eli bdziecie na miejscu.

**Szymon Warda**: Tak, ale to nie wszystko, bo stwierdzilimy, 偶e troch si wymdrzamy w tych podcastach i te偶 w 偶yciu odnonie kilku temat贸w, wic stwierdzilimy, 偶e skoro si wymdrzamy i dostalimy sygnay, 偶e fajnie byoby nie tylko si wymdrza, ale te偶 uo偶y t wiedz, troch ustrukturyzowa, wic odpalamy szkolenia kr贸tkie. Ja poprowadz szkolenie odnonie modelowania danych nie tylko w SQL-u. Generalnie szkolenie bdzie o modelowaniu danych. Te偶 jak kto umie modelowa dane, to si przekada generalnie na r贸偶ne bazy, czy NoSQL-owe, czy SQL-owe, obojtne.

**ukasz Kau偶ny**: Na razie pokazanie jak zamodelowa to w stor'ze do trzymania ich.

**Szymon Warda**: Tak, dokadnie, r贸偶ne podejcia i to, 偶e odkrycie, pita posta normalna nie jest czym wybitnym i praktycznie jak podej, 偶eby te dane si skaloway przede wszystkim i 偶eby byy te偶 jakie rozumne. 21 lutego, zapraszam.

**ukasz Kau偶ny**: Tak, a dzie potem, 22 lutego przyszego roku, bo to ju偶 bdzie 2024 Kubernetes The Hard Way. Si miej, 偶e jest to troszeczk kultowe szkolenie, 偶eby pokaza, dlaczego nie warto u偶ywa Kubernetesa. Czyli pokazanie jak postawi i jak dziaa Kubernetes od bebech贸w strony, binarek i caej infry, 偶eby go naprawd zrozumie, co tam siedzi i zrozumie dlaczego tak czsto wypowiadam si, 偶e jest to cep.

**Szymon Warda**: Troch jest.

**ukasz Kau偶ny**: I co wa偶ne mocno praktyczne. U Ciebie, z tego co kojarz, jest Szymonie du偶o wicze praktycznych i grupowych.

**Szymon Warda**: Slajd贸w nie bdzie, to og贸lnie rzecz biorc.

**ukasz Kau偶ny**: Tak, a u mnie dostajecie takie ciekawe repozytorium GitHubowe, kt贸re przechodzimy wsp贸lnie i sami stawiacie na rodowisku, w kt贸rym dostaniecie cay klaster. Wic zapraszamy, linki te偶 w opisie. I jest to na 偶ywo szkolenie, bo tego nie dodalimy, mogo wynika, 偶e co nagrywamy. Nie, to szkolenie takie caodniowe, na 偶ywo, zdalnie.

**Szymon Warda**: Tak, z pen interakcj. Dobrze, to o czym dzisiaj?

**ukasz Kau偶ny**: Dzisiaj ostatnia konferencja w tym roku, czyli AWS re:Invent. I dobra, to Szymon, jakie pierwsze przemylenie, je偶eli popatrzysz na cao? I zestawmy Gen AI-a.

**Szymon Warda**: Tak, dla mnie ciekawy waciwie miks, bo wydawao mi si przed konferencj, 偶e AWS p贸jdzie w opcj - wcale nie jestemy tak w plecy jak pozostali konkurenci je偶eli chodzi o AI-a de facto. A nie byo a偶 tyle o AI-u, mo偶e dlatego, 偶e to co byo o AI-u nie byo jakie takie zbyt rewolucyjne i troch tak rednio to wygldao. Byo du偶o rzeczy aplikacyjnych, byo du偶o rzeczy przygotowujcych pod AI-a de facto. Ale samego AI-a nie byo a偶 tak du偶o. Byo du偶o o skalowaniu, byo o tych aplikacjach. Cakiem powiedziabym, 偶e to ciekawie wyglda tak naprawd.

**ukasz Kau偶ny**: Dobra, to wiesz co, tak, z mojej perspektywy pierwsze przemylenie, 2 keynote'y, kt贸re warto byoby obejrze, to s prawie dwie godziny. Je偶eli g贸wny keynote i Wernera Vogelsa obejrzymy, to s prawie 4 godziny keynote'贸w. I to taka moja w tym i styl jest podobnie beznadziejny jak Microsoftu, podobnie beznadziejny jak GitHuba, podobnie beznadziejny jak Google'a.

**Szymon Warda**: Tak, to s te korporacje, kt贸re s zorientowane na biznes, a chc robi keynote'y jak Steve Jobs. To nie klei si troch za bardzo.

**ukasz Kau偶ny**: Aczkolwiek z tegorocznych prawdopodobnie jakociowo najlepsza, je偶eli chodzi o przegld sceniczny. Wic to jest jedna rzecz. Tak jak m贸wie, tego Gen AI-a jest sporo i nie sporo, bo jak popatrzymy na newsy to go nie ma sporo. Je偶eli popatrzymy na to, o czym... Bo Ja zawsze tak m贸wi, patrz na ten g贸wny przekaz, to tam jest sporo, 偶e pokazanie, 偶e jestemy na tym samym w贸zku co reszta.

**Szymon Warda**: Generalnie nie s.

**ukasz Kau偶ny**: Nie s. I dla mnie taka jedna du偶a myl z caoci tej ukadanki, 偶e wygranym caoci jest Nvidia. Caej tegorocznej ukadanki najwikszym wygranym aktualnie na kasie jest Nvidia.

**Szymon Warda**: Nvidia jest wygranym od mniej wicej ju偶 kilku lat, bo wczeniej byy kryptowaluty, te偶 bya wygranym defacto Nvidia.

**ukasz Kau偶ny**: Tak, ale teraz zobacz, to jest na potg ju偶 pchane, jak sobie popatrzysz sprzt.

**Szymon Warda**: Ostatnio Nvidia ogosia, 偶e nie s firm od chip贸w, tylko s firm od AI-a defacto.

**ukasz Kau偶ny**: Kt贸ra robi chipy. I wiesz co? I teraz patrzc si na cao ukadanki, pewnie to te偶 masz dokadnie wybrane, patrzc ju偶 si na rzeczy technologiczne, kt贸re s, takich g贸wnych rzeczy, kasa jest w hardwarze i dostpie do tego capacity computingowego pod AI-a aktualnie.

**Szymon Warda**: Tak, to jest konferencja gdzie AWS pokazuje bardziej, 偶e my mo偶emy przyj na twarz du偶e iloci danych i to wida w compute i wida to w bazach danych, wida to w storage'u, wida w bardzo wielu rzeczach, 偶e oni s gotowi te dane przyj, ale nie do koca jest co z tymi danymi robi tak naprawd.

**ukasz Kau偶ny**: Tak i teraz zabawa pokazuje, 偶e oni r贸wnie偶 ogosili nowe chipy. Pewnie masz to wybrane i chipy pod AI-a i pod serwowanie.

**Szymon Warda**: Ale ja im si nie dziwi, bo to, 偶e m贸wimy, 偶e Nvidia wygraa, to w og贸le bez dw贸ch zda, ale to jest tak silne uzale偶nienie si wszystkich dostawc贸w chmurowych i nawet nie tylko od Nvidii, 偶e ka偶dy z nich zauwa偶y ogromne ryzyko. Po pierwsze ryzyko biznesowe. Po drugie te chipy 偶r prdu ile tylko mog de facto, wic to bdzie na granicy opacalnoci. Dlatego te偶.

**ukasz Kau偶ny**: Szanuj te偶 nazw, Trainium, tego chipa.

**Szymon Warda**: I tam jeszcze jest drugi, Graviton.

**ukasz Kau偶ny**: Tak, ale to jest ju偶 ich seria, kt贸ra bya wczeniej, wic to jest po prostu kolejna generacja. I tak jak ka偶dy dostawca idzie i oni z tym ARM-em w sumie, tam patrzc si na rynek, to troszk zwojowali u siebie, bo ludzie powa偶nie traktuj te instancje, tam gdzie pisz nowy software.

**Szymon Warda**: One te偶 w og贸le s faktycznie, ciekawie wypchnli, bo AWS wypchn te instancje jako takie masywne instancje do naprawd du偶ych oblicze, niejako tak tam popelink, gdzie mo偶esz sobie aplikacje zahostowa. Tylko faktycznie jako instancje dla liczb. Graviton ma 96 neoverse vicor贸w de facto, 2 Mb cache'u per core, czyli tego jest sporawo, 12 kana贸w DDR 5. To s konkretne maszyny.

**ukasz Kau偶ny**: Konkretne i to co tam byo, taki fajny slajd, 偶e szykuj si, 偶e maj wietny chip do trenowania deep learningowego, w szczeg贸lnoci LLM-贸w. To bya pierwsza taka rzecz, kt贸ra bya rzucana na grafice. I druga, 偶e maj wietne miejsce do serwowania modeli. I ten Graviton przy du偶ej skali, tak, wyglda nie藕le.

**Szymon Warda**: Wyglda nie藕le. 呕eby dla kontekstu, ogosili te偶 nowe instancje U7I, kt贸re maj 896 vcore'贸w i od 16 do 32 TB pamici.

**ukasz Kau偶ny**: Je偶eli umiesz pisa rozproszenie, adnie mo偶esz zapakowa na t maszyn. Nic wicej nie potrzebujesz.

**Szymon Warda**: Tak. Jedna rzecz pokazuje tutaj dla mnie do mocno, patrzc na inne konferencje dostawc贸w chmurowych. Je偶eli chodzi o infrastruktur tak, faktyczne instancje, wirtuale i tego typu rzeczy, to faktycznie AWS jest super dojrzay, to w og贸le przebija innych.

**ukasz Kau偶ny**: Wiesz co, ale to jest tak, jak ja sobie patrz na te ogoszenia i to jest taki m贸j zarzut, dlaczego ja osobicie nie preferuj AWS-a. Jakbym mia wybiera projekt, wol Azure albo Googla. To jest taka bardzo osobista rzecz. Mimo, 偶e wywodz si z infry, to AWS jest za bardzo przywizany do mylenia invro, jak sobie teraz popatrzymy.

**Szymon Warda**: Oni powoli to tego dochodz, ale ja si z tym zgodz. Motkiem w AWS-ie jest wirtualka. Potrzebujesz czegokolwiek, robisz wirtualk.

**ukasz Kau偶ny**: S Lambdy i Fargate'y, ale koczysz gdzie wok贸 EC2 w jakiej formie, albo jak te RDS-y s zorientowane na t EC2.

**Szymon Warda**: Wida, 偶e oni od paru lat pr贸buj od tego odej po prostu. Ale moja teoria jest taka, 偶e ludzie po prostu nie s w stanie znale藕 tych nowych usug, bo nazewnictwo w AWS-ie dalej jest tak do dupy jak byo do dupy.

**ukasz Kau偶ny**: I wiesz co? Ja chciabym przeskoczy do keynota Vogelsa z dw贸ch powod贸w. 1 jest wanie na temat tych VM-ek. Drugi, 偶e jest on wartociowy te偶 dla ludzi, kt贸rzy nie siedz w AWS-ie. I Vogels o czym m贸wi? Jedna rzecz, kt贸ra mnie przera偶a, bo z jednej strony w RDS-ie, czyli usudze do relacyjnych baz danych, zosta ogoszony support dla DB2 IBM-owskiej, czyli typowy lift and shift.

**Szymon Warda**: To znaczy, 偶e id po taki stary enterprise typu banki.

**ukasz Kau偶ny**: Ale suchaj, to tak jak teraz pr贸buj reanimowa WCF-a, 偶eby to przenosi.

**Szymon Warda**: Ale mi si wydaje, 偶e bdzie rynek na open WCF-a. S firmy, kt贸re nigdy z niego nie zejd de facto.

**ukasz Kau偶ny**: Tak, wic przy okazji DB2 tam pada te偶 troch inne stwierdzenie i caej tej migracji. Jest okrelenie, 偶e w angielskim jednym z najgorszych zwrot贸w jest, bo cigle robilimy w ten sam spos贸b - 'we have always done it this way'. I teraz z jednej strony jest takie narzucenie, 偶e powinnimy si rozwija, robi to coraz lepiej. Z drugiej strony robimy po prostu shift to cloud, 偶eby by w cloudzie, bo nadal s takie podejcia. I na tym AWS zarabia promujc, 偶e przeniemy g贸wno.

**Szymon Warda**: Pamitaj o tym, lift and shift to jest najatwiejszy spos贸b, 偶eby zyska klienta, bo to wygrana waciwie dla managera, kt贸ry prowadzi projekt. No bo co? No bo udao si. W cigu dw贸ch miesicy mo偶e ogosi, 偶e s w chmurze AWS-owej, itd.

**ukasz Kau偶ny**: I RDS pokazuje, 偶e jak mamy RDS-a i EC2, to jestemy natywni dla cloudu.

**Szymon Warda**: Ja ich w peni rozumiem. To jest spos贸b jak zaatakowa takie stare, stare korporacje typu wanie banki, bo tam jest du偶o DB2.

**ukasz Kau偶ny**: I Werner jeszcze jedn rzecz promowa, czyli podejcie 偶eby by oszczdnym. I tam te偶 to za linkuj sobie, The Fragile Architect, jest takich 7 praw. Ale co jest fajne w przypadku AWS-a, 偶e jest kto, czyli CTO AWS-a, kt贸ry m贸wi o oszczdnoci i j promuje.

**Szymon Warda**: Patrzc na wyniki ekonomiczne, itd., nawet sp贸jrzmy na start tego roku, co byo bardzo mocno na wieczniku? Byy cae FinOpsy, czyli jak oszczdza, jak patrze, jak monitorowa. Pojawio si mas usug od tego, po og贸lnie rzecz biorc usugi bardzo niepewne, co w og贸le bdzie si dziao. Wic oficjalnie tak. A wszyscy teraz rzucaj si na LLM-y, waduj w to mas kasy, ale za p贸 roku, 3 miesic kto powie: ej, ale skd te wydatki? Czemu to si dzieje?

**ukasz Kau偶ny**: Wiesz co, Szymon, tylko jedna rzecz, pozwol Ci si wtrci, to jest dla mnie plus AWS-a, jako vendora. Jest to jedyny vendor z tych du偶ych, kt贸remu realnie pracownicy pomagaj oszczdza, bo podchodzili zawsze do tego, 偶e je偶eli pomog oszczdzi, to klient wrzuci nastpny projekt i nastpny, bdzie pczkowa. Je偶eli pomo偶emy mu ci rachunek, to bdzie pczkowa dalej.

**Szymon Warda**: Dla mnie jest jedna rzecz oczywista, nie robi tego z dobroci wasnego serca.

**ukasz Kau偶ny**: Nie, nie robi.

**Szymon Warda**: To te偶 wanie. Wic to jest zawsze... Ale jedna rzecz, kt贸r poruszye, dane. Je偶eli chodzi o przechowanie danych, mnie co innego zaciekawio bardzo mocno. Nowa usuga, kt贸ra dla mnie jest troch taka, takie niejasne uczucia de facto Aurora Limitless Database. O co tam chodzi? Chodzi o to, 偶e w tym momencie usuga na bazie Aurora, kt贸ra co umie? Umie si automatycznie skalowa, automatycznie tworzy shardy horyzontalnie. Shardy te偶 zapisowe, nie tylko odczytowe. Jak oni to ciekawie zrobili? Mianowicie na poziomie bazy danych okrelamy, kt贸re tabele maj by shardowane, a kt贸re tabele s replikowane dla ka偶dej instancji bazy danych. Ja mam do tego bardzo mieszane uczucia, bo pomys jako taki jest super, ale pomys jako taki jest przera偶ajcy, bo de facto doprowadzi do tego, 偶e teraz wyobra藕 sobie, 偶e tworzc baz tak naprawd albo tworzc kolumny, tworzc tabele okrelasz generalnie czy s shardowane, czy s replikowane wszdzie. I teraz z punktu widzenia tego developera, kt贸ry pisze kod aplikacyjny, on z reguy nie ma pojcia jak co dziaa tak naprawd. Wic jestem bardzo ciekawy wra偶e, bo to jest du偶y system, nie oszukujmy si, jak to bdzie wykorzystywany i jak to bdzie si realnie sprawdzao. Bo nazwa jest fenomenalna i jak w jednym zdaniu to jest fenomenalne. W szczeg贸ach to pali si du偶o 偶贸tych lampeczek, 偶e to nie jest takie automatyczne, automagiczne, jak nazwa mogaby wskazywa. Ale usuga nie mniej ciekawa.

**ukasz Kau偶ny**: Brzmi ciekawie, ale strasznie. Tak jak m贸wi, mam swoje wra偶enia kiedy w 2017 chyba, 2016, 2017, co takiego, musiaem si przy okazji nauczy wanie cao r贸偶nicy pod hurtownie danych, replikacji, asharidng贸w i innych tych zabaw, gdzie hurtownia jest prostszym scenariuszem.

**Szymon Warda**: Jest du偶o prostszym.

**ukasz Kau偶ny**: Ludzie od date'y wybaczcie, ale hurtownia po zaprojektowaniu modelu jest du偶o prostszym scenariuszem.

**Szymon Warda**: Mamy g贸wnie odczyty.

**ukasz Kau偶ny**: Tak, bo mamy odczyty. Na czas ETL-a mo偶na zwikszy moc w cloudzie. To jest to, tak to mo偶na okreli. Wic nie wierz w takiego AI-a. Jak jestemy przy danych, to co? Dokument DB Open Search dostay wektory, a jak偶e inaczej. Z nazwy to s te inwestycje, o kt贸rych trzeba byo zrobi.

**Szymon Warda**: To si musiao pojawi, atwy spos贸b na dodanie, zwikszenie ophype'owanie usugi, kt贸ra... DynamoDB jest tak jedn z podstawowych usug AWS-a tak naprawd. To byo zawsze, jest i to jest...

**ukasz Kau偶ny**: Tylko przez dugi czas bya taka fajna patola, jak zrobi wszystko w DynamoDB na jednej tabeli.

**Szymon Warda**: O czym w og贸le m贸wilimy par odcink贸w temu, dokadnie tak.

**ukasz Kau偶ny**: Chyba tak, byo. I suchaj, z rzeczy, kt贸re s ciekawe te偶, jak jestemy w tematyce danych, to r贸wnie偶 zero-ETL-e do Redshifta i OpenSearcha.

**Szymon Warda**: Tak, wanie te偶 zauwa偶yem, 偶e si pojawiy.

**ukasz Kau偶ny**: Te偶 si to rzucio. I suchajcie, z takich ciekawych rzeczy, czyli Postgresy, Dynamo, RDS-y, Auror mo偶emy zapakowa do Amazon RedShift-a za pomoc zero-ETL-a. To jest jedna rzecz. Druga, te偶 ciekawa, to DynamoDB ma te偶 integracj zero-ETL-ow pod wektory g贸wnie w OpenSearch. Co te偶 jest ciekawym scenariuszem z perspektywy takiej typowo aplikacyjnej, bo to troch pokazuje, Szymon, scenariusz, gdzie Cosmos DB mo偶na automatycznie zindeksowa teraz Azure AI Searchem, jak si teraz ta usuga nazywa, czyli wczeniej Cognitive Searchem.

**Szymon Warda**: I jeszcze kolejny element to jest to, 偶e jeszcze zwikszona zostaa wydajno kolejek, bo jak m贸wimy dane, to kolejki te偶 za chwil bd wchodziy i 70 tys. transakcji na sekund. I [niesyszalne 00:16:26] adne wsparcie. Ale powiem Ci, 偶e mnie co innego w og贸le ucieszyo. Takie dwie rzeczy, kt贸re mnie naprawd ucieszyy. To jest jedna rzecz, je偶eli chodzi o monitoring i bezpieczestwo, to jest wprowadzenie, wsparcie dla zapyta do log贸w, metryk, itd., wykorzystujc jzyk naturalny. To mnie bardzo ucieszyo. Wydaje mi si, to jest genialny absolutnie pomys, bo o ile lubi kwerendy i zapytania odnonie r贸偶nych narzdzi, to nauczenie si ich jest tak dziwn krzyw nauki, jest to upierdliwe. Cokolwiek uatwimy w tym obszarze to bdzie totalny, ogromny zysk de facto dla aplikacji i dla [niesyszalne 00:17:06]. I to jest super pomys dla mnie.

**ukasz Kau偶ny**: Wiesz co, ja tutaj, jak wrzucie logi i inne rzeczy, to dwa takie announcementy, kt贸re mi si rzuciy. Po pierwsze, nie sprawdzaem tutaj caoci, ale Cloud Watch Application Signals, czyli wanie AWS dorabia si APM-a, Application Performance Monitoringu, patrzc si na mo偶liwoci, natywnego. Czyli bdzie odpowied藕 u innych dostawc贸w, bo tego brakowao. Nie byo APM-a wczeniej.

**Szymon Warda**: I bdzie. Zaczynaj z grubej rury, z du偶 obiecank, 偶e automatycznie mog korelowa telemetri, logi, trace'y, metryki i w og贸le wszystko.

**ukasz Kau偶ny**: Syntetyczny monitoring, wic jest tego sporo. Tylko wiesz, z drugiej strony uczestnicz w Open Telemetry, to ju偶 nie bdzie takie straszne.

**Szymon Warda**: Tak, tylko czy zmiany na Open Telemetry jest proste? Pytanie, czy p贸jd... Bo dla mnie to jest osobista przewaga Application Insights z Azure'a. To jest to, 偶e ten stary model pod Open Telemtry jest du偶o pot偶niejszy. Wczasz i dziaa wszystko automagicznie i faktycznie dziaa automagicznie.

**ukasz Kau偶ny**: Jestem ciekaw tej autoinstrumentacji. Zrobi pewnie Jav na pocztku, zobaczymy co dalej, bo nie zagldaem. I przy tej rzeczy oni jeszcze dodali co takiego jak My Applications, czyli de facto, 偶e mo偶na sobie wyspecyfikowa taki wsp贸lny cay dashboard, kt贸ry bdzie zbiera nam informacje o kosztach, statusie zasob贸w, informacjach z Cloud Watcha, z Security Huba, bdzie zbiera w jednym miejscu. I to powiem, wiesz co, taki dashboard dla aplikacji, zastanawiam si po co to? Ale patrzc si to jest w og贸le ciekawa rzecz, 偶e mo偶esz zespoowi wystawi, je偶eli kto jest mocno AWS-owy, w jednym miejscu dosownie wszystkie najwa偶niejsze rzeczy, zamiast bawi si w dashboardzie w Grafanie i zrobi to tak z pudeka.

**Szymon Warda**: Dla mnie, powiem tak, cay rynek zdecydowa, 偶e u偶ywamy Grafany. Nie do koca widz sens, 偶eby i w co swojego. Podoba mi si podejcie MS-u, 偶e stwierdzili, 偶e okay, to my robimy Manage Grafan. I to jest fajne podejcie po prostu, bo odchodzi nam koszt utrzymania tego, w sensie taki mentalny. Wsp贸pracuj z firm, kt贸ra jest liderem rynkowym, robi to dobrze i jeszcze wspomagaj rozw贸j opensource'owego, mn贸stwo produkt贸w, kt贸re mo偶emy te偶 zahostowa. Jako nie kupuj tego podejcia, takiego customowych teraz ekran贸w, dashboard-贸w. Grafana istnieje tyle lat na rynku i jest ewidentnym liderem pod ka偶dym wzgldem.

**ukasz Kau偶ny**: Jestem ciekaw jakie s data source'y, bo tego nigdy nie sprawdzaem, jakie s.

**Szymon Warda**: Wanie tego bdzie mniej.

**ukasz Kau偶ny**: Wiesz co, wanie si zastanawiam, ale wiesz co, data source'贸w AWS-owych maj troch do Grafany, wic jest...

**Szymon Warda**: Ok, czyli to jest ich przewaga rynkowa, ta usuga.

**ukasz Kau偶ny**: Nie.

**Szymon Warda**: Nie, wic po choler to robi?

**ukasz Kau偶ny**: Wiesz co, sdz, 偶e to jest pokazanie, 偶e mamy wszystko. Na zasadzie, pamitaj, 偶e s gupie pytania Enterprise'贸w. Nawet tam w referencji jest gupie pytanie, 偶e chcemy mie wszystko w jednej szklance.

**Szymon Warda**: Oczywicie tak, masz racj. Dlatego osobicie wol podejcie Azure'a, 偶e wzili Manage Grafan.

**ukasz Kau偶ny**: Przy czym tak, w AWS-ie te偶 dla obrony jest Manage Grafana.

**Szymon Warda**: A mnie inna rzecz zaciekawia te偶 odnonie co m贸wimy, odnonie danych. Control Tower dorobi si 65 nowych controls, tak to mo偶emy przetumaczy generalnie, kt贸re maj wspomaga limity, ograniczenia je偶eli chodzi o suwerenno danych. Czyli limity gdzie te dane mog by. Czyli znowu AWS pochyla si w kierunku: dajcie nam wasze dane i to samo co te偶 Azure zrobi, bdzie to bezpieczne. Czyli ewidentnie maj chrapk na dane takie bardziej wra偶liwe, dane bardziej rzdowe, kt贸re po prostu nie mog odpowiednich region贸w opuszcza. Taka maa rzecz a pokazuje bardzo mocno w kt贸rym kierunku chc i.

**ukasz Kau偶ny**: Ja jestem ciekaw dokadnie czym s te kontrolki, bo to te偶 si w to nie zagbiaem. Czy to po prostu wyliczyli sobie per usuga, w kt贸rym mo偶e by datacenter, bo tak to brzmi troszeczk.

**Szymon Warda**: To mo偶e by ciekawe. Ale druga rzecz, to mnie ucieszya i te偶 wydaje mi si strza w dziesitk, je偶eli to bdzie dziaao dobrze, bo widziaem, 偶e Ty te偶 to masz - Q Code Transformation, czyli automatyczne upgrade'y aplikacji do nowszych wersji. Np. z Javy z 贸semki do jedenastki, z 贸semki do jedenastki do siedemnastki. Wic ogromny skok je偶eli chodzi o wersjonowanie. Teraz bd zsadzali si te偶 na rzeczy .NET-owe, itd. Fenomenalny ruch. I teraz czemu...

**ukasz Kau偶ny**: Pomys automatycznego reviewowania jest super?

**Szymon Warda**: I teraz czemu oni to robi? Bo w sensie po co AWS-owi zale偶y? Ano dlatego, 偶e jak oni maj utrzyma te wszystkie runtime'y stare, to ich to kosztuje. Oni wol optymalizowa te nowsze runtime'y, wic im zale偶y, 偶eby aplikacje byy w jak nowszej wersji tak naprawd, bo po prostu mniejszy koszt utrzymaniowy de facto. Wic wydaje mi si, 偶e to jest jedna z takich usug, gdzie zyskuje AWS i zyskuje klient wykorzystujcy.

**Szymon Warda**: Tak, wic tutaj si zgodz i tutaj dorzuc, jak jestemy w tematach developerskich, rozwijaj bardzo mocno swojego CodeWhisperer, czyli odpowiednik GitHub Copilota. O, to jest chyba najlepsze. I patrzc si, co mnie zaskoczya, pikna integracja z Visual Studio Code to wiadomo, 偶e bdzie, ale r贸wnie偶 z penym Visualem, jako plugin do penego Visual Studio. Inaczej, ten .NET, co by nie patrze, bardzo mocno tam si przebija.

**Szymon Warda**: Wiesz co, ja jestem po przegldaniu ponad piciogodzinnego podcastu z  Carmackiem od Dooma generalnie. Wic to, 偶e tam istnieje ten Visual Studio zwyky, wcale mnie absolutnie nie dziwi.

**ukasz Kau偶ny**: Wic tak, lecimy sobie, wic ta integracja, fajn rzecz, mocne wprowadzenie do Infrastructure as Code. I ja sobie rzuciem i to jest pierdoa, bo w AWS-ie mamy ten natywny jzyk deklaratywny template'owania, kt贸ry nazywamy Cloud Formation do Infrastructure as Code. I co jest ciekawego, to poszli bardzo fajnie w GitOpsa. Czyli, 偶e mo偶esz synchronizowa sobie tak, jak... To jest ciekawa ukadanka, bo mo偶esz tak, jak synchronizujesz sobie Fluxa czy Argo, 偶eby zdeployowa zasoby z repozytorium, tak teraz mo偶esz podczy sw贸j account, 偶eby ciga deployment z repozytorium i syncowa.

**Szymon Warda**: O ile nie jestem fanem Fluxa ani Argo, to to mi si podoba. Na tym poziomie synchronizacja naprawd wedug mnie...

**ukasz Kau偶ny**: Jest ciekaw rzecz. Fakt, 偶e bdzie wymaga od Ciebie pewnie kombinowania, bo znajc t ukadank i logik, ale jest ciekawym konceptem.

**Szymon Warda**: Najwy偶sza warto jest to, 偶e to robi sam AWS, a nie u偶ywamy kolejnego narzdzia, kt贸re by za t synchronizacj odpowiadao. Czyli mniej utrzymywania. Mi to gra, zdecydowanie. Co dalej? A rzeczy aplikacyjne, bo te偶 widz, 偶e masz ogoszenie odnonie Lambdy, 偶e nagle bdzie 12 razy szybsza, co jest du偶ym bardzo ogoszeniem i bdzie skalowaa si.

**ukasz Kau偶ny**: I bdzie skalowaa si 12 razy, tak. Czyli poszli w jeszcze lepsz skalowalno tego.

**Szymon Warda**: I tak 偶eby doda troch liczb, co rozumiaem przez to, 偶e bdzie skalowaa si 12 razy szybciej, pr贸bkowanie jest, zwikszanie iloci 1000 instancji co 10 sekund, jako tak, co 10 sekund de facto, a偶 dobijemy do limitu konta albo limitu subskrypcji.

**ukasz Kau偶ny**: Konta i regionu, konta i regionu.

**Szymon Warda**: Tak, 1000 r贸wnolegych wykona, co 10 sekund pr贸bkowanie. Cakiem fajne skalowanie bym powiedzia.

**ukasz Kau偶ny**: Tak, jest to druga ciekawa rzecz. To s cae zabawki z endpointami do Lambda, te偶 si tam rozwija. Z takich ciekawych rzeczy, to endpointy do step functions, to chyba te偶 masz Szymonie?

**Szymon Warda**: Tak, taki odpowiednik integracji z Logic Apps贸w tak naprawd, 偶eby por贸wna z Azurem.

**ukasz Kau偶ny**: I teraz patrzc si na to, jak kleimy rozwizania albo chcemy dostarczy na szybko, to naprawd spoko funkcjonalno, 偶e mo偶emy do tego flowu si odwoa, wreszcie w r贸偶ne miejsca flowu po prostu przez HTTPS-a.

**Szymon Warda**: Ale nie wiem czy zwr贸cie uwag na to, jakie s te integracje? To s integracje do provider贸w patnoci i tego typu rzeczy. Co fajnie pokazuje gdzie jest korpbiznes AWS-a. To s r贸偶ne, przer贸偶ne startupy. To s r贸偶ne instytucje, kt贸re s B2C tak naprawd, bo oni potrzebuj. Czy Enterprise potrzebuje integracji z providrami patnoci kart kredytowych? Nie za bardzo. Ale to fajnie pokazuje ten rozrzut, 偶e Azure jest taki du偶o bardziej korporacyjny, a AWS tam sobie te startupiki, itd., kt贸rych jest od groma i na tym te偶 ma du偶o Enterprise'u. Ale mimo wszystko, kto jest jego g贸wnym graczem?

**ukasz Kau偶ny**: Dobra, to kolejna rzecz i to jest kurde ciekawe i z jednej strony przera偶ajce, bo nie wiem jak jest to mo偶liwe, bo idzie si zabi. Zao偶enie jest takie, 偶eby zrobi co takiego jak consol to code. Czyli co sobie wyklikasz na swoim account'cie, w uproszczeniu, zostanie zautomatyzowane za pomoc Gen AI-a i wyplute jako IaC.

**Szymon Warda**: To ma jaki tam sens. Pytanie, czy to bdzie template'ing czy co wicej?

**ukasz Kau偶ny**: Ludzie, kt贸rzy si znaj na AWS-ie, potrafi si gubi w tej konsoli, chyba nawet bardziej ni偶 w Azure'owej, je偶eli popatrzymy, wic to jest ciekawa rzecz. Dobra. Z pierd贸 jeszcze, zanim przejdziemy do core'u, kt贸rego jeszcze nie poruszylimy, AI-owego, to AWS wypuci sw贸j kawaek grata Tiny Clienta, czyli malutkiego komputera z ARM-em, 偶eby czy si do swojej usugi Amazon Workspace i Upstream, czyli wirtualnych desktop贸w.

**Szymon Warda**: Czyli ten sam ruch, o kt贸rym m贸wilimy w poprzednim odcinku odnonie tego, czy bdziemy pracowali na terminalach de facto.

**ukasz Kau偶ny**: Tak, w wiecie Microsoftowym tego sprztu du偶o istnieje, wic Microsoft pewnie nie zrobi Surface Tiny Clienta. No a w Googlu mamy te Chromebooki, kt贸re cigle maj si dobrze w edukacji.

**Szymon Warda**: Tak, Azure ma swoje terminale, kt贸re Dell klepie takie, kt贸re s de facto terminalami i si integruj po prostu dobrze.

**ukasz Kau偶ny**: Fajna rzecz jest z provisioningiem, bo przy zamawianiu masz od razu klucz i przypite do swojego accounta. Wic provisioning tego jest piknie tutaj przemylany.

**Szymon Warda**: Dla pewnych organizacji na pewno bdzie to super. Ponownie, to jest dla korporacji.

**ukasz Kau偶ny**: Tak. Dobra, co Ci jeszcze zostao?

**Szymon Warda**: Wiesz co, zostay tak naprawd te wszystkie rzeczy AI-owe do om贸wienia. Ale tego ju偶 du偶o nie ma tak naprawd bym powiedzia. Nic ju偶 mn tak nie ruszyo za zabrdzo. Sorry, jeszcze na rzecz - storage. Zwikszyli prdko storage'u. I to, co mi si podoba, to jest wanie S3 Express One, czyli storage, kt贸ry jest, po pierwsze, w pojedynczych milisekundach dostpu. Jest 50% taszy, je偶eli chodzi o requesty, ale 7 razy bardziej kosztowny, je偶eli chodzi o storage. I co mnie zdziwio,? Bo zakadaem, 偶e cennik bdzie dokadnie odwrotny.

**ukasz Kau偶ny**: tak.

**Szymon Warda**: Ale jest.

**ukasz Kau偶ny**: I najwiksza wada, nie r贸bcie tego na produkcji, jak nie macie powodu, Single-AZ.

**Szymon Warda**: Tak, czyli Availability Zone, troch w jednym miejscu, ale dlatego, 偶e te dane po prosu musz by w innym miejscu, wic zapisywanie, itd., to wszystko musi dzia si szybciej, je偶eli nie zrobimy georeplikacji w pojedynczych milisekundach. Fizyka na to na razie nie pozwala. Dobrze.

**ukasz Kau偶ny**: To z AI-a byy takie dwie wa偶ne rzeczy, kt贸re powiedzielimy. Wczeniej jedn powiedzielimy, trzeba powiedzie wprost. Czyli z jednej strony Amazon nastawia si na hostowanie r贸偶nych opensource'owych i komercyjnych modeli i wystawianie tego as a service w ramach swojej usugi AWS Bedrock. I druga rzecz, Amazon Q...

**Szymon Warda**: Kt贸ry tak troch si nie pokaza na tej prezentacji do koca. Bardzo mieszane uczucia. Chyba nie wypalio tak bardzo jak AWS na to liczy, 偶e bdzie adnie i piknie.

**ukasz Kau偶ny**: Teraz o co chodzi? 呕eby Wam pokaza, ja te偶 poczytaem sobie newsy i ludzie s w niekt贸rych miejscach przestraszeni. Czyli dostajemy z jednej strony asystenta do budowy Copilota, nazwijmy to asystenta, czyli narzdzie do budowy Copilota dla Ciebie. Z drugiej strony Copilot dla AWS-a, 偶eby nie klika tylko wpisa, 偶e chcesz co zrobi. I ludzie ju偶 si zastanawiaj jak tam prompt injection, to ju偶 jest teraz, bya du偶a dyskusja czy bdzie mo偶na obej IAMA czy nie, w zale偶noci jak to bdzie zrobione. I potem, co jest de facto, Microsoft ma swojego Power BI, czyli dashboardy do Business Intelligence. I tutaj, tak jak zreszt MS to robi, czyli nakadka na Quicksighta wanie, czyli prosty Business Intelligence od AWS-a. Czyli wygeneruj mi z takiej takie dane i na podstawie tego co mamy podczone powinien zbudowa nam insight i inne rzeczy.

**Szymon Warda**: To jest genialne, u偶ywanie AI-a, 偶eby pozwoli na wykorzystywanie naturalnego jzyka do zapyta odnonie log贸w, telemetrii, danych, itd.

**ukasz Kau偶ny**: Czy danych biznesowych. Je偶eli masz dobrze zrobione metryki i to jest bardzo wa偶ne, je偶eli masz dobrze zrobione metryki biznesowe to wpuszczenie zwykego u偶ytkownika jest super, ale pod warunkiem, 偶e te miary tam w rodku s realnie zdefiniowane na naszych hurtowniach.

**Szymon Warda**: Ale z reguy te dane biznesowe to jest jeden wielki pierdolnik [niesyszalne 00:30:07] wielu lat, wielu system贸w, itd. Wic tam taki AI to jest fajna rzecz. To co mnie martwi to jest to, na ile te kwerendy bd dobre, na ile faktycznie bdziemy widzieli, 偶e dostalimy to, o co si pytalimy.

**ukasz Kau偶ny**: Dlatego na dobrze zadban hurtowni mo偶na z czym takim wpuci czowieka.

**Szymon Warda**: Wedug mnie to jest taka opcja, 偶e za chwil dojdziemy do tego, 偶e one nie bd zwracay danych, tylko bdziemy mogli zaznaczy po prostu opcj "poka偶 mi kwerend" i bdziemy tak to weryfikowali do danych krytycznych.

**ukasz Kau偶ny**: Ty bdziesz weryfikowa. Ale zobacz, 偶e chcesz posadzi od tego... Te narzdzia s nie dla IT, tylko dla biznesu.

**Szymon Warda**: Kt贸ry potem, doskonale wiemy, jak biznesowi daje si narzdzia, to potem zaczynaj ukda raporty, nie pytajmy si IT i nagle mamy system, kt贸ry jest na produkcji, kt贸ry jest niezabezpieczony. Takie przypadki te偶 ju偶 byy nie raz.

**ukasz Kau偶ny**: Lemy sobie, jeszcze dwie rzeczy i dwie ostatnie rzeczy, kt贸re spina. Jest tam centralka telefoniczna Amazon Connect, wic wpina si w budow sobie Call Center Service Desku, na wsparcie. I druga usuga, kt贸ra jest ciekawa, to mamy AWS Supply Chain. Nie myli z atakami, tylko z faktycznym zarzdzaniem dostaw, bo jest to robione jako taki know-how, udostpniaj produkt w ramach AWS-u. I tam r贸wnie偶 zostanie wadowane do m.in. wanie eksploracji jakich przypadk贸w, what-if i innych takich rzeczy.

**Szymon Warda**: Mi si to podoba, bo to nie jest pierwszy raz, kiedy oni adresuj problemy w og贸le caego tego acucha zale偶noci dostaw jakie mamy. I to jest cholernie trudny problem, jak si na to spojrzymy.

**ukasz Kau偶ny**: Dlatego ten Q nie jest wow, ale w kontekcie tej usugi Connect i Supply Chain dla klient贸w, kt贸rzy z tego korzystaj, to mo偶e by wow.

**Szymon Warda**: Tak, to nie zmieni 偶ycia, ale to jest ok. Spora odpowiedzialno, spore ryzyko korporacyjne, kt贸re mamy nagle odpada po prostu. I to mo偶e by ten element, kt贸rego normalnie nie patrzymy tworzc aplikacje, itd. Ale jak patrzymy na zakupy, decydowanie si na chmur, to mo偶e by ten element, kt贸ry m贸wi, 偶e okej, bierzemy to, bo to ma ten feature de facto, no nie? I to jest bardzo fajna opcja.

**ukasz Kau偶ny**: Dobra, masz jeszcze co z nius贸w?

**Szymon Warda**: Tyle.

**ukasz Kau偶ny**: Dobra, to taka myl koczca jeszcze Wernerem na temat LLM-贸w i Gen AI-a. To, 偶e LLM-y nie s srebrn kul AI-a.

**Szymon Warda**: Co mia powiedzie je偶eli nie maj swojego du偶ego LLM-a? Sorry, to jest to samo co powiedzia Ballmer, kt贸ry wymia pierwszego iPhone'a. Nie mo偶e powiedzie nic innego.

**ukasz Kau偶ny**: Wiesz co? Dokadnie. Aczkolwiek jedno takie po caoci przemylenie, wanie LLM w niekt贸rych przypadkach mo偶e, jak dobrze go u偶yjesz, mo偶e by t srebrn kul je偶eli chodzi o pocztek wejcia. Bo i w przypadku NLP, teraz budowanie customowych modeli, no sorry, prawdopodobnie traci racj bytu cay Natural Language Processing, ale pracy na liczbach nam nie zastpi.

**Szymon Warda**: To jest troch tak samo jak jest z iPhonem. Ten pierwszy iPhone by fajny, by mocno okrojony. Wydaje mi si, 偶e czekaj nas ciekawe iteracje i ciekawe kilka lat rozwoju tego caego rynku. Czy s srebrnym pociskiem? Nie, nie s, ale s bardzo bliskie, na pewno si byszczy ten pocisk z LLM-u na chwil obecn.

**ukasz Kau偶ny**: No dobra i tym koczymy.

**Szymon Warda**: Dobra, na razie.

**ukasz Kau偶ny**: Na razie.

