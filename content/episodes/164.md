---
title: '#164 Przekonaj mnie do OpenTelemetry '
date: 2025-10-03T08:00:00+02:00
episode: "164"
tags: ["OpenTelemetry", "Observability", "Monitoring", "Grafana", "Prometheus", "Tempo"]
description: "Szymon przekonuje ukasza do OpenTelemetry jako standardu observability. Omawiamy logi, metryki, tracing, migracj z APM oraz stos Grafana+Prometheus+Loki+Tempo."
seo_keywords: "opentelemetry, observability, monitoring, prometheus, grafana, loki, tempo, apm, datadog, new relic, dynatrace, metryki, logi, tracing, open source"

# Hugo fields
youtube_id: "zQKpeAwTWGg"
youtube_url: "https://www.youtube.com/embed/zQKpeAwTWGg?enablejsapi=1"

# Social media images (poprawione nazwy)
og_landscape: "/img/164-landscape.webp"
og_square: "/img/164-square.webp"

# Intro for episode
intro: |
  **"Praktycznie ka偶dy vendor umie konsumowa Open Telemetry"** - nawet **DataDog** i **New Relic** przyznaj, 偶e przegray t wojn. Ale czy to znaczy, 偶e powiniene rezygnowa z ich _"jednej linijki kodu"_ na rzecz konfigurowania **Prometheus + Loki + Tempo + Grafana**?
  
  Szymon twierdzi, 偶e to **"przyszo bez dw贸ch zda"**, podczas gdy ukasz pyta _"po co zmienia co, co dziaa?"_. Prawda jest brutalna: **kontrola nad kosztami** vs **wygoda pacenia**, **przenono** vs **vendor lock-in**, **elastyczno** vs _"wcz i zapomnij"_. 
  
  Problem w tym, 偶e **open source observability** to nie jest _"dla ka偶dego"_. Jeli tw贸j system to _"20-letni monolit w maintenance mode"_, to mo偶esz przesta czyta. Ale jeli masz **aktywny development** i **zespoy DevOps**, to mo偶e czas przesta dokada si do pensji programist贸w w **Dolinie Krzemowej** przez licencje APM.
  
  Czy **"future proofing"** to wystarczajcy argument do migracji? Sprawd藕, jak Szymon pr贸buje przekona ukasza - i czy argumenty o _"standardach na nastpne 5 lat"_ brzmi przekonujco. 锔
  

# Links for the episode
links:
  - title: "OpenTelemetry"
    url: "https://opentelemetry.io/"
  - title: "Grafana Tempo OSS | Distributed tracing backend"
    url: "https://grafana.com/oss/tempo"
  - title: "Application Performance Monitoring (APM) | Datadog"
    url: "https://www.datadoghq.com/product/apm"
  - title: "Enable OpenTelemetry in Application Insights - Azure Monitor"
    url: "https://learn.microsoft.com/en-us/azure/azure-monitor/app/opentelemetry-enable"
  - title: "Grafana: The open and composable observability platform"
    url: "https://grafana.com/"
  - title: "Prometheus - Monitoring system &amp; time series database"
    url: "https://prometheus.io/"
  - title: "Grafana Loki OSS | Log aggregation system"
    url: "https://grafana.com/oss/loki"
  - title: "Documentation"
    url: "https://opentelemetry.io/docs"
  - title: "Collector"
    url: "https://opentelemetry.io/docs/collector"
---

**Szymon Warda**: Wczoraj dziaao a dzisiaj nie dziaa, to w tym mTmencie co si musiao zmieni. Open telemetry jest standardem, tak to trzeba ju偶 nazwa tak naprawd i to dojrzaym, bo ju偶 wersja 1.0 wysza. Logi nie dziaaj, logi, znaczy nie dziaaj, kulawo troch dziaaj, ale s. Skadnia Elastica, je偶eli chodzi o wyszukiwanie, jest prosta, 偶e mo偶na postawi tam juniora i bdzie korzysta z tego dobrze. Skoro ju偶 robimy, integrujemy si z aplikacj, to pchajmy te logi jawnie przez Open Telemetry Protocol. Cze, czoem, kluski z rosoem. Suchacie Patoarchitekt贸w. Prowadz Szymon Warda...

**ukasz Kau偶ny**: I ukasz Kau偶ny. Wszystkie linki do tego odcinka znajdziecie na patoarchitekci.io, gdzie tu na dole, wierzymy w Was, dacie rad. Dobra i dzisiaj odcinek w troch innym stylu. Wracamy do observability i Szymon ma dzi bardzo ci偶kie zadanie. Musi mnie przekona, 偶e jest sens i czas w og贸le inwestowa w Open Telemetry, je偶eli m贸wimy o observability. I suchaj Szymon, to skd ta rozmowa?

**Szymon Warda**: Ta rozmowa jest std waciwie, bo jak popatrzymy sobie na rynek, co si dzieje, to mamy Open Telemetry, w kt贸ry si dzieje do du偶o. A ile razy wejdziemy do dowolnego wikszego klienta (...), to widzimy du偶ych graczy, widzimy New Relic'a, Dynatrace'a, Elastica i Datadoga, tego typu narzdzia. Wic w takim razie, skoro tak piejemy od du偶szego czasu, bo zgodzisz si, 偶e chwalimy Open Telemetri od jakiego czasu, to nie jest te偶 super nic nowego na chwil obecn, si ustabilizowa. To czemu dalej w og贸le widzimy tych graczy? Czemu w og贸le to istnieje i maj si cakiem dobrze? Bo dochody maj zacne, nazwijmy to tak delikatnie. Std ta rozmowa waciwie. Wic w takim razie czy jest sens w og贸le w takich du偶ych instytucjach wchodzi w Open Telemetry, wchodzi w ten stos open sourceowy? W tym kontekcie bdziemy m贸wili g贸wnie o stosie grafanowym, bo nie oszukujmy si, wygra t wojn je偶eli chodzi o o to jak widzimy, co widzimy i tak dalej.

**ukasz Kau偶ny**: Wiesz co, dobra, zr贸bmy chwil cofnicia si, bo nie wszyscy wiedz tak naprawd czym jest observability i czym jest Open Telemetry. To mo偶e zejd藕my pierwsz rzecz Szymon, tak wracajc, znajdziecie do tego chyba 3 albo 4 odcinki, podlinkujemy je, stare na ten temat, gdzie spdzilimy tam z godzin 20, tumaczc pewne pojcia pod spodem. Ale czym jest observability tak naprawd?

**Szymon Warda**: Czym jest observability? Observability jest tak chci tego, 偶eby widzie czemu co nie dziaa. R贸偶nica observability kontra monitoring. Monitoring to byo, 偶e patrzylimy na CPU, RAM i tak dalej i czy aplikacja dziaa. Wtedy za贸偶my byy takie sytuacje, 偶e przychodzi za贸偶my szef do zespou, m贸wi: aplikacja mi nie dziaa. Zesp贸 monitorujcy patrzy, CPU jest ok, RAM jest okej, dziaa z naszej perspektywy. Tak troch tego nie wystarcza. Observability jest tak chci i ruchem, 偶eby zobaczy co si dzieje wewntrz tej aplikacji tak naprawd, jak ona przepywa po caoci, cae nasze kochane mikroserwisy tudzie偶 serwisy, jakkolwiek to nazwiemy i chci zrozumienia, co si dzieje wewntrz i zbierania sygna贸w i danych, kt贸re bd tumaczyy zachowanie naszego systemu.

**ukasz Kau偶ny**: Ja lubi to pojcie troch te偶 z mechaniki w og贸le, takie in偶ynierskie, 偶e jestemy w stanie zmierzy stan systemu na podstawie wanie tych sygna贸w wychodzcych, wchodzcych, co si dzieje. Dobra Szymon, a z czego, bo tam s trzy takie kluczowe skadniki, z czego to observability si skada?

**Szymon Warda**: I to idziemy od najstarszych, kt贸re znamy doskonale. Mamy logi, log贸w si nie pozbdziemy, nie oszukujmy si. Czyli tekst, m贸wic bardzo prosto. Tekst, ale te偶 czsto okraszony dodatkowymi rzeczami, takimi metadanymi wanie, kt贸re powiemy, 偶e odnonie korelacji i tak dalej. Te偶 czsto ten tekst, te logi ju偶 nie s prost lini, ale s te偶 czsto form ustrukturyzowan. Structured Logging, ju偶 istnieje pojcie od dawna, weszo, ma si dobrze, promujemy jak najbardziej, jest ok. Idziemy dalej. Dalej mamy metryki, czyli zbi贸r key value mo偶na powiedzie, gdzie kluczem jest nazwa metryki. Tam oczywicie ona jest olabelowana, otagowana, jakkolwiek j nazwiemy tak naprawd. I mamy te偶 warto. Jest to z reguy liczba, tudzie偶 jaki float tak naprawd. I to s wartoci liczbowe, kt贸re s zbierane z r贸偶nych system贸w, kt贸re m贸wi, jak czsto co si dzieje, co si dzieje i tak dalej. Czyli daj nam takie og贸lne pojcie jak i co system waciwie robi. I z mojej perspektywy one s super krytyczne tak naprawd, bo je偶eli patrzymy wanie odnonie monitoringu observability tak naprawd, to... Za贸偶my, widzimy, 偶e system nie dziaa, to znaczy, 偶e co si zmienio z reguy. By deploy'ment, okay, to zmieni si kod, to winny jest jasne. Ale je偶eli nie byo deploy'mentu, je偶eli wczoraj dziaao a dzisiaj nie dziaa, to w tym momencie co si musiao zmieni. I wanie o to chodzi, 偶eby... Wracam do tego, co Ty powiedziae, okrelenie, co si dzieje wewntrz aplikacji. Czyli musimy namierzy to, co si zmienio, bo co si musiao zmieni, albo wicej ruchu, albo co innego. I wanie monitoring daje nam tak szybk mo偶liwo przeczesania i por贸wnania co jest dzisiaj, co byo wczoraj, co byo tydzie temu, 偶eby znale藕 t wanie anomali, odstpstwo od tego, co dzisiaj raportowane jest inaczej. Tego w logach nie znajdziemy za bardzo.

**ukasz Kau偶ny**: Je偶eli teraz tak, p贸jdziemy, dobra, a czym jest samo Open... Mamy observability, czym jest Open Telemetry?

**Szymon Warda**: ukasz, ale jeszcze o trace'ach zapomnielimy. Czyli spos贸b na ledzenie rzeczy pomidzy serwisami, co jest bardzo krytyczne i to jest fenomenalna rzecz. Natomiast bardziej dla developer贸w, mniej do monitorowania wanie, tak to czsto rozr贸偶niam. Ale te偶 tam fajne rzeczy mo偶na wycign. Mianowicie widzimy, jak si zachowuje cay flow, jak si systemy ze sob komunikuj. Super wa偶ne. Dobra, teraz czym jest Open Telemetry? Open Telemetry jest standardem, tak to trzeba ju偶 nazwa tak naprawd i to dojrzaym, bo ju偶 wersja 1.0 wysza, wszystko jest fajnie. Jest sposobem w jaki raportujemy dane z serwis贸w i zar贸wno sposobem, jak je nazywamy, jak je labelujemy, konwencje nazewnicze, to jak s zbierane, jakimi protokoami si komunikuj, gdzie waciwie wprowadzamy wzbogacanie tych danych ma przykad o labele, dodatkowe rzeczy i informacje, gdzie procesujemy. To jest zbi贸r bardzo du偶ej iloci takich dobrych praktyk, je偶eli chodzi wanie o monitorowanie observability. M贸wic bardzo prosto, recept na to, jak wej, zar贸wno je偶eli tworzymy jaki system, jestemy dostarczycielem jakiego softu, czy te偶 nawet jestemy dostarczycielem softu, kt贸ry zbiera dane o monitoringu, bo tam te偶 mamy pojcie eksporter贸w, kt贸re adnie wysyaj nasze dane, logi, telemetri czy metryki do Grafany, do Elastica i do wszystkich innych tak naprawd.

**ukasz Kau偶ny**: Dobra, czyli mamy sobie te trzy filary w postaci tych najprostszych log贸w, metryk, kt贸re s najbardziej wartociowe wbrew pozorom, jak popatrzymy.

**Szymon Warda**: I najtasze.

**ukasz Kau偶ny**: Najtasze i najmniej zrozumiane. I trace'y, kt贸re robi efekt wow dop贸ki nie odpalimy na produkcji. Czemu? To mo偶emy pod koniec si jeszcze poznca. To te trzy rzeczy. Szymon, to jest to, co wypychamy z aplikacji. Jakby powiedzia jak wyglda ta architektura Open Telemetry, z czego ona si skada? Bo tam te偶 s jakie pojcia.

**Szymon Warda**: Je偶eli m贸wimy o samej architekturze Open Telemetry, to dziaa tak. Mamy sobie nasz aplikacj. Aplikacja, i teraz bd upraszcza, aplikacja w jaki spos贸b, jeszcze nie m贸wimy w jaki, wypycha te dane. Tym sposobem preferowanym jest oczywicie korzystanie z Open Telemetry Protocol, kt贸ry mo偶e i po gRPC, mo偶e sobie miga jeszcze po http. Wiadomo, tutaj gRPC mo偶e si przyda du偶o bardziej. I teraz wypychanie mo偶e nastpowa do konkretnego konsumenta, nazwijmy go tak, czyli jakiego Elastica, czy to bdzie Loki, czy to bdzie cokolwiek innego, co konsumuje. I tak, przy maych systemach to bdzie dziaao. Natomiast je偶eli mamy co bardziej sensownego i chcielibymy tych 藕r贸de mie troch wicej i troch pokombinowa, troch wzbogaci, na przykad wysya jakie labele, przetransportowa, zbuforowa, zrobi takie suszne jak najbardziej przy dowolnym rednim i wikszym systemie, to po drodze wystawiamy sobie collectora. I co umie robi taki collector? On umie robi do sporawo, bo po pierwsze, w tym momencie wszystkie dane wysyamy do collectora i on tam sobie umie to zbuforowa, umie sobie wzbogaci, umie zamieni na przykad z trace'贸w metryki, umie zrobi cae procesowanie. Czyli aplikacje si nie martwi, a on w jednym miejscu. Umie na przykad te偶 scrape'owa niekt贸re rzeczy. I on te rzeczy zbiera, mamy w jednym miejscu ca konfiguracj. Co wicej, ta konfiguracja od do niedawna mo偶e te偶 by dynamicznie podmieniana, co te偶 jest bardzo fajne. I potem on mo偶e odpowiednie dane wysya do konkretnych konsument贸w. Czyli mo偶emy sobie za贸偶my wstawi takiego Open Telemetry Collectora, przepi aplikacj na co nowego, a dalej przez jaki czas na przykad raportowa dane do naszego starego systemu i na przykad cz log贸w wysya na przykad do danych archiwizacyjnych, a cz wysyamy sobie do Elastica, cz wysyamy sobie na przykad do Datadoga, cz wysyamy sobie na przykad do Grafany, bo chcemy zrobi poka m.in., case, kt贸ry obecnie mamy na talerzu wanie. Czyli tak to wyglda z du偶ej perspektywy, je偶eli chodzi o du偶e klocki.

**ukasz Kau偶ny**: Czyli idziemy sobie aplikacja do niej SDK, Collector i eksporter.

**Szymon Warda**: Nie do koca ukaszu. Wanie, bo teraz wchodzimy w ten element, kt贸ry jest czsto pojciem, 偶e to SDK musi by. A nie tylko, bo Open Telemetry jako taki ma te偶 mo偶liwoci totalnej zero code instrumentation. Nie dla wszystkich jzyk贸w co prawda, m贸wimy tutaj dwa g贸wne, gdzie to si rozwija najlepiej. Java stoi w sumie chyba najlepiej, je偶eli chodzi o dojrzao, chocia偶 nie w ka偶dym obszarze, 偶e mo偶emy sobie odpali nasz aplikacj w formie w agencie, kt贸ry bdzie przy zerowej zmianie kodu w naszej aplikacji zbiera t telemetri, zbiera dane i wysya wanie do Open Telemetry Collectora. Czyli to nie jest tylko SDK, ale tak, SDK jest t wersj jak najbardziej zalecan.

**ukasz Kau偶ny**: Teraz powiedziae, 偶e SDK jest zalecane, daje tam jakie autoinstrumentation r贸wnie偶 z pudeka. Ale wr贸my sobie, bo zacze od tego, 偶e gdzie znajduj si ci偶kie, klasyczne kobyy. I tak naprawd jaka jest zaleta, 偶e ja zaczn inwestowa teraz w Open Telemetry? Czyli mam, nie wiem, wdro偶onego dajmy na to na trace'a Datadoga, mo偶e New Relic jak wspomniae, i jaka jest tak naprawd warto schodzenia z takiego SAS-owego APM-a czy on prem'owego Dynatrace'a, jak mamy na rzecz tego stosu open source? Bo ja teraz pr贸buj to zrozumie kiedy, czy to w og贸le ma sens inwestowanie i dotykanie w to?

**Szymon Warda**: Wiesz co, powiem Ci tak, rok temu bym powiedzia, 偶e tak: a zastan贸wmy si jeszcze, mo偶e niekoniecznie. Teraz co si dzieje? Po pierwsze, ci duzi gracze, bo cay standard Open Telemetry zosta wymylony czciowo wanie po to, 偶eby nie byo takiej sytuacji, 偶e na przykad ja jako dostawca jakiego softu integruj si z jakim APM-em, daj to klientowi, a klient ma innego APM-a i nagle jest sabo. Wic zacznijmy od tego, 偶e praktycznie dowolny, czy to bdzie Datadog, czy to bdzie New Relic i tak dalej, umiej konsumowa Open Telemetry. Wic ja piszc moj aplikacj nie musz w tym momencie, po pierwsze, czy si z SDK konkretnego providera, mog korzysta z SDK Open Telemetry. Czyli jestem przenony. I tu si zgodzimy, 偶e to ma sens. Wpinanie i czenie si konkretnym SDK, na przykad Elastic'a czy kogokolwiek innego, rednio ma to na chwil obecn warto, niewiele tym zyskujemy. To jest ta jedna rzecz. Wic tu rozw贸j aplikacji spoko. Problem jest drugi, problem jest faktycznie autoinstrumentacji. Bo o ile m贸wimy, 偶e tak, Open Telemetry ma autoinstrumentacj, to czy ona jest tak samo dojrzaa? Nie, nie bdziemy tu kitowali, 偶e jest super. Rzecz, kt贸rej nie ma za bardzo tak naprawd i nie jest tak bardzo rozwinita, to jest midzy innymi profiling taki typowy. To co widzimy w Application Insights i tak dalej, w ka偶dym praktycznie, 偶e widzimy sobie, 偶e klikamy profile i widzimy wszystkie przejcia, wszystkie wywoania i tak dalej, i tak dalej, i tak dalej. Taki bardzo dokadny wgld w to, co si dzieje w aplikacji. Czy tego potrzebujemy zawsze? Nie. Czy powinnimy mie cay czas wczone? Te偶 absolutnie nie. Czy przydaje si raz na jaki czas, kiedy jest wywa na produkcji albo nie wiemy, co si dzieje? Tak, przydaje si bez dw贸ch zda. Wic tutaj trzeba by wiadomym. Pytae si w takim razie, czemu warto inwestowa w Open Telemetry?

**ukasz Kau偶ny**: No wanie.

**Szymon Warda**: Tak. Dlatego, 偶e to jest przyszo. Bez dw贸ch zda cay rynek idzie w tym kierunku. To jest pierwsza rzecz. Druga rzecz, to jest ta dyskusyjna, jak do tego podej i jak to policzy. A wiemy, 偶e ksigowo jest bardzo, bardzo kreatywna. Tak, to jest to, 偶e znamy, syszelimy, widzielimy jakie s cenniki du偶ych AP-贸w, czyli Application Performance Monitor贸w. To nie s mae koszty. One s liczone od kilku rzeczy. Albo od danych wchodzcych do nich, albo od CPU, od RAM-u, od host贸w, tego typu rzeczy. Wic je偶eli mamy troch instancji, mamy rodowisko, jakie performance testowe, developerskie, testowe, to czsto widzimy tak opcj, 偶e one tam nie s te rzeczy wczone, typu APM-y, bo jednak oszczdzamy koszty, a te koszty z reguy s du偶e. Korzystajc z tego, gdzie trzymanie tego samemu nas to ratuje? Oczywicie pacimy za dane, pacimy za ludzi, pacimy za bardzo wiele rzeczy, ale mo偶emy te dane usuwa, mo偶emy pewnymi danymi w inny spos贸b zarzdza, wic staje si to bardziej elastyczne i ta kontrola nad tymi kosztami staje si po prostu lepsza.b Inna bajka, narzdzia, mojej zdanie jest takie, narzdzia typu Dynatrace, New Relic, to s bardzo fajne narzdzia og贸lne. To nie s narzdzia, na bazie kt贸rych zbudujesz taki dobry zesp贸 do monitorowania, do utrzymania i taki szeroki. Co wicej, s to narzdzia, kt贸rych maa jest znajomo rynkowa. To jednak jak kto zna jedno, to potem przechodzi, to musi si od nowa uczy. A daj mi dowolnego SRE, gwarantuj Ci, 偶e zna Grafan, gwarantuj Ci, 偶e zna te high level'owe narzdzia, bdzie przynajmniej mia znajomo, kiedy u偶ywa Alert Manager'a od Prometheus'za. To s ju偶 po prostu standardy rynkowe. Co te偶 widzimy u dostawc贸w chmurowych, przechodz na przykad na Prometheus'za.

**ukasz Kau偶ny**: Tak, Prometheus, Grafana si pojawia coraz czciej jako manage.

**Szymon Warda**: Dokadnie tak. Po prostu wygrao t walk.

**ukasz Kau偶ny**: Suchaj, popatrzymy, dobra, bo jedna rzecz, kt贸ra mnie nadal... Popatrzymy, wezm sobie takiego Dynatrace'a, Datadoga, wepchn go w co, co jest w trybie maintenance. To dziaa i monitoruje.

**Szymon Warda**: Zgadza si, dziaa i monitoruje.

**ukasz Kau偶ny**: No wanie. I teraz jaki jest sens tak naprawd przesiadania si na Open Telemetry? W kt贸rym momencie?

**Szymon Warda**: ukasz, to taki sam... Sens jest taki, 偶e dziaa i monitoruje. Tak, tylko pomylmy o tym, to samo mo偶esz zrobi, dziaa i monitoruje w ramach Open Telemetry, ta autoinstrumentacja jest coraz bli偶ej, 偶eby inn rzecz wykluczy. R贸偶ni providerzy typu Dynatrace, New Relic i tak dalej, oni maj na przykad dodatkowe wartoci typu, 偶e zarzdzaj security, troch jeszcze inne rzeczy, tak bardziej do tego podchodz holistycznie. Czyli mamy jedno narzdzie, kt贸re mo偶emy da zespoowi, kt贸ry niewiele czasami wie i bd na przykad mieli alerty troch mdrzejsze, troch lepsz komunikacj, troch mdrzejsze wykrywanie, co tam si popsuo i tak dalej. To tutaj w og贸le nie wchodzimy. Open Telemetry jest do do aplikacji naszego systemu, takie goe, czyli logi, metryki, trace'y. Dobra, pytasz si w takim razie: mo偶esz wczy? Mo偶esz. Tylko jako tego co bdziesz mia bdzie taka, doskonale wiesz jaka bdzie. Nie bdzie najlepsza. Czyli patrzysz, pr贸bujesz wywnioskowa dane biznesowe, kt贸re realnie Ci interesuj na bazie nazw kontroler贸w, na bazie tego co tam ten nasz agent, kt贸ry si podczy, pr贸buje wykoncypowa. Jako tego wtpliwa. Wic 偶eby j poprawi realnie i tak bdziesz musia jakie zmiany w kodzie zrobi, 偶eby mie lepsz widoczno i tak dalej, 偶eby stworzy te wszystkie linie, warstwy, generalnie odpowiedzi i jak zespoy reaguj. Bdziesz to musia zrobi. Wic teraz moja opcja, skoro i tak musisz to w pewien spos贸b zrobi, skoro koszt integracji, koszt na przykad przekazywania trace'贸w, ledzenia, wywoa http, wywoa do baz danych, dla wikszoci jzyk贸w to albo jest wspierane w bibliotekach natywnych do komunikacji, to mamy przy Javie, mamy przy .Necie. Przy Node'zie tam troch to idzie...

**ukasz Kau偶ny**: No wanie miaem Ciebie zapyta jak jest, bo s dwie rzeczy, kt贸re widzimy po prostu z pudeka, kt贸re si zaczynaj pojawia tam, to distributed tracing niskim kosztem od strony takich gotowc贸w. I druga rzecz pokazanie sobie drzewa zale偶noci w adny spos贸b. Do tego stopnia, 偶e jak mamy popularniejszych jzyk贸w i ORM-贸w, to zobaczymy sobie querki, kt贸re s na bazie danych puszczane w danej transakcji.

**Szymon Warda**: No dobra, to przejd藕my jak to wyglda, bo to jest bardzo wa偶ne. Po pierwsze tak, je偶eli wykorzystasz autoinstrumentacje, Open Telemetry, t kt贸ra jest wbudowana w Jave i .Neta, to to dziaa. Czy jest idealne? Nie. My dalej bdziemy, ja bd dalej zachca do tego, 偶eby jednak zrobi przez SDK, czyli jednak to z aplikacji mie. Jak to wyglda? Realnie jest to konfiguracja, dodanie kilku bibliotek i skonfigurowanie, 偶e tak, chc SQL-e. Tak, korzystam z NHibernate'a czy Hibernate'a czy Entity Frameworka i wpicie si w ORM-y, wpinasz si i dziaa z pudeka, masz SQL-e. To jest koniec Twojej roboty. Po prostu jest. Idziemy dalej, jak wsparcie wyglda. Dla http klient贸w Java, .Net dziaa. Dla wszystkich gRPC? Dziaa, nie ma problemu. Wsparcie przez Springa? Czyli nie oszukujmy si, wikszo aplikacji java'owych. Wsparcie dla klient贸w do Kafki. Wsparcie dla klient贸w do Rabbita. Wsparcie dla za贸偶my cay Azure SDK, te偶 jest obo偶ony telemetri. Mass Transit, czyli wanie rabbitowy, to wszystko generalnie dziaa Ci z pudeka. Idziemy teraz troch dalej, bo to nie jest tak bardzo r贸偶owo. Teraz tak, mamy Node'a, kolejny popularny jzyk. Tam czy mamy wersj agentow? Taka nie do koca, bo tam wpinamy si w ten spos贸b, 偶e dodajemy, odpalamy jak agent, ale on po prostu podmienia niekt贸re wywoania i robi takie proxiaki na wywoania, bo Node jest bardziej dynamiczny, ale te偶 mamy form autoinstrumentacji. Teraz dalej, je偶eli chodzi o dojrzao wywoa, masz do Expressa, masz do GraphQL, gRPC, MySQL, Mongo, Reddisa, Kafki, masz biblioteki, kt贸re wspieraj ca telemetri. Python podobnie, te偶 ma podobn autoinstrumentacj. Nie jest tak stabilna jak pozostae, ale mimo wszystko... Nie jest tak dojrzaa, mo偶e tak. Dobra, dalej idziemy. Wsparcie dla Flaska, Django, Fast API, gRPC, SQL Alchemy i tak dalej. miga. I teraz wchodzimy z dojrzaoci. Gorzej Rust. Go - rednio, tam nie mamy autoinstrumentacji.

**ukasz Kau偶ny**: Dobra, ja z Go zostawi tutaj w tym, bo byy gdzie wylewane wiadra pomyj na temat implementacji Open Telemetry w Go, wic to zostawi.

**Szymon Warda**: Dlatego m贸wi, to jest tutaj, tu jest rednio, w Rust'cie te偶 jest rednio.

**ukasz Kau偶ny**: Gdzie wydawao si powinno by rock solid. Dobra.

**Szymon Warda**: Mo偶e do sterownik贸w nie potrzebujesz mie Open Telemetry. To jest 偶art oczywicie.

**ukasz Kau偶ny**: Dobra, teraz powiedziae sobie o tych rzeczach. Okej, czyli distributed, tracing i inne takie rzeczy dostajemy, wypychamy. Tylko cao i tak wymaga jakiej tam, tak jak z logami, jakiej naszej pracy w tym kodzie.

**Szymon Warda**: Wiesz co, tak. Przykad, kt贸ry dam Ci, anegdot z 偶ycia wzit, to jest na przykad m贸wimy sobie o tym, 偶e idziemy scenariuszem, 偶e nie potrzebujemy. Mielimy ostatnio tak sytuacj, 偶e klient zainstalowa agenta dynatrace'owego w klastrze i nagle aplikacja przestaa dziaa. Czemu? Okazao si, 偶e klient dynatrace'owy, 偶eby robi tracing dla wiadomoci, bo to jest takie troch trudniejsze po kafce, wstrzykiwa w headery swoje swoje trace ID. I okazao si, 偶e aplikacja wykorzystuje headery i si zaczyna wywala na twarz. Wic niestety to jest taka opcja, 偶e jak mamy jakkolwiek magi, to ta magia mo偶e nas do mocno ugry藕 w tyek, m贸wic bardzo prosto i si wywali. Wic prdzej czy p贸藕niej bdziemy zmuszeni, powinnimy wanie przekazywa te rzeczy, wpi si mimo wszystko jednak rcznie. A uatwia to, 偶e wikszo narzdzi umie to zrobi bez wikszego problemu ju偶 na chwil obecn.

**ukasz Kau偶ny**: Dobra, powiedzielimy sobie mamy narzdzia, powiedziane wpinanie tego. Okej, zaczynamy to wypycha z aplikacji. Czyli aplikacja zaczyna to wypycha. Tak naprawd co dalej po tym, czyli gdzie to wypychamy? Bo tak jak powiedziae, Open Telemetry dziaa w trybie pushowania g贸wnie. To gdzie to wypycha?

**Szymon Warda**: Zanim tam p贸jdziemy, bo jeszcze jednego obszaru nie dotknlimy - przegldarki.

**ukasz Kau偶ny**: Ok, bo APM-y ok, faktycznie APM-y daj nam czsto plugin frontendowy.

**Szymon Warda**: Plugin frontendowy, jedn lini do wczamy i wszystko jest wysyane i dziaa.

**ukasz Kau偶ny**: Tak m贸wi teoria.

**Szymon Warda**: Ale lepiej lub gorzej dziaa. W sensie mamy tracing od strony przegldarki do tego, co si dzieje na naszym backendzie. Przez jaki czas, du偶szy czas nie byo tego po stronie Open Telemetry. To ju偶 jest, co nie wiem czemu nie obio si wiksz wrzaw, 偶e tak powiem. Co wicej, to mo偶emy zrobi taki myk, 偶e bdziemy te dane telemetryczne raportowali do naszego endpointu pod nasz domen. Wic w tym momencie jest mniejsza szansa, 偶e telemetria nasza bdzie blokowana przez wszystkie adblockery i tak dalej, jako elementy ledzce.

**ukasz Kau偶ny**: Ok.

**Szymon Warda**: Co przyznasz, 偶e jest du偶 wartoci.

**ukasz Kau偶ny**: Tak, mo偶na przeledzi transakcje przy bugach od frontendu zazwyczaj, kt贸rego teraz mamy do koca. Tak, to ma swoj warto, o tak, to jest taka rzecz, kt贸ra jest, o kt贸rej faktycznie zapomniaem, 偶e to nawet weszo, a z czego zdarza nam si w Application Insights bardzo czsto korzysta.

**Szymon Warda**: Bo dziaa bardzo dobrze i te偶 ta integracja jest, no nie jest tak super dojrzaa, jednak jest i dziaa dobrze. Taka czw贸rka z plusem spokojnie mo偶emy powiedzie. Logi nie dziaaj, logi tam troch... Znaczy nie dziaaj, kulawo troch dziaaj, ale s, wic tracing mamy. Dobrze, m贸wie teraz odnonie, pytanie byo: gdzie te logi s wysyane?

**ukasz Kau偶ny**: Tak i jak to dziaa dalej?

**Szymon Warda**: Tu idziemy po kolei, od najprostszych rzeczy. Metryki id do Prometheus'za. Chyba nie musimy narzeka. Albo do Prometheus'za, albo do czego prometheus'zo podobnego, bo tego troch jest. Jest to standard rynkowy, wygrao, wszyscy korzystaj, wiemy jak korzysta, ma fajny jzyk do querowania, ma cakiem okej system do alert贸w, nie mo偶emy mie wikszych zarzut贸w. Powiem nawet wicej, je偶eli chodzi o metryki, to Prometheus jest du偶o przyjemniejszy ni偶 dostawcy du偶ych APM-贸w. Takie moje zdanie. Dobrze, idziemy sobie dalej. Logi teraz rzumy. No i tu trzeba by szczerym tak naprawd. Je偶eli chodzi o logi, je偶eli chodzi o du偶e systemy typu wanie Loki, to oddajemy UX za to, 偶e to jest tasze po prostu m贸wic bardzo prosto. Wykorzystanie i skadnia Elastica, je偶eli chodzi o wyszukiwanie, jest proste, 偶e mo偶na postawi tam juniora i bdzie korzysta z tego dobrze. Jak doskonale wiemy skadnia Loki ju偶 nie jest taka intuicyjna i tam wykorzystywanie ze, albo bez przeszkolenia, bez jakiej wiedzy jak to dziaa, skoczy si z reguy rednio, bo po prostu ubijaniem tego serwera.

**ukasz Kau偶ny**: Ok, bo trzeba powiedzie teraz, bo m贸wisz konkretnie, bo log collectorem dla Open Telemetry nadal mo偶e by Elastic, je偶eli sobie tego 偶yczymy.

**Szymon Warda**: Oczywicie, 偶e tak.

**ukasz Kau偶ny**: Nadal od tej strony. Je偶eli popatrzymy na Lokiego, to on ma swoj wad, 偶e nie mamy caej replikacji, nie jest baz danych tak naprawd w takim rozumieniu jak Elastic i nie ma full text search'a.

**Szymon Warda**: Dokadnie tak. Ma strumienie, jest du偶o taszy, szybszy... Znaczy szybszy, szybszy w pewnych obszarach, ale query bd zajmoway du偶ej na przykad. Jest z punktu widzenia osoby, kt贸ra wykorzystuje system jako taki, jest mniej fajny. I tu nie bdziemy kitowa, 偶e jest inaczej.

**ukasz Kau偶ny**: A frontendem do wszystkiego bdzie, jak rozumiem, Grafana.

**Szymon Warda**: To jest ten du偶y plus. Mamy jedno miejsce, gdzie spinamy wszystkie systemy i nie musimy mie wielkiej strony wiki, 偶e logi to tu, a performance monitoring to tu, a tu mamy Prometheus'za, a tu mamy co innego, bo doskonale wiemy jakie u偶yjemy.

**ukasz Kau偶ny**: Dobra, czyli teraz tak, pytanie jest, czy w takim razie, czyli te logi z aplikacji pchamy sobie z stdout'u, z jakiego wrapera, czy w jaki spos贸b wrzucamy te logi?

**Szymon Warda**: Wanie nie, bo je偶eli m贸wimy o tym, 偶ebymy pchali z stdout'u, to w tym momencie aplikacja bdzie robia troch wicej, to te logi mogyby si pogubi. Nasza droga jest inna. Skoro ju偶 robimy, integrujemy si z aplikacj, to pchajmy teologii jawnie przez Open Telemetry Protocol do naszego collectora, czyli do jakiego endpointu Open Telemetry. Co wicej, taki Elastic te偶 mo偶e takie dane w tym formacie konsumowa i te偶 si nie obrazi. Wikszo vendor贸w przyjmie z wielk chci Open Telemetry Protocol.

**ukasz Kau偶ny**: Czyli po prostu zamiast stdout pushujemy je sobie dalej.

**Szymon Warda**: Tak. Przy czym tu bd藕my realistami, mo偶e by taka sytuacja, taka sytuacja pewnie bdzie, 偶e jakie logi si przez Open Telemetry Protocol nie wyl. Tak 偶e stdout dalej trzeba obserwowa, bo bdy krytyczne bd si pojawiay w stdout'cie.

**ukasz Kau偶ny**: Rozr贸偶niamy logi czysto aplikacyjne od takich log贸w technicznych, kt贸re powinny tam zosta, typu polecia jaki stack trace.

**Szymon Warda**: Dokadnie tak. Mo偶e inaczej, polecia jaki auto memory exception, jaki krytyczny bd, framework nam si wywali, bd w konfiguracji, tego typu rzeczy. Spodziewamy si, 偶e bdzie z aplikacji, ale nie zawsze tak si dzieje. Trzeba jednak by realist.

**ukasz Kau偶ny**: Przewijasz teraz temat w og贸le, bo cigle si pojawia Prometheus, Grafana, ten stos open sourceowy. To tak naprawd co tam jest i do czego w tym stosie opensourceowym? Bo to rozumiem, to jest dla nas cay, 偶e tak powiem, Grafana jest frontendem, plus cay ich zestaw zabawek do skadowania tych danych.

**Szymon Warda**: Dobrze, tam jest kilka zabawek faktycznie. Dobrze, 偶e o tym powiedziae. Idziemy najprostszych. Mamy Grafan, czyli co, co su偶y do wywietlania, czenia i alertowania. Tyle. adne, adne wykresiki, z tego g贸wnie j znamy. I te偶 jest takim single point of entry, g贸wnym punktem wejcia dla wszystkiego. Teraz idziemy dalej. Prometheus, kt贸ry nie jest grafanowy, ale Grafana te偶 ma sw贸j odpowiednik. Czyli tam trzymamy wszystkie metryki. Fajny jzyk, prosty, adnie si skaluje, mo偶emy fajne rzeczy robi. Dobra, idziemy dalej. Loki, trzymamy logi, czyli trzymamy tekst. Dziaa, umie... I bardzo ceni Loki za to, 偶e mo偶e skalowa si do absurdalnych rozmiar贸w, absurdalnych wolumenu log贸w i jest do przyjemny je偶eli chodzi o stawianie. Ma te偶 alerting na logach, ma do du偶o rzeczy generalnie i integracja z caym stosem jest fenomenalna. Idziemy dalej. Wchodzimy w Tempo, czyli element do trace'贸w. Czyli tam trzymamy wszystkie trace'y, mo偶emy je wywietla. Jedna wa偶na uwaga to jest taka, 偶eby te偶 by, to adnie te偶 Ty powiedziae odnonie tego, 偶e jest pewne rozczarowanie odnonie trace'贸w, to jest to, 偶e trace'y jako takie, Tempo obsuguje trace'y w trybie... Nie ma raportowania, nie ma agregacji. Czyli wszystkie wyszukiwania robimy w kontekcie jednego trace'a i mo偶emy znale藕 jeden, mo偶emy znale藕 trace, kt贸ry nas interesuje, ale na przykad nie mo偶emy powiedzie: znajd藕 mi redni po wszystkich trace'ach, kt贸ra metoda...

**ukasz Kau偶ny**: Czyli nie da si zrobi tych adnych graf贸w z metrykami, ze statystykami.

**Szymon Warda**: Tak, takie rzeczy raportowe niestety nie dziaaj. Czemu? No bo albo robimy transakcyjnie, albo robimy raportowo, sorry. Ale nie jest tak 藕le, bo Tempo zapisuje dane w parquet'cie. Wic w tym momencie te dane, kt贸re zapisujemy w parquet'cie mo偶emy przerzuci przez jakikolwiek stos do machine learningu, kt贸ry bdzie to rozumia i raportowanie robi w tym miejscu. Nie jest to wbudowane w Tempo, sorry, ja te偶 tego 偶auj. Rozumiem t decyzj je偶eli chodzi o produkt.

**ukasz Kau偶ny**: Tak, wiesz, bo ja teraz tak, to jest wanie ta rzecz chyba, kt贸ra w APM-ach, jak popatrzymy, bo to, co m贸wisz jest dobre, tylko w APM-ach daj nam przyjemny view, kt贸ry pozwala, nawet je偶eli mamy wczony tylko sampling, to zobaczy sampling z trace'贸w i zobaczy wzgldnie rzeczywiste statystyki, co, jak wyglda.

**Szymon Warda**: Tak, na przykad rozkad czasu wywoa do bazy danych. Dziki temu nie patrzymy na pojedynczego trace'a, nie mamy takiego wskiego widoku, 偶e to wywoanie zachowuje si wolno. Mo偶e ok, mo偶e ono wykonao si wolno, ale je偶eli 99% wykonuje si w czasie szybszym znaczco, to po prostu mamy ten jeden element, kt贸ry odstaje. To jest bardzo wa偶ne.

**ukasz Kau偶ny**: By ten pech, by ten pech, a nie...

**Szymon Warda**: Albo bya czkawka, albo cokolwiek innego, albo to byo abnormalnie du偶e wzgldem reszty systemu. Tak, wic z tego takiego kontekstu, co si w og贸le dzieje, niestety nie mamy. I to jest, tu przyznaj, jak najbardziej jest to element bolcy.

**ukasz Kau偶ny**: Dobra, je偶eli teraz tak popatrzymy sobie dobra, czyli tutaj od tej strony Tempo troszeczk odstaje aktualnie.

**Szymon Warda**: Tak, mo偶na to zasypa wasnymi rozwizaniami i nawet jest par podej, ale niestety trzeba si troch nagowi.

**ukasz Kau偶ny**: No dobra, i teraz tak, bolczka, je偶eli popatrzymy, to jest przechowywanie danych w tych systemach, wic jak og贸lnie w monitoringu. Wic je偶eli nie masz rozwizania SAS-owego, kt贸re pobiera od Ciebie stosown opat za to, 偶e zdejmuje Ci to z gowy. Wic jak tu wyglda z przechowywaniem?

**Szymon Warda**: I to jest ten element, kt贸ry byszczy i trzeba to rozbi troch na dwie opcje. Po pierwsze, je偶eli w czym byszczy, bo skupimy si tu g贸wnie na tam, gdzie danych mamy du偶o, czyli m贸wimy o Loki, Tempo. To w czym to byszczy? To jest to, 偶e faktycznie jest to system pomylany na to, 偶e przychodzi du偶e iloci danych. Jak to si dzieje? Dzieje si przede wszystkim to, 偶e dane s adnie dzielone, dane s zipowane, dane s przechowywane na g贸wnie storage'u blobowym. Czy to bdzie Azure Blob Storage, czy to bdzie S3, cokolwiek co ten interfejs implementuje bdzie dziaao. Wic je偶eli jestemy w chmurze tak naprawd, to mo偶emy sobie to robi bardzo niskim kosztem, storage naprawd du偶ego zbioru danych. Je偶eli jestemy na on premie, to oczywicie s rozwizania, kt贸re bd symuloway. Mo偶e nam to wyj troch dro偶ej.

**ukasz Kau偶ny**: Ewentualnie to, co podpowiadamy klientom, jak si okazuje, czasami okazuje si, 偶e maj licencj np. do storage'u, kt贸ry wystawia te S3 API.

**Szymon Warda**: Tak, dokadnie sporo w og贸le vendor'贸w, to co m贸wilimy wiele lat temu o tym wanie, 偶e sporo wanie vendor'贸w takich macierzowych m贸wi, 偶e okej, wystawiaj w og贸le wanie API S3, bo ono stao si standardem, mo偶na powiedzie.

**ukasz Kau偶ny**: Tak, dobra, to zrobilimy. To teraz kolejny element, o kt贸rym myl. Jak podej w takim razie, dobra, to powiedzmy, 偶e przekonae mnie do Open Telemetry. Wa偶ne, to chyba to trzeba powiedzie, tak jak ja to rozumiem, najlepszym odbiorc Open Telemetry to jest co, co ma aktywny maintenance, aktywny development.

**Szymon Warda**: Dokadnie tak.

**ukasz Kau偶ny**: I mamy kontrol nad kodem.

**Szymon Warda**: Dokadnie tak.

**ukasz Kau偶ny**: Dobra. I teraz powiedzmy sobie Szymon, to co si znajduje z naszej codziennej praktyki z klientami, to co robimy? Przychodzisz i klient powiedzia, 偶e: chcemy Open Telemetry. Jak wyglda proces adopcji tego?

**Szymon Warda**: Jasne. Znaczy on jest dwojaki. Bo pytanie jest proste, czy klient jest w Kubernetes'ie? Bo je偶eli klient jest w Kubernetes'ie, to nasze 偶ycie si znaczco uatwia. I nie tylko dlatego, 偶e jest w Kubernetes'ie, bo w tym momencie mo偶emy ustawi scraping pod贸w, mo偶emy adnie sobie wdro偶y collectora, adnie wdro偶y wszystkie pozostae rzeczy, czyli mamy do tego niemal偶e gotowe YAML-e. W tym momencie jest atwiej. Drugi jest element, bo je偶eli klient jest w Kubernetes'ie, to znaczy, 偶e stos, na kt贸rym pracuje jest relatywnie nowy. Sowo kluczowe: relatywnie nowy. Czyli nie m贸wimy na przykad o antycznych aplikacjach, kt贸re s rozwijane od lat dwudziestu. Zapewne produkuj du偶o wartoci biznesowej. Technicznie mog by wyzwaniem. Wic je偶eli jest w Kubernetes'ie, prosta sprawa. Je偶eli na przykad pracuje na VM-kach, czyli m贸wimy ju偶 troch bdzie trudniej, to w tym momencie ok, Open Telemetry Collector mo偶e dalej scrapowa logi, mo偶e dalej zbiera dane z VM-ek, to te偶 nam si przyda w kontekcie samego Kubernetesa, 偶eby wiedzie co tam jest hostowane i to wszystko dalej mo偶emy wysya. Czyli plus, kt贸ry widzimy, to jest to, 偶e idziemy od najatwiejszych, obcinamy i budujemy cay pipeline, gdzie nasz Collector i jego rola podstawowa jest to, 偶eby nie mie tego co czsto widzimy w narzdziach do APM-u, 偶e mamy takie warstwy jakoci, 偶e okej, dla tego systemu to wyglda dobrze, ale potem wchodzimy do tego systemu, to te logi wygldaj i te dane, kt贸re mamy, wygldaj po prostu jak co nieadnego, 偶e tak powiem adnie. Wic wstawiamy po kolei collectory, 偶eby dane wzbogaca, 偶eby jak najbardziej zbli偶a je do tego finalnego miejsca. Jak to wyglda, je偶eli chodzi o samo wysyanie, czyli ten cay proces migracji? Nie robimy wielkiego skoku hopsasa na nowy system. To robimy tak, 偶e poniewa偶 mo偶emy mie Open Telemetry Collector, pewnie bdziemy go mieli, to jest to, 偶e wdra偶amy, zaczynamy cz danych wysya do nowego celu mo偶na powiedzie, pewnie do Loki, pewnie do Tempo. I w tym momencie, jak ten system napenimy powiedzmy danymi z dw贸ch, trzech miesicy, w tym momencie mo偶emy robi adne przeskoczenie. Czemu? 呕eby nie byo takiej rzeczy, kt贸r widujemy czasami, 偶e ok, wiesz co, dane odnonie tego, to kt贸re maj tam powiedzmy powy偶ej tygodnia to s w tym systemie, a te s w tym systemie i w tym momencie budujemy absurdaln frustracj. Co jest dalej wa偶ne? Je偶eli chodzi o sam proces w og贸le przejcia, to jest to, 偶e musz by jakie szkolenia, kt贸re poka偶, jak si z tego korzysta. To te偶 jest w og贸le czsto du偶y problem dla APM-贸w wszelkich, 偶e one s rzucone na po偶arcie, 偶e tak powiem, zespoom i teraz uczcie si. No sorry, tak to nie bdzie dziaao. Nie przy systemach open source'owych, kt贸re s troch trudniejsze i troch szorstkie w interakcji, 偶eby odpowiednio pokonfigurowa. Dalej przede wszystkim pokazujemy jakie s mo偶liwoci, jakie s feature'y, bo czasami do niekt贸rych dogrzebanie si jest troch problematyczne. Potem dalej co robimy? To jest konfigurowanie wszystkich dodatkowych rzeczy typu generowanie metryk z trace'贸w, przydaje si szczeg贸lnie na starcie, generowanie service grapha, generowanie poszczeg贸lnych rzeczy, 偶eby ten feature set by jak najbardziej bogaty i peny. I potem pokazanie, co jest te偶 bardzo wa偶ne, jakie persony z czego bd pewnie najbardziej korzystay. Admini bd mieli zupenie inny przypadek u偶ycia, 偶e tak powiem, inny scenariusz u偶ycia ni偶 developerzy. To bd zupenie inne rzeczy. I dalej idziemy. Konfiguracja retencji i dla performance testowych nie ma sensu pewnych log贸w trzyma. Dzielenie kt贸re rodowiska jak trzymamy, konfiguracja multitenancy, podzielenia widok贸w, dostp贸w i tak dalej, i tak dalej.

**ukasz Kau偶ny**: Dobra, ile to czasu zajmuje? Bo teraz tak, powiedziae o tym caym procesie, kt贸ry mo偶e dla niekt贸rych brzmie w diaby dugo. Wic ile to jest takiej... Wiesz co, mo偶e inaczej, decydujemy si, ile to jest takiej faktycznej pracy?

**Szymon Warda**: I tu jest super nowina, bo trzeba podzieli t prac dwojako. Bo realnie, je偶eli mamy w miar nowy stos, to pracy po stronie zespou developerskiego, czyli po prostu jest relatywnie niewiele. To jest 5-10 bibliotek, albo je偶eli bymy bardzo chcieli, to na starcie to w og贸le u偶ycie podejcia agentowego. Czyli to nie jest totalna wywrotka, 偶e nagle zatrzymujemy development na najbli偶sze dwa tygodnie i wszyscy robi Open Telemetry. Nie, to tak nie dziaa. Wic to jest du偶a warto.

**ukasz Kau偶ny**: Ale inaczej jest robota, bo teraz jest jedna rzecz, ale to bdzie te偶 przy APM-ach, kiedy chcemy faktycznie w te trace'y, metryki dorzuci procesy biznesowe. To tak jak z logami, 偶e trzeba te linijki tam wpisa, jak rozumiem?

**Szymon Warda**: Tak. Trzeba je wpisa, od tego nie uciekniemy. M贸wimy godziny per system. Jak zrobimy za jednym razem, to potem realnie wyekstrachujemy z tego jak prost nasz wewntrzn bibliotek. Prost, kt贸r po prostu dodajemy do aplikacji i ona ma domyln konfiguracj. Na samym starcie wczmy, niech dane lec, a potem mo偶emy to tweekowa za pomoc konfiguracji, za pomoc centralnej naszej biblioteki, kt贸ra zawiera jak konfiguracj domyln, zawiera mo偶liwoci, definiuje co domylnie wczamy i jak wczamy i tak dalej. I to wystarczy. I tu m贸wimy to jest kilka godzin per system, wic czas jest bardzo, bardzo niewielki. Dodatkowo jeszcze mo偶emy zrobi tak opcj, 偶e wczymy albo wyczymy za pomoc feature flagi, 偶eby mie pewno, 偶e wszystko jest w porzdku. Co wicej, jest to bardzo scentralizowane, bo z reguy to robimy na samym starcie aplikacji w jednym konkretnym miejscu. Wic te偶 ryzyko eksplozji po tej zmianie jest relatywnie niewielkie. Teraz drugi koszt. Koszt, kt贸ry m贸wimy, je偶eli chodzi o sam infrastruktur, cay ten stos chodzi sobie bardzo wesoo i przanie i dobrze na Kubernetes'ie. Wic je偶eli dana organizacja ma jakikolwiek klaster platformowy, monitoringowy, a pewnie ma, bo powinna takie rzeczy mie, to w tym momencie postawienie tego jest relatywnie szybk akcj. czymy si adnie, je偶eli chodzi o uprawnienia z prawdopodobnie Entr, kt贸r tam bdziemy mieli, albo dowolnym providerem to偶samoci. Kolejna rzecz to jest podczenie si, je偶eli chodzi o storage, o kt贸rym m贸wilimy. W tym momencie, je偶eli znowu mamy Kubernetesa, mamy narzdzia, to jest pewnie kwestia tylko wygrzebania, kt贸ra usuga daje nam S3. Natomiast je偶eli mamy chmur, jest to jeszcze prostsze, jest to prosta konfiguracja i...

**ukasz Kau偶ny**: Stw贸rz obiekt, tak.

**Szymon Warda**: To jest stw贸rz obiekt, dokadnie, stw贸rz obiekt i wygeneruj klucz dostpowy i dziaa. Kropka. Co si dalej dzieje? Dalej wchodzi troch obszar taki bardziej skomplikowany, czyli wchodzi generalnie tweekowanie i symulowanie jak ten ruch bedzie realnie wyglda. Bo musimy si dostosowa pod to wanie jak, ile log贸w, co, gdzie si dzieje. Bo w tym momencie wczylimy. Bdziemy musieli zerkn na to, co si dzieje na przykad w collectorze, chocia偶by ile wysyamy log贸w info, ile wysyamy, jakie mamy stany do logowania i tak dalej. Ta robota, kt贸ra jest organizacyjna, ona bdzie musiaa si odby. Znowu, robimy to raz, z zasady i tak powinnimy mie, ustalamy... Bo zauwa偶my jedno, te rzeczy byy sabe te偶 w APM albo w innych systemach wczeniej, wic teraz tylko przy okazji je porzdkujemy. I tu jest te偶 bardzo du偶a warto. Znowu, jak damy wasn bibliotek do Open Telemetry, budujemy Open Telemetry, wasn bibliotek, to zmiana formatu logowania we wszystkich systemach staje si relatywnie prost bajk. Wic tu ponownie dobre praktyki. I znowu, jak chcemy i dalej, prosta biblioteczka. Obudowujemy naszego klienta do wysyania, odbierania wiadomoci, 偶eby mie tracing asynchroniczny, przydaoby si. Wczamy na naszym Ingress'ie czy gdziekolwiek, przez co przechodzi nasz ruch, wczamy tracing, 偶eby byy trace'y generowane. To s z reguy wczenie konfiguracji pakiet贸w w istniejce rozwizania. Bo pamitajmy, nie jestemy pierwszymi, kt贸rzy maj te problemy i kt贸rzy te rzeczy robi, relatywnie proste rzeczy. Wic wiele rzeczy robimy, w 3 miesice g贸ra si wyrobimy z caoci rozwizania.

**ukasz Kau偶ny**: W zale偶noci.

**Szymon Warda**: (...) szkolenia oczywicie, w tym czasie s szkolenia.

**ukasz Kau偶ny**: Tak, dobra. To teraz popatrzymy sobie, to dla kogo jest to Open Telemetry z tym stosem open sourceowym? Jakby teraz tak podsumowa cao. Okej, bo powiedzmy, 偶e to jest rabialne w tym momencie, ale dla kogo to jest? Kto jest odbiorc? Kto z tego zyskuje warto?

**Szymon Warda**: Warto najwiksza jest du偶e organizacje, bo one mog powiedzie wszystkim dostawcom swojego software'u... Inaczej, je偶eli same produkuj soft to jest to no brainer, po prostu lemy w tym kierunku, bo po prostu to jest przyszociowe. Je偶eli organizacje zamawiaj soft, to danie specyfikacji, powiedzenie macie by zgodni je偶eli chodzi o observability, zasady Open Telemetry, jest fenomenalne, bo w tym momencie mamy jedn konfiguracj na wszystko i nie bawimy si w wiele APM-贸w w wielu organizacjach. Dla super maych, dla maych firm, kt贸re maj kilkadziesit os贸b i jest to powiedzmy sobie jaki startup, nie do koca, bo tam czasowo atwiej jest po prostu wczy sobie Application Insights, wczy sobie jakiegokolwiek providera chmurowego, m贸wi chmurowego, bo pewnie organizacje bd w og贸le siedziay sobie na chmurze i po prostu tam to dziaa. Natomiast organizacje, kt贸re maj zespoy do monitorowania, gdzie nie tylko developerzy na 偶ywca debuguj produkcje i patrz, co si dzieje, bo je偶eli aplikacje utrzymuj 3 osoby, 5, 10 os贸b, kt贸re doskonale wiedz i to one reaguj, zysk tam bdzie niewielki, bo nie ujednolicamy tego caego stosu. Je偶eli, to co powiedziae te偶 Ty, je偶eli mamy soft, kt贸ry utrzymujemy od bardzo wielu lat, rozwijamy go, nie mamy w planach inwestycji jakichkolwiek w niego, jest jaki wielki monolit - rednia warto. Ponownie, pytanie czy tam nam du偶o pomo偶e jakikolwiek inny APM? Te偶 wtpliwa opcja. No ale co pewnie zrobi. W sensie inwestycja czasowa w Open Telemetry mo偶e nie mie tak du偶ego zwrotu. Stare technologie, jest wsparcie, ono nie jest tak dobre mimo wszystko, je偶eli na przykad migamy sobie po prostu na VM-kach albo na jakich dziwnych hostach.

**ukasz Kau偶ny**: Czyli tak troch podsumowujc, pierwsz tak rzecz jest aktywny development, jest wyznacznikiem, 偶e mo偶na si zainteresowa Open Telemetry.

**Szymon Warda**: Tak.

**ukasz Kau偶ny**: I to od tego mo偶na podejmowa reszt decyzji, czy to sprawdza czy nie.

**Szymon Warda**: Druga opcja to jest to, je偶eli chcemy faktycznie budowa zespoy SRA, czyli taki zamordyzm, 偶eby ujednolici baagan, kt贸ry z reguy providerzy softu dla naszej organizacji wprowadzili, bo to te偶 jest bardzo, bardzo wa偶ny przypadek.

**ukasz Kau偶ny**: Albo sama organizacja swoj bezwadnoci i silosowoci to wprowadzia.

**Szymon Warda**: Nie chciaem tego m贸wi, chciaem to zwali na innych.

**ukasz Kau偶ny**: Dobra i chyba tym mo偶na to podsumowa. Chyba, 偶e chciaby co doda.

**Szymon Warda**: Wiesz co, to co mnie zaskakuje z Open Telemetry to jest to, 偶e stale si rozwija i adopcja jego jest naprawd, naprawd szeroka. Dla developera to jest totalny no brainer, to po prostu trzeba z tego korzysta. Dla organizacji to jest co, czemu idziemy t krzyw, je偶eli za贸偶my chodzi o Tech Radar, to jest co, czemu trzeba ju偶 robi PoC-i, bo za chwil stanie si to standardem og贸lnym mo偶na powiedzie.

**ukasz Kau偶ny**: Chyba jedn rzecz warto sobie powiedzie, 偶e to bardziej 偶yo w Open Telemetry, 偶yje bardziej na skraju tej czci dostawcy bibliotek, inne rzeczy i duzi Big Tech'owi vendorzy ni偶 kocowi u偶ytkownicy, 偶e tam teraz byo bardzo du偶o inwestycji, pracy ze strony wanie du偶ych dostawc贸w, 偶eby to dziaao sp贸jnie.

**Szymon Warda**: Tak i dziaa sp贸jnie. To jest to, 偶e praktycznie te偶 nie ma si co martwi, je偶eli chodzi o przepicie, bo praktycznie ka偶dy du偶y vendor Open Telemetry przyjmie z wielk chci. Wic dla mnie wchod藕cie, po prostu patrzcie, nie lokujcie si z jakim konkretnym vendorem. Open Telemetry te偶 jest t warstw uniwersaln. To jest taki, nie lubimy tego, taki future proofing aplikacji na najbli偶sze powiedzmy 2, 3, 4, 5 lat.

**ukasz Kau偶ny**: Dobra, a je偶eli potrzebujecie z tym pomocy, to Szymon Wam bardzo chtnie pomo偶e. Trzymajcie si.

**Szymon Warda**: Na razie. Hej!

**ukasz Kau偶ny**: Hej!
