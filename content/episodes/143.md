---
title: '#143 Short #66: Cloud Revenue Q4, GPT-4o Copilot, OpenTofu Updates, MSFT Quantum Majorana Chip '
date: 2025-02-28T08:00:00+02:00
episode: "143"
tags: ["Short", "AWS", "Azure", "Google Cloud", "OpenTofu", "Copilot"]
description: "AI agent kasuje kod, cloud revenue rośnie, a GitOps okazuje się pomysłem sprzed dekady. OpenTofu żyje, quantum potrzebuje miliona qubitów. Posłuchaj zanim uwierzysz w hype!"
seo_keywords: "cloud revenue, aws azure google cloud, gpt-4 copilot, github copilot, opentofu terraform, quantum computing, microsoft quantum, cloud computing, devops, infrastructure as code"

# Hugo fields
youtube_id: "W7EF2ML1WX0"
youtube_url: "https://www.youtube.com/embed/W7EF2ML1WX0?enablejsapi=1"

# Social media images (poprawione nazwy)
og_landscape: "/img/143-landscape.webp"
og_square: "/img/143-square.webp"

# Intro for episode
intro: |
  W **Short #66** analizujemy finansowy wyścig gigantów chmurowych z AWS, Microsoftem i Google. Omawiamy nowy model **GPT-4o mini** dla GitHub Copilot i przełomowe funkcje w **OpenTofu 1.9**. Przyglądamy się też pierwszemu chipowi kwantowemu Microsoftu z cząsteczkami _Majorana_.
  
  Cloudflare przechodzi na **Open Telemetry**, co znacząco upraszcza ich infrastrukturę monitorowania. Adidas migruje swoje **Ingress Controllery** w Kubernetes, wybierając standardowe rozwiązanie Nginx. Dyskutujemy również o security.txt i zabawnej wpadce z agentem AI, który _usunął_ kod Coinbase.
  
  Jeśli używasz **OpenTofu** zamiast Terraform, wypróbuj nową pętlę _for each_ dla providerów. Jeśli wdrażasz **security.txt** na swojej stronie, sprawdź usługę Cloudflare do dynamicznego wstrzykiwania pliku. A gdy pracujesz z agentami AI, pamiętaj o _git commit_ przed wydaniem polecenia "usuń wszystko"!
  

# Links for the episode
links:
  - title: "Matt Gowie on LinkedIn: #terralith #terraform #opentofu #infrastructure #infrastructureascode #iac…"
    url: "https://www.linkedin.com/posts/gowiem_terralith-terraform-opentofu-activity-7284639844692115456-Y30L/"
  - title: "Cloud giants continue to struggle with capacity constraints as demand for AI grows"
    url: "https://www.itbrew.com/stories/2025/02/12/cloud-giants-continue-to-struggle-with-capacity-constraints-as-demand-for-ai-grows"
  - title: "Adopting OpenTelemetry for our logging pipeline"
    url: "https://blog.cloudflare.com/adopting-opentelemetry-for-our-logging-pipeline/"
  - title: "New GPT-4o Copilot code completion model available now in public preview for Copilot in VS Code - GitHub Changelog"
    url: "https://github.blog/changelog/2025-02-18-new-gpt-4o-copilot-code-completion-model-now-available-in-public-preview-for-copilot-in-vs-code/"
  - title: "OpenTofu 1.9.0"
    url: "https://opentofu.org/blog/opentofu-1-9-0/"
  - title: "A major update on the ingress controller: Migrating to the new nginx-ingress controller"
    url: "https://medium.com/adidoescode/major-update-on-the-ingress-controller-84cbf448e89c"
  - title: "Microsoft’s Majorana 1 chip carves new path for quantum computing - Source"
    url: "https://news.microsoft.com/source/features/innovation/microsofts-majorana-1-chip-carves-new-path-for-quantum-computing/"
  - title: "Enhance your website&amp;#39;s security with Cloudflare’s free security.txt generator"
    url: "https://blog.cloudflare.com/security-txt/"
  - title: "Cursor f*ck up my 4 months of works"
    url: "https://www.reddit.com/r/cursor/comments/1inoryp/cursor_fck_up_my_4_months_of_works/"
  - title: "RFC 9116: A File Format to Aid in Security Vulnerability Disclosure"
    url: "https://www.rfc-editor.org/rfc/rfc9116"
  - title: "Majorana 1 Explained: The Path to a Million Qubits"
    url: "https://www.youtube.com/watch?v=wSHmygPQukQ&ab_channel=Microsoft"
---

**Szymon Warda**: Cześć, słuchacie Patoarchitektów. Prowadzą Szymon Warda...

**Łukasz Kałużny**: I Łukasz Kałużny. Wszystkie linki do tego odcinka znajdziecie na Patoarchitekci.io lub klasycznie gdzieś tu na dole, dacie sobie radę.

**Szymon Warda**: A co jeszcze można znaleźć Łukasz?

**Łukasz Kałużny**: Wiesz co, dwie rzeczy. Po pierwsze, wstępnie już pierwsze szkolenia na najbliższe pół roku, więc zobaczycie co dla Was przygotowaliśmy tam. Dla osób, które są na mailingu albo były u nas na szkoleniach też są specjalne kody, więc warto sobie na to zerknąć. A więcej na razie nie zdradzam, bo i tak wymęczymy Was tymi ogłoszeniami w przyszłych odcinkach. A druga sprawa, jeżeli ktoś z Was jest bardziej z klimatów cloudowych, a dokładnie azurowych, to jako współorganizator zapraszam na Azur Day'a. Taki bardzo dobry kod zniżkowy znajdziecie też w opisie, tam jest chyba minus 20 lub 25% od regularnej ceny biletu. I jest trochę ciekawych sesji, w szczególności jak ktoś jest od strony DevOpsowej, można naprawdę ułożyć ciekawą ścieżkę na temat sprzątania.

**Szymon Warda**: Dobra, to jak idziemy odnośnie kasy, zniżek, itd., to ja zacznę tym razem. Od czego? Trochę reporterski obowiązek odnośnie tego, że nasi trzej giganci opublikowali swoje wyniki z dochodów jeżeli chodzi o chmurę. Więc lecimy po kolei. AWS 28.8 miliarda dolarów, wzrost 19% względem poprzedniego roku. Jest to tak idealnie względem predykcji, jakie były, finansowych. Microsoft 25,5 miliarda, też 19% wzrostu rok do roku. I Google Cloud 12 miliardów, ale aż 30-procentowy wzrost. To fajnie pokazuje skalę i kto się liczy obecnie. Chociaż przyznam się, że wzrost Google'a jest zaskakujący i robi wrażenie. 30% wzrostu, to jest dużo.

**Łukasz Kałużny**: W tym momencie, w szczególności, że sorry koledzy z Google'a, ale traktujemy was jako taką niechcianą chmurę.

**Szymon Warda**: Parę rzeczy mają fajnych, żeby nie było.

**Łukasz Kałużny**: Żeby nie było, tak. A parę mają źle skopiowanych i wymyślonych.

**Szymon Warda**: I trochę takich niedojrzałych tak naprawdę. No dobrze, ale tyle. Więc kasy dużo się przez to przelewa.

**Łukasz Kałużny**: Wiesz co idzie? Ja nienawidzę tych raportów, bo AWS fajnie to pokazuje. Microsoft i teraz kurde pytanie, które się zawsze pojawia, jak rozbijać SAS-y od PAS-ów i tych offeringów. Plus tam jest też multum rzeczy pochowane, więc z kronikarskiej uczciwości Cloud jest trikiem księgowym.

**Szymon Warda**: Oczywiście, że tak. My w ogóle nie dyskutujemy, ale są to rzeczy, które są publikowane na giełdzie, bo muszą być i będą miały jakiś tam wpływ i każdy chce się tu pokazać i naprężyć swoje mięśnie. Dobra, co tam masz?

**Łukasz Kałużny**: Dobra, dzień bez LLM-ów to dzień stracony. Moglibyśmy się ponabijać o tych niewypałach ogłoszeń o współpracy z nie wiadomo jakimi firmami przez Polskę w kontekście AI-a, gdzie inwestycje są w ich własne data center, czyli kasa wraca do Stanów, więc nie było inwestycji. Ale nie o tym. Wyszedł teraz GPT-4 Copilot, bo tak można nazwać ten model i to jest wewnętrzny model w Copilot'cie do code completion. I co jest teraz ciekawe, bo rzucając tylko liczbami: GitHub wziął 275 tys. open source'owych repozytoriów z 30 najpopularniejszych języków i z tego zrobił training set do fine tuningu GPT-4o mini. Czyli tam mówimy o naprawdę dużej ilości tokenów, które dowalili do tego, co jest ważne, do przetrenowania. Gdzieś się rzuciło takie podsumowanie, że to jest około miliarda tokenów do fine tuningu, co jest naprawdę już niezłym kawałkiem zebranym. I teraz co mnie interesuje? Bo jakość modelu spoko, mogli naprawdę nieźle poprawić takim czymś. Ale 275 tys.? I jak oni wybrali pod tytułem High Quality Public Repositories w tej skali?

**Szymon Warda**: Ilość gwiazdek, prawie na pewno.

**Łukasz Kałużny**: Wiesz co i tutaj jestem ciekaw czy ktoś kiedyś pokaże pipeline, być może walidacyjny codebase, że uznawany jest: tak, użyjmy go do wygenerowania syntetycznie danych czy nie. To jest taka rzecz, którą chciałbym zobaczyć. Ty obstawiasz, że prosto, gwiazdki?

**Szymon Warda**: Gwiazdki, gwiazdki, przy tej skali nie ma... Ewentualnie jakaś walidacja prosta na poziomie czy tam nie nie załapiemy jakiegoś bubla, ale wydaje mi się, że gwiazdki inaczej tego nie zrobisz.

**Łukasz Kałużny**: Dlatego Szymon jestem ciekaw w jaki sposób oni to ograli, ten pipeline danych. To jest taka rzecz, jeżeli patrzysz na to i myślisz, no to jest ciekawe przy tej skali, jak taki ETL, nazwijmy to data engineering wygląda.

**Szymon Warda**: Dobrze Łukasz, teraz...

**Łukasz Kałużny**: Dobra, dajesz.

**Szymon Warda**: Ty mówisz, że dzień bez LLM-a, a ja powiem, że rok bez OpenTofu rokiem straconym, więc Twoje...

**Łukasz Kałużny**: Ale coś robią.

**Szymon Warda**: Ja twierdzę, że jak najbardziej robią. Mimo naszej predykcji, że oni jednak umrą, to to generalnie się dalej ciągnie, dalej żyje. Weszło OpenTofu 1.9, przede wszystkim nadal żyje. Co weszło? Parę weszło rzeczy ciekawych, ale też trochę niepokojących. Wszedł exclude, czyli możliwość deploy'owania z zaznaczeniem, które z zasobów nie deploy'ujemy. To brzmi fajnie, ale równie niebezpiecznie. Weszła też pętla for each i tam jest cytat odnośnie tego, komentarz: If you know what you're doing and you don't point it at your own foot, this could be a fantastic addition to your IaC toolbox on tofu. Nie wiem skąd wynika ten strach  przed for\_each'em tak naprawdę.

**Łukasz Kałużny**: Ja też nie wiem, tak jak z count'em. Ale Szymon np. for_each'a, to jest teraz taki moment, taki delikatny z tym for_each'em, gdzie nawet nie wyobrażasz, jak ja bym uprościł pipeline przez to, bo to jest for\_each dla providerów, czyli dynamiczne tworzenie providerów.

**Szymon Warda**: Ja sobie zdaję sprawę. To powinno być tak naprawdę, więc no ok. Ale jeszcze jest trzecia wiadomość, która w ogóle mnie nie ucieszyła.

**Łukasz Kałużny**: Wiesz co, tylko pozwól, dlaczego mówię, że dla mnie ten for\_each for providers to jest faktycznie przemyślana rzecz? Bo zobacz, że pozbywasz się potrzeby kombinowania z takim terragruntem, dynamicznego provisioningu. U jednego z naszych klientów w takim case platformowym pull requestem powołujesz całą subskrypcję i sieć. I tam niestety są dwa różne pipeline'y, które jedna robi provisioning sieci, generuje jakieś template'y, a dopiero potem jest odpalany właściwy kod platformowy, żeby usadzić tą subskrypcję, bo niestety Terraform nie pozwala Ci w locie stworzyć subskrypcji z nowym providerem. Nie zrobisz tego dynamicznie.

**Szymon Warda**: Wiem i też z tym walczyłem. Mnie po prostu zaciekawiło, że to nie było od dawna wrzucone, takie rzeczy powinny być. Perełką tego, co powinno być od dawna, to jest ulepszenie konsoli, bo konsola teraz obsługuje breakline'a.

**Łukasz Kałużny**: Małe a cieszy.

**Szymon Warda**: Raczej bardziej bym powiedział przerażające, że tego nie było już od dawna tak naprawdę, bo akurat już tam w Terraformie jakiś czas nie siedziałem. No ale mimo wszystko to jest takie, raczej nie są to rewolucje w tym OpenToffu. To się ciągnie, żyje, ale taka jakość tego życia jest taka różna, bym powiedział.

**Łukasz Kałużny**: No ale tak, powiedzmy wiesz, też dodając to, że wrócili, dorzucili tam, jak popatrzymy support w JetBrains'ach, Visual Studio Code jest spoko. I wiesz, np. rzecz, która mnie bardzo cieszy, która pokazuje, że jest to też produkt open source'owy, mimo że tam hejtujemy, to rzecz, która jest ciesząca w OpenTofu, to np. że dodają te feature'y, które HashiCorp specjalnie nie dodawał, żeby zmusić się do wersji Enterprise, rzucając nawet przykład na screenie tak chamsko pokazany szyfrowanie stanu.

**Szymon Warda**: To w ogóle wróciło jako jedno z pierwszych swoją drogą dawno temu.

**Łukasz Kałużny**: Tak, to było od razu, to było od razu.

**Szymon Warda**: To było świetne, z tym się zgadzamy. Niech OpenTofu się rozwija jak najbardziej, bo HashiCorp, Terraform był świetny, wyszedł jako pierwszy tak naprawdę. I co tam było? I to był produkt, który był przez wiele, wiele lat zapomniany po prostu, leżał sobie i był nierozwijany praktycznie. Więc super, fajnie, że ktoś pokazał, że można.

**Łukasz Kałużny**: Niektórzy nas zabiją jak mówimy, że te małe drobne poprawki to nie rozwijanie.

**Szymon Warda**: Pamiętam sesję z Terraforma bardzo wiele lat temu, wygląda dalej podobnie. Dobrze, lecisz teraz Ty.

**Łukasz Kałużny**: Dobra, to idziemy dalej. Teraz nabijanie się z LLM-ów, dzień stracony znowu. Cursor fuck up my 4 months of works. Czyli to jest taka rzecz, którą zauważyłem, bo ostatnio też siedzę trochę, używałem trochę Cursora i ten agent mode, w nim naprawdę coś potrafi, jak wiesz jak oczywiście nim wysterować. I tutaj jest klasyka, która się przewija. Oczywiście pewnie nie mógł czegoś zrobić, więc stwierdził, że skasuje codebase, Cursor agent stwierdził, że skasuje codebase. Ktoś pewnie kliknął czy co innego zrobił, czy mu przerefaktorował kod i solucji nie ma. I tak to jest jak osoby, które nie umieją kodować albo w ogóle nie mają jakiejkolwiek wiedzy na temat używania komputera do celów informatycznych, to nazwijmy, zaczynają produkować kod jakby to był nocode i dziwią się, że trzeba robić backupy, posiadać Gita.

**Szymon Warda**: To co mówiliśmy od dawna. Na chwilę obecną wszystkie Copiloty podobno są świetne jeżeli chodzi o wsparcie, rzeczy drobne, jako coś wspomagającego. To nie jest tak jak jest reklamowane na prezentacjach, które fajnie wyglądają, że my tylko piszemy językiem naturalnym, mamy: zróbmy to, a on zakoduje nam cały projekt. Tak nie działa no, nie oszukujmy się.

**Łukasz Kałużny**: Przy czym chciałbym... Inaczej, szkoda, że nie mam kasy na opatentowanie, bo wrzuciłbym patent autocommitu i autopusha.

**Szymon Warda**: I jeszcze autodeploya, może tak od razu.

**Łukasz Kałużny**: To już wiesz, to już jest. Ale autocommit i autopush. I w jednej dyskusji już ktoś zwrócił uwagę, że potem dostaniemy nowy ten, bo AI doda minus minus force przy pushu, jak nie będziesz w stanie zmerge'ować.

**Szymon Warda**: Czemu nie. Dobra, żeby nie było, że się dzisiaj tylko nabijamy, to jedna rzecz faktycznie użyteczna. Nowy RFC, plik security.txt. Rzeczy które małe a cieszą. O co chodzi? To jest standard do umieszczania informacji jak raportować wykryte podatności na stronie, czyli informacje kontaktowe, itd. Co przy okazji tego jest? Przy okazji tego oczywiście nasz ulubiony, nielubiany Cloudflare opublikował, zrobił swój serwis, który umożliwia tak naprawdę wstrzykiwanie pliku security.txt dynamicznie.

**Łukasz Kałużny**: W locie.

**Szymon Warda**: Dokładnie tak. Czyli nie trzeba tego umieszczać, bo to jest tam umieszczane w root'cie strony. Jak skorzystamy z Cloudflare'a, to nawet nie musimy tego umieszczać na informacji, tylko po prostu konfigurujemy sobie to w Cloudflare i jak zapytanie idzie, to Cloudflare to wstrzyknie ładnie. Ogólnie no co tu więcej dodać? Jest to tak samo przydatne przy stronach publicznych jak powiedzmy robots.txt przy indeksacji Google'owej i innych robotów, chociaż teraz już są przez LLM-y ignorowane, niech będzie. Fajne, przyjemne, dobrze to mieć, bo możemy się dowiedzieć o jakiejś podatności zanim zostanie wykorzystana załóżmy przez jakiegoś dobrego duszka albo kogoś, kto nie chce nam tego wykorzystywać. Jest to całkowicie za darmo. Oczywiście sam standard i usługa Clouflare'a. Także co? Brać i korzystać, bym powiedział.

**Łukasz Kałużny**: Jeszcze tak, aż takie nowe to RFC nie jest, usługa jest nowa.

**Szymon Warda**: No nie jest, tak, usługa jest nowa. Tak, tak, RFC już istniał jakiś czas, ale zostało ładnie opakowane.

**Łukasz Kałużny**: Dobra. No to lecimy z ogłoszeniem którego musiałem. Microsoft ogłosił swój pierwszy chip kwantowy. Jak to się tam powinno wymawiać Szymon, bo ja zawsze mam z tym problem. Majora? Majorana?

**Szymon Warda**: Wydaje mi się, że majora, bo z Zeldy podobna była rzecz. Tam było Majora's Masks.

**Łukasz Kałużny**: Dobra, i o co chodzi? Microsoft zaprezentował, jest tam coś, co nazywają materiał topconductor i pierwszy chip, który wykorzystuje właśnie te cząsteczki majory. Można powiedzieć, że to są antycząsteczki, jak tam pójdziemy, fizyka kwantowa niestety w tym. Ale teraz co jest ważne? 8 kubitów, czyli jeżeli chodzi o wykorzystanie nie nadaje się do niczego poza dalszym rozwojem. I teraz tak, jak popatrzymy sobie na optymizm i inne rzeczy, że będziemy mieli procesor kwantowy pod biurkiem, ludzie zapominają wspomnieć, że to wymaga prawie temperatury zera bezwzględnego do pracy.

**Szymon Warda**: Bo powyżej tej temperatury wszystkie zachowania kwantowe zaczynają się rozmywać.

**Łukasz Kałużny**: Tak, więc pierwsza to bardzo duże schłodzenie. Ale dwie rzeczy, które są ciekawe, to jest jego wielkość. Czyli sam chip mieści się na dłoni. I to jest jedna taka rzecz, że wielkościowo upakowanie plus ta nowa wielkość. Druga sprawa, która tutaj występuje, za co szanuję, ktoś wreszcie powiedział w announcement'cie, że sorry, potrzebujemy około miliona takich kubitów, żeby to miało sens.

**Szymon Warda**: No tak, że to jest duża różnica, ponieważ poprzednio chwalono się, że tak mamy 20, mamy 10, że 128 już w ogóle wystarczy i będzie super tak naprawdę. Ale to wszystko kończyło się tym, że to było tłuczenie piany i robienie hype'u wokół tego wszystkiego tak naprawdę. Ogłoszenie prawdziwe faktycznie. Co z tego wyniknie? Ja już słyszałem pierwsze komentarze, bo Microsoft przy okazji opublikowania tego chipa opublikował też kilka papierów naukowych i tam już są jakieś wątpliwości odnośnie tego, czy to faktycznie jest tak przełomowe i czy tam, czy jednak nie ma hype'u w tym papierze. Zobaczymy co będzie się jeszcze rozwijało.

**Łukasz Kałużny**: Inaczej, czy jest to kierunek rozwoju, który jest istotny? Tak. Czy będzie to przełom? Dowiemy się za parę lat. Przynajmniej nikt nie mówi, że ten, ile tam było? 64 kilo RAM-u wystarczy dla każdego?

**Szymon Warda**: Jakoś tak. I jeden komputer na kraj. Wiesz co, zobaczymy jak to będzie wyglądało. Rewolucji to nie zrobi. Już mamy, przecież niejednokrotnie mówiliśmy o kryptografii postquantumowej, jakkolwiek to nazwiemy. Więc czy to będzie miało duży wpływ? Nie, na przeciętnego człowieka nie będzie miał wielkiego wpływu.

**Łukasz Kałużny**: Raczej w pewnym momencie, jak ktoś wymyśli, jak trenować na tym modele AI-owe i inne przetwarzania, tak, będzie miało.

**Szymon Warda**: Ale to jeszcze daleko, żeby to była ta skala.

**Łukasz Kałużny**: Tak, milion kubitów.

**Szymon Warda**: Dobrze.

**Łukasz Kałużny**: Dobra.

**Szymon Warda**: Idziemy dalej. Można zauważyć, że nadrabiałem blog Cloudflare'a, bo kolejny news cloudflare'owy. Ale ten jest całkiem, całkiem fajny. I to jest tym razem dość długi, dość dobry wpis, więc zachęcamy też, jakbyście byli bardziej zainteresowani. Adopting OpenTelemetry for our logging pipeline, czyli co tam się zmieniło? Cloudflare zmienia swojego syslog-ng daemona na open telemetry. No i biorąc pod uwagę ich skalę i tego ile oni logują, to jest dość zauważalne i przede wszystkim to jest docenienie tego, co się dzieje w open telemetry. Czemu oni to zmieniają? To jest w ogóle ciekawe, bo syslog-ng jest w C, a to nie jest ich główna kompetencja. I naprawdę podziwiam za taką decyzję, bo ona jest bardzo zasadna. Faktycznie oni tam zmieniali, parę rzeczy potrzebowali. Problemy z wykorzystaniem postquantum bibliotek do kryptografii w syslog-ng. Collector do open telemetry ma wbudowane wsparcie dla Prometheusa faktycznie, więc to im dużo ułatwia po prostu, mogą się pozbyć części rzeczy, które mają, a i tak wykorzystują open telemetry do tracingu. Swoją drogą chciałbym zobaczyć tracing w ich skali, bo to będzie ciekawe. Jakie mają...

**Łukasz Kałużny**: Bardziej z tym tracem jestem ciekaw jaki procent trafia tych logów faktycznie w ramach...

**Szymon Warda**: Promil albo jak długo to trzymają. Tak, to mnie zaciekawiło głównie, tak. Jakie mają problemy? Mieli własny format logowania i będą musieli jakoś tam z tym przeżyć i pozmieniać. W ogóle format, który mieli, mieli bardzo sprytny, bo mieli pole format i mieli pole body, gdzie mieli cały tekst tego logu, a format mieli po to, żeby na odpowiednie topics Kafki to wszystko powrzucać. No oczywiście jest tam Kafka, żeby to wszystko buforować, dość popularne tak naprawdę. Ale docelowo chcą przejść na cały standard open telemetry. Pytanie czy to... Bo ich największą wartością jest korzystanie z Collectora open telemetry, który faktycznie jest fajny, bez dwóch zdań. Jestem ciekawy jak im się to sprawdzi długofalowo i wpisów odnośnie tego jak im to działa. Tak że wpis ciekawy. Może będę musiał przemyśleć swoje podejście właśnie do logowania z open telemetry. Zobaczymy.

**Łukasz Kałużny**: O, groźnie brzmi.

**Szymon Warda**: Tak to raczej sensowność tego była średnia. Ale oni z prostego powodu. Czemu? No bo pisanie tylko i wyłącznie do strumienia open telemetry, czyli pushowanie takie mało sensowne. Ale pisanie do pliku i potem Collectorem do open telemetry, to już ma sens. To już jest fajne.

**Łukasz Kałużny**: Dobra, kolejna rzecz z tych wpisów, które gdzieś tam mi się starszych trafił, ale wyskoczył, to jest wpis Adidasa na temat migracji do migracji i sprzątania Ingress Controllerów.

**Szymon Warda**: Widziałem go, tak.

**Łukasz Kałużny**: Wiesz co? Jest jedna rzecz, którą ja tylko z jednego powodu go tutaj wrzucam.

**Szymon Warda**: No?

**Łukasz Kałużny**: Bardzo prostego. W większości przypadków, jego mać, nie potrzebujesz więcej niż nginx. Technologicznie, jak budujesz platformę Kubernetesa, to jest rzecz... Zobacz, że wybrany został najpopularniejsze, najbardziej standardowe rozwiązanie. Tutaj oczywiście delikatnie tam stuningowali pod swoje potrzeby. Ale co jest bardzo ważne, z jednej strony AWS load balancer na wejściu, a potem już jako Ingress Controller nginx. I z jednej rzeczy, którą podają, które potrzebowali, to wreszcie wystandaryzować u siebie na platformie Ingress Controller.

**Szymon Warda**: Tak, te wpisy z Adidasa pojawiają się i są całkiem, całkiem okej, ale widać, że tam trochę hype'u było przez jakiś czas.

**Łukasz Kałużny**: Tak, to jest ciekawe. Zobacz, uproszczonko, bierzemy zwykłego, najprostszego i wystarczy Wam.

**Szymon Warda**: Tak, wystarczy. Dobrze. Coś jeszcze Łukasz masz?

**Łukasz Kałużny**: Wiesz co? Mamy coś, co dyskutowaliśmy przed odcinkiem z pewnego newslettera.

**Szymon Warda**: Ja się powstrzymałem.

**Łukasz Kałużny**: Tak, a ja stwierdziłem, że wrzucę. I problem jest następujący. O czym był wpis może właśnie? Że tradycyjne potoki CI/CD są niedoskonałe i adoptuj GitOpsa. Czyli buduj oddzielnie, rób CI paczek. Ja myślałem, że CI powstało wcześniej niż CD. Tak. A wdrażaj CD z GitOpsem i że to jest prawdziwa poprawa setupu.

**Szymon Warda**: Znaczy tak jeszcze doprecyzuję właśnie, bo pierwsze założenie było takie, że przez lata robiliśmy niby CI/CD, czyli budowaliśmy aplikację i od razu ją wdrażaliśmy i to był jeden połączony potok. A tu jest propozycja tego, że osobno budujemy paczki i potem tą paczkę wykorzystujemy przy deployment'cie właśnie gitopsowym. Ja pamiętam, że w projekcie 10 lat temu wdrażaliśmy, rozbijaliśmy to osobno i tak wyglądało, wtedy nienazwane było to może GitOpsem, ale działało bardzo dobrze i bardzo podobnie. Tak że...

**Łukasz Kałużny**: Wiesz co, ja próbuję sprawdzić w tym, czy Visual Studio, właśnie teraz mnie tak naszło, refleksja. Pamiętasz, było kiedyś Visual Studio Online.

**Szymon Warda**: Było, tak.

**Łukasz Kałużny**: Było zanim jeszcze się nazywało to Azure DevOps i Visual Studio TeamServices potem.

**Szymon Warda**: Tak.

**Łukasz Kałużny**: I teraz próbuję sprawdzić jedną rzecz. Czy już wtedy, moment, muszę znaleźć gujacza, release pipeline'y, uwaga, release pipeline'y, bo już sobie teraz sprawdziłem, 7 lat temu były normalnie w SAS-owej wersji tego, co jest teraz Azure DevOps'em. Wydzielone zupełnie od CI-a, gdzie podawałeś na wejściu paczki jakie będą wdrażane i artefakty.

**Szymon Warda**: Jest to podejście stare, ustalmy i może już się nad tym wpisem tutaj nie bestwmy.

**Łukasz Kałużny**: Raczej inaczej, usilna próba pokazania, że GitOps jest cool. A ja tak sobie przypominam wszystkie Octopusy i inne takie rozwiązania, które istniały... Inaczej, oddzielne rzeczy do CI-ów. Sorry, to już było.

**Szymon Warda**: Było, jest cały hype wokół CI/CD i był wiele lat temu. Dobrze, kończmy.

**Łukasz Kałużny**: Tak, kończmy, bo byśmy się znęcali nad tym nieszczęsnym GitOpsem. Trzymajcie się, na razie.

**Szymon Warda**: Hej.

