---
title: '#153 Google Cloud Next 2025 '
date: 2025-05-09T08:00:00+02:00
episode: "153"
tags: ["Konferencja", "Google Cloud", "AI", "Kubernetes", "DevOps", "Cloud Native"]
description: "Google Cloud Next 2025: rok AI agents oficjalnie wystartowa. Agent to Agent Protocol, TPU Ironwood, Kubernetes inferencing. Co Google zabije tym razem?"
seo_keywords: "google cloud next, gemini, ai agents, tpu ironwood, agent to agent protocol, vertex ai, google cloud, observability, kubernetes, cloud native, devops"

# Hugo fields
youtube_id: "h5Rwd7Ty7kg"
youtube_url: "https://www.youtube.com/embed/h5Rwd7Ty7kg?enablejsapi=1"

# Spreaker data (technical only - for Schema.org, not user-facing)
duration: "PT25M33S"
audio_url: "https://api.spreaker.com/v2/episodes/65993114/download.mp3"

# Social media images (poprawione nazwy)
og_landscape: "/img/153-landscape.webp"
og_square: "/img/153-square.webp"

# Intro for episode
intro: |
  **Google Cloud Next 2025** otwiera sezon konferencji hyperscaler贸w z **Agentic AI**  na pierwszym planie. Google zaprezentowa przeomowy **Agent to Agent Protocol** , kt贸ry stanowi fundament komunikacji midzy agentami. Czeka nas rok peen "Agentic, Agentic, Agentic" .
  
  W odcinku analizujemy **TPU Ironwood** (10x wydajniejsze ni偶 poprzednia generacja) i **Google Agentspace** . Omawiamy tak偶e **Unified Security**, **Gemini Code Assist** oraz kompatybilno **Firestone z MongoDB**. **Chrome Enterprise Browser**  zaskakuje mo偶liwociami przeszukiwania zasob贸w lokalnych.
  
  Chcesz wiedzie, czy **ADK** przetrwa du偶ej ni偶 inne projekty Google?  Posuchaj naszej dyskusji o przyszoci **agent-to-agent communication** i zrozum, dlaczego wszyscy dostawcy chmury bd teraz kopiowa te rozwizania .
  

# Links for the episode
links:
  - title: "Google Unified Security"
    url: "https://cloud.google.com/security/google-unified-security?hl=en"
  - title: "Ironwood: The first Google TPU for the age of inference"
    url: "https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference"
  - title: "Firebase Studio lets you build full-stack AI apps with Gemini"
    url: "https://cloud.google.com/blog/products/application-development/firebase-studio-lets-you-build-full-stack-ai-apps-with-gemini"
  - title: "About AI/ML model inference on GKE"
    url: "https://cloud.google.com/kubernetes-engine/docs/concepts/machine-learning/inference"
  - title: "Nie dla miczak贸w: Patoszkolenia, kt贸re zmieniaj zasady gry!"
    url: "https://patoarchitekci.io/szkolenia"
  - title: "AlloyDB AI natural language overview"
    url: "https://cloud.google.com/alloydb/docs/ai/natural-language-overview"
  - title: "About GKE Inference Gateway"
    url: "https://cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway"
  - title: "Announcing the Agent2Agent Protocol (A2A)"
    url: "https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability"
  - title: "Announcing Firestore with MongoDB compatibility"
    url: "https://cloud.google.com/blog/products/databases/announcing-firestore-with-mongodb-compatibility"
  - title: "Google Agentspace"
    url: "https://cloud.google.com/products/agentspace?hl=en"
  - title: "Agent Development Kit: Making it easy to build multi-agent applications"
    url: "https://developers.googleblog.com/en/agent-development-kit-easy-to-build-multi-agent-applications"
  - title: "Live API reference"
    url: "https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/multimodal-live"
---

**ukasz Kau偶ny**: Cze, suchacie Patoarchitekt贸w. Prowadz ukasz Kau偶ny...

**Szymon Warda**: I Szymon Warda. A linki do tego odcinka Patoarchitekci.io, w opisie, wygoogle'acie, ogarniecie, wierzymy w Was. Dobrze ukaszu, last call na szkolenia.

**ukasz Kau偶ny**: Last call, tak, jak tego suchacie, to ostatnia szansa na Architektur 101, kt贸r prowadz. W sumie taka cie偶ka na sterydach jak myle o architekturze, je偶eli tego jeszcze nie robilicie i chcecie si nauczy system designu, a mo偶e, nie oszukujmy si, usysze wprowadzenie do system designu, bo potem trzeba i tak jeszcze zdoby dowiadczenie. A zaraz po mnie Szymon ma Observability.

**Szymon Warda**: Dokadnie, na grafanowym stosie. A jak kto by chcia jeszcze odnonie tego dowiadczenia, to jeszcze pamitajcie, 偶e tam szukamy kogo, tak przy okazji, 偶e tak powiem. Tak 偶e wysyajcie. Co dzisiaj?

**ukasz Kau偶ny**: Dzisiaj ustawiamy tempo i tematy konferencji na ten rok w Big Techach. Chyba tylko GitHub mo偶e bdzie ciut inny w pa藕dzierniku, bo maj wicej rzeczy developerskich, a mianowicie dzisiaj omawiamy Google Cloud Next.

**Szymon Warda**: AI, Gemini.

**ukasz Kau偶ny**: Gemini, tak. Suchajcie, na powa偶nie, je偶eli popatrzycie, to tak, bdzie to AI, AI, agenci, AI. I tak, suchajcie, bd wyglday prawdopodobnie konferencje z lekkim odchyem pewnie w AWS-ie mo偶e, bo oni zawsze jednak tej infry i takich usug pobocznych troch wicej pokazuj. Ale to si bdzie dziao.

**Szymon Warda**: Dobra, to w og贸le zaczo si od tego, 偶e oni si pochwalili bardzo mocno, ile to developer贸w nie korzysta z Gemini i tam jest ju偶 4 miliony developer贸w, 20 razy wicej, 20-krotny wzrost w Vertex AI usage. Nowe TPU, Ironwooda wypucili. Odnonie tego, tak zaczn od tego, jest to, 偶e takim elementem, kt贸ry powoduje, 偶e co nie jest super, jest to, jak por贸wnujemy to do pierwszej wersji w og贸le tego. No i faktycznie Ironwood jest si贸dm generacj. Por贸wnuj go bardzo gonym liczbami, 偶e 3600 razy bardziej wydajny ni偶 ich pierwsze TPU, 29 razy bardziej wydajne energetycznie ni偶 pierwsze TPU, wic znaczy, 偶e chcieli mie adne numerki, itd. Troch tak bardziej drobnym tekstem jest, 偶e realnie to jest 10 razy bardziej wydajny ni偶 poprzednie, co ju偶 jest te偶 dobrym wynikiem, bo nie oszukujmy si cakiem nie藕le i cznie 42,5 exaFLOP-a per node obliczeniowy. Ale teraz w kontrze do tego, oczywicie ogosili tu偶 poni偶ej, 偶eby nie byo, 偶e te偶 wsparcie dla Configuration Computing Nvidii jak najbardziej bdzie, na DGX, B200 i te偶 na Blackwellu generalnie i ciekawe przy wsp贸pracy z Dellem. Nie wiem czy to wyapae, co jest do ciekawe, bo...

**ukasz Kau偶ny**: Wiesz co, nie, musieli z kim to zrobi, to nie jest... Wiesz, to jest te偶... Oni te偶 mocno z nimi wsp贸pracowali, jakby popatrzy na wczeniejsze. Wiesz co, to jest wsp贸praca, kt贸r patrzysz Szymon... Okrelibym tak, bo oni te偶 mieli VMware'a wczeniej, bo pamitaj, 偶e Dell mia VMware'a i by, je偶eli dobrze pamitam, rekomendowan platform do ich tego GKE lokalnego stawianego na VMware. Ju偶 za chiny nie pamitam jak to si zwao, to lokalne GKE.

**Szymon Warda**: Chodzi mi o co innego. Przy tej skali to czsto robi si ju偶 co mimo wszystko wasnego, ale wydaje mi si, 偶e im si bardziej troch pali pod wiadomo jak czci ciaa.

**ukasz Kau偶ny**: Czy realnie... Nie, dostarcza... Hardware dostarczany do klienta kocowego to jest taki wrz贸d, 偶e si nie dziwi, w modelu operacyjnym.

**Szymon Warda**: Do serwerowni, do serwerowni, klient kocowy to oczywicie inna bajka.

**ukasz Kau偶ny**: W sensie do serwerowni, odbiorcy, dostarczanie. Zobacz, 偶e tak, outpost zgin w tym, Microsoft r贸wnie偶, przecie偶 wszystkie te Azure Local i inne rzeczy, z Stack HCI te偶 wypchn na partner贸w totalnie. Prawdopodobnie jakbymy weszli to tego serwera od Azure Stack Local, czy jak to si tam kiedy nazywao, do IoT i innych rzeczy, pewnie nie zam贸wisz z Microsoftu, wic wszyscy tak chowaj.

**Szymon Warda**: Znaczy nie, no oczywicie. Wydaje mi si, 偶e mimo wszystko mogliby to bardziej zoptymalizowa. No ale tak czy siak no chwal si wasnym TPU i za chwil chwal si tym, co z Nvidia. Ale wydaje mi si te偶, 偶e te fajne wyniki sprzeda偶owe, kt贸re Dell pokazywa, wanie czciowo wynikay z tego.

**ukasz Kau偶ny**: Tak. Raczej wczeniej wynikay z serwer贸w dla AI-a na zerowej mar偶y. Tak byo. Tak i suchaj, polemy sobie nastpnym newsem, kt贸ry jest ciekawy. To jest Google Unified Security, czyli dla tych co siedz w Microsofcie, to Microsoft Copilot Security i Sentinel. Czyli rozwizanie do Security Operation CRED Intelligence, odpowiadania na incydenty, bla bla bla. Ale oni... Inaczej, na dwoje babka wr贸偶ya, albo bdzie to dowozio, albo bdzie ssao po caoci. Nie bdzie po rodku.

**Szymon Warda**: ukasz, nie ma to jak dobra predykcja, powiem Ci tak.

**ukasz Kau偶ny**: No ale to jest w Google'u. Bo inaczej, znajc, wiedzc od znajomych przy piwie jak pewne rzeczy u nich wygldaj, to dla klienta kocowego to jest tylko zerojedynkowy wynik. Albo dowioz, albo nie dowioz, nie bdzie nic porodku. I dwie rzeczy, kt贸re mnie zainteresoway w tym. To pierwsze, pokazali agenta, kt贸ry mo偶e by dobry do automatycznego tria偶u zgosze, tych SOC-owych wanie, bo to jest ten Unified Security, to jest po prostu offering platformy SOC-owej, je偶eli na to tak popatrzymy i SIEM-owej i agent do analizy malware. Wic to s dwie takie rzeczy wpite, kt贸re s ciekawe. No i Ty zobaczye jeszcze Enterprise Browser.

**Szymon Warda**: Chrome Enterprise Browser i tam jest kilka rzeczy. Po pierwsze, to jest wcity adnie w ten cay mechanizm security. Ale jedna rzecz, kt贸ra jest mega fajna z punktu widzenia takiej osoby ju偶 wewntrz organizacji, 偶e z poziomu tego wyszukiwania, czyli okienka chromowego, bdzie przeszukiwanie zasob贸w lokalnych wanie z wykorzystaniem agent贸w. I ok, wyszukiwanie zasob贸w lokalnych nie jest 偶adn rewelacj, SharePoint to robi od dawna, ale ktokolwiek szuka tam, to nie dziaa tak dobrze. Je偶eli faktycznie wyniki bd lokalne, to to jest tak niesamowite, fajne osignicie, je偶eli chodzi o dostpno rzeczy i przeszukiwalno organizacji wewntrz, 偶e wow.

**ukasz Kau偶ny**: Pamitasz, kiedy ten Google Search te偶 dziaa, taki plugin, co Ci indeksowa lokalnie by, takie lata temu, jak i te serwery...

**Szymon Warda**: Wczeniej byy takie serwerki, takie 1U i takie 2U [niesyszalne 00:07:22].

**ukasz Kau偶ny**: A jeszcze mo偶na byo kupi, tak, local, tak. Wrzucimy Wam o czym m贸wimy, to ja zapisz sobie w linkach i Wam wrzuc.

**Szymon Warda**: To nawet mo偶na byo kupi jakie par lat temu na Allegro za jakie tam 3 czy 5 st贸wek.

**ukasz Kau偶ny**: Tak. Google Appliance, sobie zapisze, 偶eby dorzuci.

**Szymon Warda**: Fajnie to wygldao w og贸le.

**ukasz Kau偶ny**: Tak. I suchajcie, to jest to. Przejd藕my teraz do news贸w takich AI-owych, kt贸re si pojawiaj. Jest tego masa, wikszo w og贸le nie warta uwagi, jak sobie popatrzymy, ale zaczbym od tego i to jest podmiechujka, bardzo celowa, w Vertexie, Vertex AI pokazywa si live API, suchajcie. Czyli suchaj Szymon, te fejkowe demo sprzed 5 lat, to chyba byo, nie pamitam czy to jest z 2021 czy z 2019, by zrobiony, 偶e agent AI, bo oni wtedy te偶 ju偶 to mocno robili, 偶e potrafi Ci zadzwoni i um贸wi wizyt.

**Szymon Warda**: Synne spotkanie generalnie, 偶e dzwoni, przekada, synchronizuje si z kalendarzem, itd.

**ukasz Kau偶ny**: Tak, i to live API to jest co, co mogoby pozwoli, 偶eby tam to zadziaao. Czyli live API, chodzi o to, 偶e model voice'owy z bardzo niskimi op贸藕nieniami do real time interaction.

**Szymon Warda**: To jest okej, fajne. Czy mo偶e pozwoli? Ja bym to bardzo chcia zobaczy i jako w to nie wierz do koca mimo wszystko.

**ukasz Kau偶ny**: Raczej Szymon, dlatego m贸wi, 偶e podmiechujka.

**Szymon Warda**: Tak. Z rzeczy powa偶niejszych, takich odnonie wanie, jak m贸wimy, wykorzystania wanie LLM-贸w, to jest natural language support in AlloyDB. Brzmi bardzo, bardzo, bardzo powa偶nie, ustalmy, no nie. Ale jak teraz wejdziemy teraz w co tam wanie siedzi, to jest tak: wsparcie do generowania kwerend na bazie jzyka normalnego, generowania fleet management, czyli generowania zarzdzania caoci i do operations. Ale efekt jest taki, 偶e my m贸wimy, a on potem generuje kod, kt贸ry jest wykonywany. Nie jest to robione z tak [niesyszalne 00:09:28], 偶e my m贸wimy - on robi.

**ukasz Kau偶ny**: Suchajcie, ale teraz tak, jest jedna rzecz, przepraszam za to okrelenie, ale zajebicie wyglda SQL-ka, bo masz: SELECT alloydb_ai_nl.get\_sql i w rodku string np. z sampla. What is the sum that client number 4"s account has following transaction 851? I to jest w select'cie. W SQL-u macie stringa, w kt贸rym wysyacie zapytanie.

**Szymon Warda**: Wic jestem ciekaw jak to si finalnie skoczy.

**ukasz Kau偶ny**: Ale SQL Injection nowej generacji, zobacz.

**Szymon Warda**: Tam bdzie si dziao. Ale jak jestemy przy pomier贸偶nych, 偶eby by bardziej przedszkolofriendly, 偶e tak powiem, to mnie rozwali jeden cytat. To byo odnonie system贸w do monitorowania. Kto m贸wi, 偶e: indeed, our systems used to fail in fairly predictable ways, said another presenter, cofounder and CTO of Honeycomb. Czemu si nabijamy? Bo byo troch, bo Conecon, czyli cae Observability 2.0 i w og贸le chwalenie si, by moment, 偶e niesamowicie du偶o wanie byo narzekania, 偶e oni si non stop wywalali, 偶e to byo super niestabilne. I te wszystkie ich obiecanki odnonie tego, 偶e to bdzie super wydajny i w og贸le super, macie tylko logi i tyle, no to wanie tak to si koczy. Ja jako CTO bym si mo偶e nie chwali tego, 偶e to si po prostu wywalao i 偶e byo...

**ukasz Kau偶ny**: Do monitoringu.

**Szymon Warda**: Tak, znaczy na konferencji partnera, no ale jak tam kto woli. Dobrze, co powa偶niejszego jeszcze, co tam masz?

**ukasz Kau偶ny**: Dobra, i teraz tak, podzielibym to sobie na dwie rzeczy. Stopniujc od najbardziej istotnej rzeczy. Bo jest jedna rzecz na tej konferencji, z kt贸rej sorry, nie bdzie podmiechujek z AI-a, a potem bdziemy schodzi ju偶 w d贸 i bdzie coraz gorzej. Wic zacznijmy od powa偶nej rzeczy. Jest jedna rzecz, kt贸r mogliby zrobi z tego konferencj i j skoczy i nie ogasza nic wicej.

**Szymon Warda**: Wiem o czym m贸wisz.

**ukasz Kau偶ny**: Google ogosio Agent to Agent Protocol. I teraz co to jest? Wreszcie i to jest co piknego, wreszcie kto podni贸s rkawic i to nie tylko Google, ale prawie setka firm. I co mnie cieszy? S tam firmy i doradcze, to jest bardzo wa偶ne i doradcze, strategiczne, jak i multum rozwiza kocowych, biznesowych. Bra w tym udzia Atlassian, Salesforce, SAP, Service Now, Oracle, New Relic, Neo4j, JFrog, Mongo. Jest tego kupa firm, kt贸re bray udzia. I chodzi o to, 偶e jest ustandaryzowany, zdroworozsdkowy, to jest bardzo wa偶ne, zdroworozsdkowa specyfikacja w jaki ze sob spos贸b agenci maj rozmawia. Czyli je偶eli Ty masz np. chatbota agentowego, jak on ma wywoa chatbota w takim Salesforce czy w takim Service Now czy w takim SAP-ie? I to jest zo偶one na takie bardzo realne zao偶enia. Jedna rzecz, kt贸ra mi si tu zrobio ciepo na serduszku dosownie Szymon, kto pomyla, 偶e jest autoryzacja i uwierzytelnianie potrzebne i kontekst u偶ytkownika w tym. 呕al mi firm, kt贸re bd musiay to napisa jak bdziemy sprawdza czy poprawnie zaimplementowali. Ale to jest mega, bo jest np. przewidziana kontekstowo. I teraz wa偶na rzecz przy tym, bo kto mi zaraz powie, 偶e Anthropic wyda Model Context Protocol. I bdzie zaraz zarzutka, 偶e przecie偶 jest co od Anthropic'a. Nie, Anthropic, je偶eli popatrzycie, MCP i nawet tutaj wspominaj, 偶e to jest komplementarne, poniewa偶 MCP jest od tego jak model ma si integrowa ze wiatem, czyli jak ma wywoywa zewntrzne integracje i inne rzeczy. A agent to agent m贸wi jak jeden agent LLM-owy ma rozmawia z drugim agentem LLM-owym rozumiejc scenariusze u偶ycia, takie jak w szczeg贸lnoci rzeczy batchowe, user context, long running taski, agnostyczno modalnoci. Czyli te wszystkie rzeczy, kt贸re s takie w faktycznych scenariuszach, kiedy Ty przestajesz traktowa agenta jako tool, czyli... Bo teraz takie podejcie jest jak wywoujecie, 偶e wywoanie innego agenta jest po prostu function callingiem. To tutaj jest zrobiona nakadka, 偶eby naprawd wrzuci dobry kontekst sposobu u偶ywania z tego.

**Szymon Warda**: To wyglda ciekawie.

**ukasz Kau偶ny**: Tak i to bdzie... Inaczej, mog si zao偶y o piwo, 偶e to ju偶 bdzie standard.

**Szymon Warda**: Tak, to bdzie, bo nie ma nic innego jako alternatywy tak naprawd. Koniec. Ale okej, ale ruszye temat, kt贸ry jest, rzeczy, kt贸re s niemieszne i kt贸re bd powa偶ne i kt贸re faktycznie bdziemy wykorzystywali. To rzecz, kt贸ra troch za bardzo adnie nazwana, ale mimo wszystko fajna: Google Kubernetes Engine Inferecing. Czyli mianowicie to, 偶e skalowanie wykorzystujc AI-a, czy tam jest AI, czy tam s po prostu zwyke funkcje statystyczne du偶o prostsze...

**ukasz Kau偶ny**: Modele.

**Szymon Warda**: Nie, nie skalujemy LLM-em klastra, to troch nie ma sensu za bardzo finansowego chocia偶by i atencyjnego. Ale opcja, 偶eby doda autoskalowanie, 偶eby zarzdza tymi klastrami w spos贸b bardziej inteligentny, nie tylko na bazie po prostu, 偶e ta metryka teraz wybia, wic teraz skalujemy w g贸r, tylko wanie wyszukiwanie wzorc贸w zachowa, podobiestw, itd. Super, to jest naprawd fajne i jestem ciekaw jak to zadziaa tak w realnym u偶yciu, ale wydaje mi si, 偶e bdzie dobre.

**ukasz Kau偶ny**: Zobaczymy. Maj dobre wzorce w Borgu pod spodem i swoich rzeczach.

**Szymon Warda**: Tak, to jest tylko uo偶enie tego w odpowiedni spos贸b.

**ukasz Kau偶ny**: Dobra, wr贸my teraz na chwil do podmiechujek AI-owych. I teraz tak, zastanawiam si, czy to jest podmiechujka, czy nie, tak ju偶 na powa偶nie. Bo to, co wydali, zaadresowano potrzeb ju偶 t agentow, powstao co takiego jak Agentspace. Google Agentspace, czyli miejsce, gdzie mo偶esz wsadzi... Co jest wa偶ne, ja bardziej patrz teraz z perspektywy u偶ytkownika. To jest bardzo wa偶ne. Dziki wanie temu agent to agent mo偶esz podpi swoich agent贸w spoza Google'a docelowo, to jest wa偶ne i mo偶esz u偶ytkownikowi da jedn przestrze, w kt贸rej on mo偶e orkiestrowa i wysya zapytania do r贸偶nych agent贸w i zo偶y cay proces. Czyli masz taki centralny dostp dla endusera do tego, co jest w tym wypadku najlepsze, czyli: we藕 mi zbierz dane, wykonaj jak akcj tam, gdzie mam uprawnienia. I przy tym Agentspace dwie rzeczy, kt贸re s od razu zaadresowane. To s Access Control i wanie to nie jest DLP, ale nazywaj to Safeguard Sensitive Information, czyli od razu m贸wi tutaj wanie o tym, co u偶ytkownik mo偶e zobaczy. I to jest ju偶...

**Szymon Warda**: Znaczy jest to ucywilizowanie agent贸w.

**ukasz Kau偶ny**: Dostpu do agent贸w i zobaczymy to od ka偶dego z dostawc贸w w tym roku.

**Szymon Warda**: Dobrze, ja bd troch skaka z rzeczami nie AI-owymi, bo widziaem, 偶e ten kawaek przejmiesz. Z rzeczy, kt贸re mnie znowu zainteresoway, to by taki troch umieszek, Firestone teraz bdzie zgodny z MongoDB. Czemu? Wszyscy m贸wi. Czemu takie ogoszenie? Co widzimy? MongoDB byo kiedy super fajn technologi. Sprzedawao si na zasadzie, 偶e nie trzeba bdzie update'owa schemat贸w i w og贸le jest zero potrzeby. Potem si organizacje przekonay, 偶e jednak to utrzymywanie tego Mongo to nie jest takie super fajne. Efektem tego byo to przecie偶, 偶e Cosmos, kt贸ry wystartowa ju偶 sporo lat temu, wystartowa z protokoem zgodnym binarnie z MongoDB. Czemu? 呕eby firmy mogy przerzuci MongoDB wanie do Azure'a. Wic to jest znowu niewielki mo偶e ruch. Realnie powsta dlatego, 偶e klienci si pytali. Znaczy, 偶e jest parcie, 偶eby pozby si i to Mongo wywali. Ciekawe, jak kto potrzebuje, jest, prosz bardzo i te偶 potrzebuje, w kt贸rym kierunku si jednak bazy ruszaj i jak si og贸lnie rynek zachowuje.

**ukasz Kau偶ny**: Tak, zaraz wyjdzie, 偶e bdziemy mieli trzy protokoy. Redis, protok贸 Redisa, protok贸 Mongo i Postgresa. No i, przepraszam, jaki grafowy, Neo4j najlepiej. Tak?

**Szymon Warda**: Tak, na tym si skoczy, dokadnie. Wiesz co, grafy w tym roku to w og贸le dostay kopa jak nie wiem co. Cypher si przyjmuje cakiem bardzo fajnie. Tak 偶e wydaje mi si, 偶e odkurz moj wiedz z Cypher'a i mo偶e si przyda.

**ukasz Kau偶ny**: Dobra, to co, wracamy na chwil do AI-贸w i agent贸w. Agent Development Kit.

**Szymon Warda**: No wanie to w og贸le temat ominem kompletnie, bo tak ok, fajnie wyglda, lecimy dalej.

**ukasz Kau偶ny**: W sensie ja bardziej tym, 偶e znowu kto kt贸re podejcie znowu do... Kolejny framework do robienia agent贸w.

**Szymon Warda**: 呕eby to urealni, oni chwal si, 偶e mo偶esz stworzy wasnego agenta w 100 linii kodu.

**ukasz Kau偶ny**: Czy wiesz co, dobra, zerknem sobie i co jest dobre? To od razu jest pomylane o third party rzeczach. Z dobrych rzeczy, kt贸re s, bo popatrzyem sobie np. te偶, 偶eby... Inaczej, z jednej strony szydera, 偶e to Google'a, pewnie zaraz zginie, ale z takich dobrych rzeczy, to dobrze zosta przemylany, prosto zosta przemylany tooling i od razu wsparcie wanie dla MCP. To jest pierwsza rzecz. Druga, przy tworzeniu workflow'贸w zostao przemylane kodowanie workflow'贸w, gdzie masz podejcie sekwencyjne, parallel lub obsugi rzeczy. Czyli zosta, 偶e mo偶esz np., to nie jest taki typowy wiesz, 偶e mo偶esz sobie zrobi, nie, 偶e postawisz, dwa agenty bd ze sob gaday, ale mo偶esz faktycznie zrobi workflow, jak ma co by procesowane z dynamicznym routingiem te偶 pomidzy LLM agentami. Wic to jest dobry pomys. Druga rzecz, 偶e od razu przychodzi z narzuceniem sposobu deploymentu w kontenerze. Czyli w sensie wiesz, wyglda lepiej ni偶 LangChain np.

**Szymon Warda**: Okej, dobra. Super fajnie, tylko prawda jest teraz taka tak, to pewnie w jakim stopniu za偶re. Moje pytanie jest teraz takie - czy bdzie wok贸 tego spoeczno, kt贸ra bdzie to rozwijaa? Czy bdzie to znowu produkt tylko google'owy i potem jak Google stwierdzi, 偶e jednak mamy co nowego, to bdzie znowu wielka drama, 偶e Google co porzuci.

**ukasz Kau偶ny**: Wielka drama, 偶e co porzuci, jak zawsze.

**Szymon Warda**: Oczywicie, 偶e tak, no wanie. Wic dla mnie sorry, jest jakie spore ryzyko wchodzenie w takie rozwizania, bo nie wiadomo jak to bdzie si zachowywao za powiedzmy dwa lata.

**ukasz Kau偶ny**: Tak, to jest jedna rzecz. Druga sprawa, wiesz, jak sobie popatrzycie na pisanie wasnego loopa do agenta to te偶 nie jest 偶adna straszna rzecz.

**Szymon Warda**: To te偶 wanie, dlatego ja bardziej czekam na t opcj, jak kto si zainspiruje tym z open source'u i to za偶re open source'owo faktycznie.

**ukasz Kau偶ny**: Wiesz co, inaczej, wiesz co, powiem Ci tak. W open source to jest, bo masz tam, ostatnio robiem, skoczyem na tym, 偶e musiaem napisa wasn implementacj od zera, takie byo przejcie przez open source. Jak wejdziesz w, wybaczcie, je偶eli kto z Was zajmuje si Data Science, ale wybaczcie, 偶e o tym powiem, ML engineerowie zrozumiej o czym m贸wi, czyli ten kod przypomina i dziury w u偶yciu tego faktycznym, przypomina kod z notebook贸w data scientist'owych.

**Szymon Warda**: Czyli absolutny pierdolnik.

**ukasz Kau偶ny**: Tak, 偶e np. kurde, jedna gupia rzecz, chciabym zrobi tracing, wpi si w atwy spos贸b do tracingu i zbiera np. ile kosztowaa mnie z agentem pena konwersacja, ile kosztowaa mnie od A-Z pena konwersacja. I okazuje si, tak, jestemy w te frameworki, jestemy np. model agnostic. Okazuje si, 偶e na tym modelu dziaa to, ten model trzeba callbacki oprogramowa tak, tamten tak. Zero warstw abstrakcji na przykad, kt贸rych by oczekiwa od framework'a, biblioteki, kt贸re powinny by dostarczone.

**Szymon Warda**: Dlatego na spokojnie, to si rozwija. Fajnie, 偶e ADK powstao. Czekam a偶 kto te pomysy zbierze w jedn cao i powstanie co, co bdzie faktycznie dobre z poziomu in偶ynieryjnego, nie tylko: mo偶emy si pobawi. Poczekamy.

**ukasz Kau偶ny**: Od strony kodu jest spoko, o tak, wyglda na dojrzalsze, o tak, to taki pierwszy look and feel bez odpalania, przejcia przez dokumentacj.

**Szymon Warda**: Jasne.

**ukasz Kau偶ny**: Dobra, to koczymy. Teraz tak, miay by podmiechujki AI-owe, cig dalszy. Czyli tak, pierwsze, oczywicie Code Assist, tutaj nazywamy Gemini Code Assist. Musi by koniec, jest w postaci extensiona do Visual Studio Code, tryb agentowy i w og贸le.

**Szymon Warda**: Co jest ciekawe? Powicili temu do du偶o czasu, tak, m贸wic o tym na konferencjach, chwalili si tym bardzo mocno.

**ukasz Kau偶ny**: Dla developer贸w, jest, tak jest w tym. Tam patrzc, to wszystko byo teraz do sporo, bo to wczeniej byo, w zeszym roku te偶 ju偶 tam byo te rzeczy wok贸 tego. Tu jest wicej, o tak, i ten tryb agentowy. Przy czym ja tak, ja testowaem sobie te Gemini 2,5, te najnowsze, tam ju偶 par przed tym Nextem, jak teraz wyszo. Ono byo dobre, o tak, byo dobre, tutaj naprawd nadganiaj, wic to jest to. Ale rzecz, kt贸ra za tym idzie, to jest Firebase Studio, czyli ja bym powiedzia GitHub Spark na sterydach, czyli mo偶liwo zbudowania full stackowo aplikacji. Albo raczej, bardzo mi si to podoba, get started with the app Prototyping Agents. Czyli to, o czym m贸wilimy w poprzednim odcinku przy vibe codingu, czyli miejsce do tworzenia sobie, wanie takie studio i cay stos do tworzenia aplikacji razem z hostingiem.

**Szymon Warda**: Ponownie czapka sceptyka, zobaczymy jak to wypali w wikszej skali.

**ukasz Kau偶ny**: Wiesz, dlatego por贸wnuj to do GitHub Sparka.

**Szymon Warda**: Tak, to s te same narzdzia, do tego samego su偶. Zobaczymy jak si przyjmie, jak bdzie dalej rozwijana.

**ukasz Kau偶ny**: Ze wzgldu na Firebase'a potrafi wicej.

**Szymon Warda**: Firebase i jego popularno, je偶eli chodzi o rozpoznawanie nazw, Firebase jest dla wielu developer贸w i w wielu obszarach po prostu domyln usug.

**ukasz Kau偶ny**: Tak i LLM jest tego te偶 nauczony dobrze, ich.

**Szymon Warda**: Tak. Dobra.

**ukasz Kau偶ny**: Czyli co? Rok agent贸w niestety, tak jak si nabijalimy ju偶 dawno.

**Szymon Warda**: Wydaje mi si, 偶e jeszcze gieda to poka偶e, co bdzie si dziao tak naprawd. Dobrze. To tyle. Na razie.

**ukasz Kau偶ny**: Trzymajcie si, na razie.
